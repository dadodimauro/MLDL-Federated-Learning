{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import copy\n",
    "import pickle\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from models import ResNet50\n",
    "from models_CCVR import feature_extractor, classifier\n",
    "from update import LocalUpdate, test_inference"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# parameters\n",
    "iid = 1 # if the data is i.i.d or not\n",
    "unbalanced = 0 # in non i.i.d. setting split the data between clients equally or not\n",
    "num_users = 100 # number of client\n",
    "frac = 0.1 # fraction of the clients to be used for federated updates\n",
    "n_epochs = 100\n",
    "gpu = 0\n",
    "optimizer = \"sgd\" #sgd or adam\n",
    "local_batch_size = 10 # batch size of local updates in each user\n",
    "lr = 0.001 # learning rate\n",
    "local_epochs = 10\n",
    "loss_function = \"CrossEntropyLoss\"\n",
    "\n",
    "# percentage = 90  # percentage of strugglers\n",
    "\n",
    "num_groups = 0  # 0 for BatchNorm, > 0 for GroupNorm\n",
    "if num_groups == 0:\n",
    "    normalization_type = \"BatchNorm\"\n",
    "else:\n",
    "    normalization_type = \"GroupNorm\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "if iid:\n",
    "    from utils_v2 import get_dataset, average_weights, weighted_average_weights, exp_details\n",
    "else:\n",
    "    from utils import get_dataset, average_weights, weighted_average_weights, exp_details"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# for REPRODUCIBILITY https://pytorch.org/docs/stable/notes/randomness.html\n",
    "torch.manual_seed(0)\n",
    "\n",
    "generator = torch.Generator()\n",
    "generator.manual_seed(0)\n",
    "\n",
    "np.random.seed(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "class DatasetSplit(Dataset):\n",
    "    \"\"\"\n",
    "    An abstract Dataset class wrapped around Pytorch Dataset class.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, idxs):\n",
    "        self.dataset = dataset\n",
    "        self.idxs = [int(i) for i in idxs]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idxs)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        image, label = self.dataset[self.idxs[item]]\n",
    "        return torch.tensor(image), torch.tensor(label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def get_dataloader(dataset, idxs):\n",
    "    trainloader = DataLoader(DatasetSplit(dataset, idxs),\n",
    "                             batch_size=None, shuffle=True, generator=generator,\n",
    "                             worker_init_fn=seed_worker)\n",
    "\n",
    "    return trainloader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset, user_groups = get_dataset(iid=iid, unbalanced=unbalanced,\n",
    "                                                       num_users=num_users)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n"
     ]
    },
    {
     "data": {
      "text/plain": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n  )\n  (layer3): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n  )\n  (layer4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n  )\n  (linear): Linear(in_features=2048, out_features=10, bias=True)\n)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet50(n_type=normalization_type)\n",
    "# model = CNNCifar()\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "    device = torch.device(\"cpu\")\n",
    "    gpu = 0\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')\n",
    "    device = torch.device(\"cuda\")\n",
    "    gpu = 1\n",
    "\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filename_pt = \"fedAVG_results/weighted_average/ResNet50_100_sgd_lr_[0.001]_C[0.1]_iid[0]_unbalanced[1]_E[1]_B[10]_BatchNorm_numGroups[0].pt\"\n",
    "\n",
    "# filename_pt = \"fedAVG_results/ResNet50_100_sgd_lr_[0.001]_C[0.1]_iid[0]_unbalanced[0]_E[1]_B[10]_BatchNorm_numGroups[0].pt\"\n",
    "\n",
    "filename_pt = \"fedAVG_results/ResNet50_100_sgd_lr_[0.001]_C[0.1]_iid[1]_unbalanced[0]_E[1]_B[10]_BatchNorm_numGroups[0].pt\"\n",
    "\n",
    "# load saved model (i.e. the one with the smallest validation loss)\n",
    "model.load_state_dict(torch.load(filename_pt))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = feature_extractor()\n",
    "f.to(device)\n",
    "\n",
    "f.load_state_dict(torch.load(filename_pt))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# def test_inference(model, test_dataset, gpu=1, local_batch_size=10, loss_function=\"NLLLoss\"):\n",
    "#     \"\"\"\n",
    "#     Returns the test accuracy and loss.\n",
    "#     \"\"\"\n",
    "#\n",
    "#     model.eval()\n",
    "#     test_loss = 0.0\n",
    "#     class_correct = list(0. for i in range(10))\n",
    "#     class_total = list(0. for i in range(10))\n",
    "#\n",
    "#     device = 'cuda' if gpu else 'cpu'\n",
    "#     if loss_function == \"NLLLoss\":\n",
    "#         criterion = nn.NLLLoss()\n",
    "#     if loss_function == \"CrossEntropyLoss\":\n",
    "#         criterion = nn.CrossEntropyLoss()\n",
    "#\n",
    "#     testloader = DataLoader(test_dataset, batch_size=local_batch_size,\n",
    "#                             shuffle=False, generator=generator)\n",
    "#\n",
    "#     for images, labels in testloader:\n",
    "#         images, labels = images.to(device), labels.to(device)\n",
    "#\n",
    "#         # Inference\n",
    "#         output = model(images)\n",
    "#         loss = criterion(output, labels)\n",
    "#         test_loss += (loss.data.item() * images.shape[0])\n",
    "#\n",
    "#         # Prediction\n",
    "#         # convert output probabilities to predicted class\n",
    "#         _, pred = torch.max(output, 1)\n",
    "#         # compare predictions to true label\n",
    "#         correct_tensor = pred.eq(labels.data.view_as(pred))\n",
    "#         correct = np.squeeze(correct_tensor.numpy()) if not gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "#\n",
    "#         for i in range(len(images)):\n",
    "#             label = labels.data[i]\n",
    "#             class_correct[label] += correct[i].item()\n",
    "#             class_total[label] += 1\n",
    "#\n",
    "#     # average test loss\n",
    "#     test_loss = test_loss / len(testloader.dataset)\n",
    "#\n",
    "#     accuracy = np.sum(class_correct) / np.sum(class_total)\n",
    "#\n",
    "#     return accuracy, test_loss\n",
    "#\n",
    "#\n",
    "# # test the trained model\n",
    "#\n",
    "# test_acc, test_loss = test_inference(model=model, test_dataset=test_dataset, gpu=gpu,\n",
    "#                                      loss_function=loss_function)\n",
    "#\n",
    "# print(f'\\nResults after {n_epochs} global rounds of training:')\n",
    "# print(\"|---- Test Accuracy: {:.2f}%\".format(100*test_acc))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# import torch.nn.functional as F\n",
    "#\n",
    "# f = nn.Sequential(\n",
    "#     # stop at conv4\n",
    "#     *list(model.children())[:-1]\n",
    "# )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "            Conv2d-3           [-1, 64, 32, 32]           4,096\n",
      "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
      "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
      "            Conv2d-7          [-1, 256, 32, 32]          16,384\n",
      "       BatchNorm2d-8          [-1, 256, 32, 32]             512\n",
      "            Conv2d-9          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-10          [-1, 256, 32, 32]             512\n",
      "       Bottleneck-11          [-1, 256, 32, 32]               0\n",
      "           Conv2d-12           [-1, 64, 32, 32]          16,384\n",
      "      BatchNorm2d-13           [-1, 64, 32, 32]             128\n",
      "           Conv2d-14           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-15           [-1, 64, 32, 32]             128\n",
      "           Conv2d-16          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-17          [-1, 256, 32, 32]             512\n",
      "       Bottleneck-18          [-1, 256, 32, 32]               0\n",
      "           Conv2d-19           [-1, 64, 32, 32]          16,384\n",
      "      BatchNorm2d-20           [-1, 64, 32, 32]             128\n",
      "           Conv2d-21           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-22           [-1, 64, 32, 32]             128\n",
      "           Conv2d-23          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 32, 32]             512\n",
      "       Bottleneck-25          [-1, 256, 32, 32]               0\n",
      "           Conv2d-26          [-1, 128, 32, 32]          32,768\n",
      "      BatchNorm2d-27          [-1, 128, 32, 32]             256\n",
      "           Conv2d-28          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 16, 16]             256\n",
      "           Conv2d-30          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-31          [-1, 512, 16, 16]           1,024\n",
      "           Conv2d-32          [-1, 512, 16, 16]         131,072\n",
      "      BatchNorm2d-33          [-1, 512, 16, 16]           1,024\n",
      "       Bottleneck-34          [-1, 512, 16, 16]               0\n",
      "           Conv2d-35          [-1, 128, 16, 16]          65,536\n",
      "      BatchNorm2d-36          [-1, 128, 16, 16]             256\n",
      "           Conv2d-37          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-38          [-1, 128, 16, 16]             256\n",
      "           Conv2d-39          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-40          [-1, 512, 16, 16]           1,024\n",
      "       Bottleneck-41          [-1, 512, 16, 16]               0\n",
      "           Conv2d-42          [-1, 128, 16, 16]          65,536\n",
      "      BatchNorm2d-43          [-1, 128, 16, 16]             256\n",
      "           Conv2d-44          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-45          [-1, 128, 16, 16]             256\n",
      "           Conv2d-46          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-47          [-1, 512, 16, 16]           1,024\n",
      "       Bottleneck-48          [-1, 512, 16, 16]               0\n",
      "           Conv2d-49          [-1, 128, 16, 16]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 16, 16]             256\n",
      "           Conv2d-51          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-52          [-1, 128, 16, 16]             256\n",
      "           Conv2d-53          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-54          [-1, 512, 16, 16]           1,024\n",
      "       Bottleneck-55          [-1, 512, 16, 16]               0\n",
      "           Conv2d-56          [-1, 256, 16, 16]         131,072\n",
      "      BatchNorm2d-57          [-1, 256, 16, 16]             512\n",
      "           Conv2d-58            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-59            [-1, 256, 8, 8]             512\n",
      "           Conv2d-60           [-1, 1024, 8, 8]         262,144\n",
      "      BatchNorm2d-61           [-1, 1024, 8, 8]           2,048\n",
      "           Conv2d-62           [-1, 1024, 8, 8]         524,288\n",
      "      BatchNorm2d-63           [-1, 1024, 8, 8]           2,048\n",
      "       Bottleneck-64           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-65            [-1, 256, 8, 8]         262,144\n",
      "      BatchNorm2d-66            [-1, 256, 8, 8]             512\n",
      "           Conv2d-67            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-68            [-1, 256, 8, 8]             512\n",
      "           Conv2d-69           [-1, 1024, 8, 8]         262,144\n",
      "      BatchNorm2d-70           [-1, 1024, 8, 8]           2,048\n",
      "       Bottleneck-71           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-72            [-1, 256, 8, 8]         262,144\n",
      "      BatchNorm2d-73            [-1, 256, 8, 8]             512\n",
      "           Conv2d-74            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-75            [-1, 256, 8, 8]             512\n",
      "           Conv2d-76           [-1, 1024, 8, 8]         262,144\n",
      "      BatchNorm2d-77           [-1, 1024, 8, 8]           2,048\n",
      "       Bottleneck-78           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-79            [-1, 256, 8, 8]         262,144\n",
      "      BatchNorm2d-80            [-1, 256, 8, 8]             512\n",
      "           Conv2d-81            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-82            [-1, 256, 8, 8]             512\n",
      "           Conv2d-83           [-1, 1024, 8, 8]         262,144\n",
      "      BatchNorm2d-84           [-1, 1024, 8, 8]           2,048\n",
      "       Bottleneck-85           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-86            [-1, 256, 8, 8]         262,144\n",
      "      BatchNorm2d-87            [-1, 256, 8, 8]             512\n",
      "           Conv2d-88            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-89            [-1, 256, 8, 8]             512\n",
      "           Conv2d-90           [-1, 1024, 8, 8]         262,144\n",
      "      BatchNorm2d-91           [-1, 1024, 8, 8]           2,048\n",
      "       Bottleneck-92           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-93            [-1, 256, 8, 8]         262,144\n",
      "      BatchNorm2d-94            [-1, 256, 8, 8]             512\n",
      "           Conv2d-95            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-96            [-1, 256, 8, 8]             512\n",
      "           Conv2d-97           [-1, 1024, 8, 8]         262,144\n",
      "      BatchNorm2d-98           [-1, 1024, 8, 8]           2,048\n",
      "       Bottleneck-99           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-100            [-1, 512, 8, 8]         524,288\n",
      "     BatchNorm2d-101            [-1, 512, 8, 8]           1,024\n",
      "          Conv2d-102            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-103            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-104           [-1, 2048, 4, 4]       1,048,576\n",
      "     BatchNorm2d-105           [-1, 2048, 4, 4]           4,096\n",
      "          Conv2d-106           [-1, 2048, 4, 4]       2,097,152\n",
      "     BatchNorm2d-107           [-1, 2048, 4, 4]           4,096\n",
      "      Bottleneck-108           [-1, 2048, 4, 4]               0\n",
      "          Conv2d-109            [-1, 512, 4, 4]       1,048,576\n",
      "     BatchNorm2d-110            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-111            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-112            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-113           [-1, 2048, 4, 4]       1,048,576\n",
      "     BatchNorm2d-114           [-1, 2048, 4, 4]           4,096\n",
      "      Bottleneck-115           [-1, 2048, 4, 4]               0\n",
      "          Conv2d-116            [-1, 512, 4, 4]       1,048,576\n",
      "     BatchNorm2d-117            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-118            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-119            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-120           [-1, 2048, 4, 4]       1,048,576\n",
      "     BatchNorm2d-121           [-1, 2048, 4, 4]           4,096\n",
      "      Bottleneck-122           [-1, 2048, 4, 4]               0\n",
      "================================================================\n",
      "Total params: 23,500,352\n",
      "Trainable params: 23,500,352\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 66.12\n",
      "Params size (MB): 89.65\n",
      "Estimated Total Size (MB): 155.78\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(f, (3, 32, 32))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "            Conv2d-3           [-1, 64, 32, 32]           4,096\n",
      "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
      "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
      "            Conv2d-7          [-1, 256, 32, 32]          16,384\n",
      "       BatchNorm2d-8          [-1, 256, 32, 32]             512\n",
      "            Conv2d-9          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-10          [-1, 256, 32, 32]             512\n",
      "       Bottleneck-11          [-1, 256, 32, 32]               0\n",
      "           Conv2d-12           [-1, 64, 32, 32]          16,384\n",
      "      BatchNorm2d-13           [-1, 64, 32, 32]             128\n",
      "           Conv2d-14           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-15           [-1, 64, 32, 32]             128\n",
      "           Conv2d-16          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-17          [-1, 256, 32, 32]             512\n",
      "       Bottleneck-18          [-1, 256, 32, 32]               0\n",
      "           Conv2d-19           [-1, 64, 32, 32]          16,384\n",
      "      BatchNorm2d-20           [-1, 64, 32, 32]             128\n",
      "           Conv2d-21           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-22           [-1, 64, 32, 32]             128\n",
      "           Conv2d-23          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 32, 32]             512\n",
      "       Bottleneck-25          [-1, 256, 32, 32]               0\n",
      "           Conv2d-26          [-1, 128, 32, 32]          32,768\n",
      "      BatchNorm2d-27          [-1, 128, 32, 32]             256\n",
      "           Conv2d-28          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 16, 16]             256\n",
      "           Conv2d-30          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-31          [-1, 512, 16, 16]           1,024\n",
      "           Conv2d-32          [-1, 512, 16, 16]         131,072\n",
      "      BatchNorm2d-33          [-1, 512, 16, 16]           1,024\n",
      "       Bottleneck-34          [-1, 512, 16, 16]               0\n",
      "           Conv2d-35          [-1, 128, 16, 16]          65,536\n",
      "      BatchNorm2d-36          [-1, 128, 16, 16]             256\n",
      "           Conv2d-37          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-38          [-1, 128, 16, 16]             256\n",
      "           Conv2d-39          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-40          [-1, 512, 16, 16]           1,024\n",
      "       Bottleneck-41          [-1, 512, 16, 16]               0\n",
      "           Conv2d-42          [-1, 128, 16, 16]          65,536\n",
      "      BatchNorm2d-43          [-1, 128, 16, 16]             256\n",
      "           Conv2d-44          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-45          [-1, 128, 16, 16]             256\n",
      "           Conv2d-46          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-47          [-1, 512, 16, 16]           1,024\n",
      "       Bottleneck-48          [-1, 512, 16, 16]               0\n",
      "           Conv2d-49          [-1, 128, 16, 16]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 16, 16]             256\n",
      "           Conv2d-51          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-52          [-1, 128, 16, 16]             256\n",
      "           Conv2d-53          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-54          [-1, 512, 16, 16]           1,024\n",
      "       Bottleneck-55          [-1, 512, 16, 16]               0\n",
      "           Conv2d-56          [-1, 256, 16, 16]         131,072\n",
      "      BatchNorm2d-57          [-1, 256, 16, 16]             512\n",
      "           Conv2d-58            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-59            [-1, 256, 8, 8]             512\n",
      "           Conv2d-60           [-1, 1024, 8, 8]         262,144\n",
      "      BatchNorm2d-61           [-1, 1024, 8, 8]           2,048\n",
      "           Conv2d-62           [-1, 1024, 8, 8]         524,288\n",
      "      BatchNorm2d-63           [-1, 1024, 8, 8]           2,048\n",
      "       Bottleneck-64           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-65            [-1, 256, 8, 8]         262,144\n",
      "      BatchNorm2d-66            [-1, 256, 8, 8]             512\n",
      "           Conv2d-67            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-68            [-1, 256, 8, 8]             512\n",
      "           Conv2d-69           [-1, 1024, 8, 8]         262,144\n",
      "      BatchNorm2d-70           [-1, 1024, 8, 8]           2,048\n",
      "       Bottleneck-71           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-72            [-1, 256, 8, 8]         262,144\n",
      "      BatchNorm2d-73            [-1, 256, 8, 8]             512\n",
      "           Conv2d-74            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-75            [-1, 256, 8, 8]             512\n",
      "           Conv2d-76           [-1, 1024, 8, 8]         262,144\n",
      "      BatchNorm2d-77           [-1, 1024, 8, 8]           2,048\n",
      "       Bottleneck-78           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-79            [-1, 256, 8, 8]         262,144\n",
      "      BatchNorm2d-80            [-1, 256, 8, 8]             512\n",
      "           Conv2d-81            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-82            [-1, 256, 8, 8]             512\n",
      "           Conv2d-83           [-1, 1024, 8, 8]         262,144\n",
      "      BatchNorm2d-84           [-1, 1024, 8, 8]           2,048\n",
      "       Bottleneck-85           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-86            [-1, 256, 8, 8]         262,144\n",
      "      BatchNorm2d-87            [-1, 256, 8, 8]             512\n",
      "           Conv2d-88            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-89            [-1, 256, 8, 8]             512\n",
      "           Conv2d-90           [-1, 1024, 8, 8]         262,144\n",
      "      BatchNorm2d-91           [-1, 1024, 8, 8]           2,048\n",
      "       Bottleneck-92           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-93            [-1, 256, 8, 8]         262,144\n",
      "      BatchNorm2d-94            [-1, 256, 8, 8]             512\n",
      "           Conv2d-95            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-96            [-1, 256, 8, 8]             512\n",
      "           Conv2d-97           [-1, 1024, 8, 8]         262,144\n",
      "      BatchNorm2d-98           [-1, 1024, 8, 8]           2,048\n",
      "       Bottleneck-99           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-100            [-1, 512, 8, 8]         524,288\n",
      "     BatchNorm2d-101            [-1, 512, 8, 8]           1,024\n",
      "          Conv2d-102            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-103            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-104           [-1, 2048, 4, 4]       1,048,576\n",
      "     BatchNorm2d-105           [-1, 2048, 4, 4]           4,096\n",
      "          Conv2d-106           [-1, 2048, 4, 4]       2,097,152\n",
      "     BatchNorm2d-107           [-1, 2048, 4, 4]           4,096\n",
      "      Bottleneck-108           [-1, 2048, 4, 4]               0\n",
      "          Conv2d-109            [-1, 512, 4, 4]       1,048,576\n",
      "     BatchNorm2d-110            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-111            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-112            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-113           [-1, 2048, 4, 4]       1,048,576\n",
      "     BatchNorm2d-114           [-1, 2048, 4, 4]           4,096\n",
      "      Bottleneck-115           [-1, 2048, 4, 4]               0\n",
      "          Conv2d-116            [-1, 512, 4, 4]       1,048,576\n",
      "     BatchNorm2d-117            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-118            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-119            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-120           [-1, 2048, 4, 4]       1,048,576\n",
      "     BatchNorm2d-121           [-1, 2048, 4, 4]           4,096\n",
      "      Bottleneck-122           [-1, 2048, 4, 4]               0\n",
      "          Linear-123                   [-1, 10]          20,490\n",
      "================================================================\n",
      "Total params: 23,520,842\n",
      "Trainable params: 23,520,842\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 66.13\n",
      "Params size (MB): 89.72\n",
      "Estimated Total Size (MB): 155.86\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (3, 32, 32))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# from torchvision.models.feature_extraction import get_graph_node_names\n",
    "#\n",
    "# train_nodes, eval_nodes = get_graph_node_names(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# return_nodes_featureExtractor = {\n",
    "#     # node_name: user-specified key for output dict\n",
    "#     'layer1.2.relu_2': 'layer1',\n",
    "#     'layer2.3.relu_2': 'layer2',\n",
    "#     'layer3.5.relu_2': 'layer3',\n",
    "#     'layer4.2.relu_2': 'layer4'\n",
    "# }\n",
    "#\n",
    "# return_nodes_Classifier = {\n",
    "#     'avg_pool2d' : 'avg_pool',\n",
    "#     'size' : 'size',\n",
    "#     'view' : 'view',\n",
    "#     'linear' : 'linear'\n",
    "# }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# from torchvision.models.feature_extraction import create_feature_extractor\n",
    "#\n",
    "# f = create_feature_extractor(model, train_return_nodes=train_nodes[:-3], eval_return_nodes=eval_nodes[:-3])\n",
    "# # f = create_feature_extractor(model, return_nodes_featureExtractor)\n",
    "# g = create_feature_extractor(model, return_nodes_Classifier)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# f(torch.rand((1, 3, 32, 32)).to(device))[\"avg_pool2d\"].reshape(-1).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# g(torch.rand((1, 3, 32, 32)).to(device))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def clientUpdate(f, dataset, idxs, device):\n",
    "\n",
    "    trainloader = get_dataloader(dataset, idxs)\n",
    "\n",
    "    d = {}\n",
    "    sum_ = 0\n",
    "\n",
    "    # extract features by category\n",
    "    for batch_idx, (image, label) in enumerate(trainloader):\n",
    "        sum_ += 1\n",
    "\n",
    "        image = image.to(device)\n",
    "        label = int(label.cpu())\n",
    "\n",
    "        # feature = (f(image.reshape(1, 3, 32, 32))[\"avg_pool2d\"].reshape(-1)).cpu().detach()\n",
    "        # feature = (f(image.reshape(1, 3, 32, 32))[\"layer4.2.relu_2\"].reshape(-1)).cpu().detach()\n",
    "        feature = (f(image.reshape(1, 3, 32, 32)).reshape(-1)).cpu().detach()\n",
    "\n",
    "        if label in d.keys():\n",
    "            d[label].append(feature)\n",
    "        else:\n",
    "            d[label] = [feature]\n",
    "\n",
    "    # mu, sigma\n",
    "    upload_d = {}\n",
    "\n",
    "    # for k, v in tqdm.tqdm(d.items()):\n",
    "    #     v_item = torch.stack(v).detach().cpu()\n",
    "    #\n",
    "    #     # consider the case where the sample size is too small to upload\n",
    "    #     if len(v_item) < 10:\n",
    "    #         continue\n",
    "    #\n",
    "    #     mu, sigma = v_item.mean(dim=0), v_item.var(dim=0)\n",
    "    #     upload_d[k] = {\"mu\": mu, \"sigma\": sigma, \"N\": len(v)}\n",
    "\n",
    "    for k, v in tqdm.tqdm(d.items()):\n",
    "        v_item = torch.stack(v).detach().cpu()\n",
    "        # consider the case where the sample size is too small to upload\n",
    "        if len(v_item) < 10:\n",
    "            continue\n",
    "\n",
    "        N = len(v)\n",
    "\n",
    "        mu = v_item.mean(dim=0)\n",
    "\n",
    "        sigma = torch.zeros((2048, 2048))\n",
    "        for t in v_item:\n",
    "            x = (t - mu).reshape(1, 2048)\n",
    "            sigma = torch.add(torch.mul(x, torch.transpose(x, 1, 0)), sigma)\n",
    "        sigma *= 1/(N-1)\n",
    "\n",
    "        upload_d[k] = {\"mu\": mu, \"sigma\": sigma, \"N\": N}\n",
    "\n",
    "    return upload_d"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_23232\\3803027819.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(image), torch.tensor(label)\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.26it/s]\n"
     ]
    }
   ],
   "source": [
    "upload_d = clientUpdate(f, train_dataset, user_groups[0], device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys([9, 5, 3, 4, 8, 7, 6, 0, 1, 2])"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload_d.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2048])"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload_d[0][\"mu\"].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2048, 2048])"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload_d[0][\"sigma\"].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_23232\\3803027819.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(image), torch.tensor(label)\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.87it/s]\n",
      "100%|██████████| 10/10 [00:02<00:00,  3.53it/s]\n",
      "100%|██████████| 10/10 [00:02<00:00,  3.50it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.20it/s]\n",
      "100%|██████████| 10/10 [00:02<00:00,  3.46it/s]\n",
      "100%|██████████| 10/10 [00:02<00:00,  3.52it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.20it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.29it/s]\n",
      "100%|██████████| 10/10 [00:02<00:00,  3.48it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.27it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.22it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.97it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.04it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.22it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.30it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.16it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.21it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.30it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.06it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.11it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.33it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.11it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.14it/s]\n",
      "100%|██████████| 10/10 [00:02<00:00,  3.34it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.11it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.11it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.28it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.03it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.07it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.16it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.98it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.81it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.89it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.74it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.92it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.79it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.76it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.91it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.73it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.88it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.79it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.94it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.72it/s]\n",
      "100%|██████████| 10/10 [00:04<00:00,  2.50it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.55it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.55it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.53it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.55it/s]\n",
      "100%|██████████| 10/10 [00:04<00:00,  2.36it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.55it/s]\n",
      "100%|██████████| 10/10 [00:04<00:00,  2.24it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.60it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.51it/s]\n",
      "100%|██████████| 10/10 [00:04<00:00,  2.39it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.52it/s]\n",
      "100%|██████████| 10/10 [00:04<00:00,  2.39it/s]\n",
      "100%|██████████| 10/10 [00:04<00:00,  2.36it/s]\n",
      "100%|██████████| 10/10 [00:04<00:00,  2.49it/s]\n",
      "100%|██████████| 10/10 [00:04<00:00,  2.35it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.82it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.61it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.61it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.61it/s]\n",
      "100%|██████████| 10/10 [00:04<00:00,  2.42it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.80it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.51it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.61it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.69it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.78it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.73it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.91it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.77it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.90it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.86it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.89it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.97it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.70it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.95it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.85it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.70it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.88it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.78it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.78it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.93it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.70it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.91it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.72it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.83it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.82it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.78it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.95it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.75it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.95it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.77it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.85it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.85it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.74it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.95it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.72it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.82it/s]\n"
     ]
    }
   ],
   "source": [
    "m = max(int(frac * num_users), 1) # number of users to be used for federated updates, at least 1\n",
    "# idxs_users = np.random.choice(range(num_users), m, replace=False) # choose randomly m users\n",
    "\n",
    "idxs_users = range(num_users)\n",
    "\n",
    "upload_d_list = [ clientUpdate(f, train_dataset, user_groups[idx], device) for idx in idxs_users ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "data": {
      "text/plain": "{5: {'mu': tensor([0.8084, 0.8075, 0.8563,  ..., 0.8329, 0.9784, 0.8318]),\n  'sigma': tensor([[ 0.0117,  0.0036,  0.0019,  ...,  0.0023,  0.0024,  0.0064],\n          [ 0.0036,  0.0065,  0.0024,  ...,  0.0020,  0.0025,  0.0032],\n          [ 0.0019,  0.0024,  0.0112,  ..., -0.0017,  0.0030,  0.0040],\n          ...,\n          [ 0.0023,  0.0020, -0.0017,  ...,  0.0124,  0.0002,  0.0019],\n          [ 0.0024,  0.0025,  0.0030,  ...,  0.0002,  0.0084,  0.0036],\n          [ 0.0064,  0.0032,  0.0040,  ...,  0.0019,  0.0036,  0.0169]]),\n  'N': 50},\n 6: {'mu': tensor([0.8137, 0.8196, 0.8324,  ..., 0.8494, 0.9741, 0.8529]),\n  'sigma': tensor([[ 0.0127,  0.0034,  0.0010,  ...,  0.0010,  0.0043,  0.0022],\n          [ 0.0034,  0.0069,  0.0011,  ...,  0.0032,  0.0030,  0.0028],\n          [ 0.0010,  0.0011,  0.0115,  ..., -0.0016,  0.0005,  0.0049],\n          ...,\n          [ 0.0010,  0.0032, -0.0016,  ...,  0.0110,  0.0042,  0.0033],\n          [ 0.0043,  0.0030,  0.0005,  ...,  0.0042,  0.0107,  0.0055],\n          [ 0.0022,  0.0028,  0.0049,  ...,  0.0033,  0.0055,  0.0130]]),\n  'N': 50},\n 4: {'mu': tensor([0.7992, 0.8264, 0.8260,  ..., 0.8293, 0.9928, 0.8232]),\n  'sigma': tensor([[0.0113, 0.0036, 0.0027,  ..., 0.0050, 0.0012, 0.0025],\n          [0.0036, 0.0095, 0.0015,  ..., 0.0027, 0.0004, 0.0025],\n          [0.0027, 0.0015, 0.0069,  ..., 0.0021, 0.0017, 0.0012],\n          ...,\n          [0.0050, 0.0027, 0.0021,  ..., 0.0125, 0.0005, 0.0018],\n          [0.0012, 0.0004, 0.0017,  ..., 0.0005, 0.0114, 0.0016],\n          [0.0025, 0.0025, 0.0012,  ..., 0.0018, 0.0016, 0.0106]]),\n  'N': 50},\n 9: {'mu': tensor([0.8015, 0.8127, 0.8311,  ..., 0.8216, 0.9607, 0.8249]),\n  'sigma': tensor([[0.0084, 0.0008, 0.0015,  ..., 0.0016, 0.0006, 0.0022],\n          [0.0008, 0.0104, 0.0021,  ..., 0.0028, 0.0032, 0.0037],\n          [0.0015, 0.0021, 0.0091,  ..., 0.0014, 0.0032, 0.0015],\n          ...,\n          [0.0016, 0.0028, 0.0014,  ..., 0.0112, 0.0026, 0.0029],\n          [0.0006, 0.0032, 0.0032,  ..., 0.0026, 0.0106, 0.0028],\n          [0.0022, 0.0037, 0.0015,  ..., 0.0029, 0.0028, 0.0091]]),\n  'N': 50},\n 0: {'mu': tensor([0.7925, 0.8394, 0.8311,  ..., 0.8586, 0.9719, 0.8623]),\n  'sigma': tensor([[0.0094, 0.0024, 0.0017,  ..., 0.0047, 0.0044, 0.0062],\n          [0.0024, 0.0079, 0.0004,  ..., 0.0027, 0.0041, 0.0046],\n          [0.0017, 0.0004, 0.0065,  ..., 0.0005, 0.0042, 0.0024],\n          ...,\n          [0.0047, 0.0027, 0.0005,  ..., 0.0116, 0.0022, 0.0014],\n          [0.0044, 0.0041, 0.0042,  ..., 0.0022, 0.0096, 0.0041],\n          [0.0062, 0.0046, 0.0024,  ..., 0.0014, 0.0041, 0.0174]]),\n  'N': 50},\n 1: {'mu': tensor([0.7797, 0.8585, 0.8049,  ..., 0.8269, 0.9608, 0.8149]),\n  'sigma': tensor([[ 9.2847e-03,  2.5588e-03, -6.1865e-05,  ...,  3.2102e-03,\n            2.2103e-03,  4.6425e-03],\n          [ 2.5588e-03,  7.7705e-03,  2.5197e-03,  ...,  2.1689e-03,\n            1.9756e-03,  2.5160e-03],\n          [-6.1865e-05,  2.5197e-03,  7.8867e-03,  ...,  1.0242e-03,\n            3.2535e-03,  2.0132e-03],\n          ...,\n          [ 3.2102e-03,  2.1689e-03,  1.0242e-03,  ...,  1.0016e-02,\n            2.9421e-03,  2.7476e-03],\n          [ 2.2103e-03,  1.9756e-03,  3.2535e-03,  ...,  2.9421e-03,\n            1.4850e-02,  1.9918e-03],\n          [ 4.6425e-03,  2.5160e-03,  2.0132e-03,  ...,  2.7476e-03,\n            1.9918e-03,  1.4760e-02]]),\n  'N': 50},\n 7: {'mu': tensor([0.7731, 0.8270, 0.8194,  ..., 0.8201, 0.9579, 0.8003]),\n  'sigma': tensor([[0.0080, 0.0024, 0.0009,  ..., 0.0028, 0.0008, 0.0047],\n          [0.0024, 0.0097, 0.0028,  ..., 0.0042, 0.0035, 0.0034],\n          [0.0009, 0.0028, 0.0056,  ..., 0.0010, 0.0011, 0.0018],\n          ...,\n          [0.0028, 0.0042, 0.0010,  ..., 0.0091, 0.0043, 0.0032],\n          [0.0008, 0.0035, 0.0011,  ..., 0.0043, 0.0115, 0.0034],\n          [0.0047, 0.0034, 0.0018,  ..., 0.0032, 0.0034, 0.0122]]),\n  'N': 50},\n 3: {'mu': tensor([0.8049, 0.7984, 0.8259,  ..., 0.8454, 0.9798, 0.7934]),\n  'sigma': tensor([[0.0074, 0.0019, 0.0029,  ..., 0.0038, 0.0020, 0.0026],\n          [0.0019, 0.0096, 0.0025,  ..., 0.0037, 0.0062, 0.0021],\n          [0.0029, 0.0025, 0.0083,  ..., 0.0015, 0.0022, 0.0010],\n          ...,\n          [0.0038, 0.0037, 0.0015,  ..., 0.0115, 0.0017, 0.0020],\n          [0.0020, 0.0062, 0.0022,  ..., 0.0017, 0.0153, 0.0009],\n          [0.0026, 0.0021, 0.0010,  ..., 0.0020, 0.0009, 0.0132]]),\n  'N': 50},\n 8: {'mu': tensor([0.7930, 0.8324, 0.8321,  ..., 0.9162, 0.9840, 0.8958]),\n  'sigma': tensor([[ 1.1007e-02,  5.3911e-03,  3.0501e-03,  ...,  4.0405e-04,\n            3.9728e-03,  1.5055e-03],\n          [ 5.3911e-03,  9.3614e-03,  2.3233e-03,  ...,  1.2236e-03,\n            4.3389e-03,  8.7339e-06],\n          [ 3.0501e-03,  2.3233e-03,  5.9765e-03,  ...,  6.4734e-04,\n            3.7069e-03, -8.3899e-04],\n          ...,\n          [ 4.0405e-04,  1.2236e-03,  6.4734e-04,  ...,  9.2277e-03,\n            1.6678e-03, -3.0209e-04],\n          [ 3.9728e-03,  4.3389e-03,  3.7069e-03,  ...,  1.6678e-03,\n            1.3025e-02,  1.6768e-03],\n          [ 1.5055e-03,  8.7339e-06, -8.3899e-04,  ..., -3.0209e-04,\n            1.6768e-03,  1.1132e-02]]),\n  'N': 50},\n 2: {'mu': tensor([0.7792, 0.8134, 0.8086,  ..., 0.8216, 0.9849, 0.8047]),\n  'sigma': tensor([[ 0.0073,  0.0018,  0.0022,  ..., -0.0012,  0.0025,  0.0031],\n          [ 0.0018,  0.0071, -0.0010,  ..., -0.0006,  0.0028,  0.0025],\n          [ 0.0022, -0.0010,  0.0071,  ...,  0.0011,  0.0006,  0.0020],\n          ...,\n          [-0.0012, -0.0006,  0.0011,  ...,  0.0092, -0.0006,  0.0014],\n          [ 0.0025,  0.0028,  0.0006,  ..., -0.0006,  0.0120,  0.0045],\n          [ 0.0031,  0.0025,  0.0020,  ...,  0.0014,  0.0045,  0.0164]]),\n  'N': 50}}"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(upload_d_list))\n",
    "upload_d_list[5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "def server_aggregate_stat(upload_d_list):\n",
    "    # statistical feature distribution for each label\n",
    "    fd_d = {}\n",
    "\n",
    "    for l in range(10):  # for each label\n",
    "\n",
    "        print(\"label : \", l)\n",
    "\n",
    "        # clients do not necessarily have all tags, heterogeneous\n",
    "        labeled_fd_lst = [ x for x in upload_d_list if l in x.keys() ]\n",
    "        sum_n = sum(x[l][\"N\"] for x in labeled_fd_lst)\n",
    "\n",
    "        mu_lst = [fd[l][\"mu\"] * fd[l][\"N\"] / sum_n for fd in labeled_fd_lst]\n",
    "        mu = torch.stack(mu_lst).sum(dim=0)\n",
    "        # print(mu.shape)\n",
    "        #\n",
    "        # sigma1 = torch.stack(\n",
    "        #     [fd[l][\"mu\"] * (fd[l][\"N\"] - 1) / (sum_n - 1) for fd in labeled_fd_lst]\n",
    "        # ).sum(dim=0)\n",
    "        #\n",
    "        # sigma2 = torch.stack(\n",
    "        #     [\n",
    "        #         fd[l][\"mu\"] * fd[l][\"mu\"].T * fd[l][\"N\"] / (sum_n - 1)\n",
    "        #         for fd in labeled_fd_lst\n",
    "        #     ]\n",
    "        # ).sum(dim=0)\n",
    "        #\n",
    "        # sigma = sigma1 + sigma2 - sum_n / (sum_n - 1) * mu * mu.T\n",
    "\n",
    "        sigma1 = torch.stack(\n",
    "            [ (fd[l][\"N\"] - 1) / (sum_n - 1) * fd[l][\"sigma\"] for fd in labeled_fd_lst ]\n",
    "        ).sum(dim=0)\n",
    "        # print(sigma1.shape)\n",
    "\n",
    "        sigma2 = torch.stack(\n",
    "            [\n",
    "                fd[l][\"mu\"].reshape(1, 2048) * torch.transpose(fd[l][\"mu\"].reshape(1, 2048), 1, 0) * fd[l][\"N\"] / (sum_n - 1)\n",
    "                for fd in labeled_fd_lst\n",
    "            ]\n",
    "        ).sum(dim=0)\n",
    "        # print(sigma2.shape)\n",
    "\n",
    "        sigma3 = sum_n / (sum_n - 1) * mu.reshape(1, 2048) * torch.transpose(mu.reshape(1, 2048), 1, 0)\n",
    "        # print(sigma3.shape)\n",
    "\n",
    "        sigma = sigma1 + sigma2 - sigma3\n",
    "        # print(sigma.shape)\n",
    "\n",
    "\n",
    "        virtual_samples = np.random.default_rng().multivariate_normal(mu, sigma, check_valid='ignore', size=1000, tol=1e-6, method='eigh')\n",
    "        fd_d[l] = torch.tensor(virtual_samples)\n",
    "\n",
    "\n",
    "        # generate data samples with batchsize of 1k, there are 10 categories in total, so it is 10k samples\n",
    "        # dist_c = np.random.normal(mu, sigma, size=(1000, mu.size()[0]))\n",
    "        # fd_d[l] = torch.tensor(dist_c)\n",
    "\n",
    "    return fd_d"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# fd_d = {}\n",
    "# for l in range(10):  # for each label\n",
    "#     print(\"label : \", l)\n",
    "#\n",
    "#     # clients do not necessarily have all tags, heterogeneous\n",
    "#     labeled_fd_lst = [ x for x in upload_d_list if l in x.keys() ]\n",
    "#     sum_n = sum(x[l][\"N\"] for x in labeled_fd_lst)\n",
    "#\n",
    "#     mu_lst = [fd[l][\"mu\"] * fd[l][\"N\"] / sum_n for fd in labeled_fd_lst]\n",
    "#     mu = torch.stack(mu_lst).sum(dim=0)\n",
    "#     # print(mu.shape)\n",
    "#\n",
    "#     sigma1 = torch.stack(\n",
    "#         [ (fd[l][\"N\"] - 1) / (sum_n - 1) * fd[l][\"sigma\"] for fd in labeled_fd_lst ]\n",
    "#     ).sum(dim=0)\n",
    "#     # print(sigma1.shape)\n",
    "#\n",
    "#     sigma2 = torch.stack(\n",
    "#         [\n",
    "#             fd[l][\"mu\"].reshape(1, 2048) * torch.transpose(fd[l][\"mu\"].reshape(1, 2048), 1, 0) * fd[l][\"N\"] / (sum_n - 1)\n",
    "#             for fd in labeled_fd_lst\n",
    "#         ]\n",
    "#     ).sum(dim=0)\n",
    "#     # print(sigma2.shape)\n",
    "#\n",
    "#     sigma3 = sum_n / (sum_n - 1) * mu.reshape(1, 2048) * torch.transpose(mu.reshape(1, 2048), 1, 0)\n",
    "#     # print(sigma3.shape)\n",
    "#\n",
    "#     sigma = sigma1 + sigma2 - sum_n / (sum_n - 1) * mu * mu.T\n",
    "#     # print(sigma.shape)\n",
    "#\n",
    "#\n",
    "#     virtual_samples = np.random.default_rng().multivariate_normal(mu, sigma, check_valid='ignore', size=100, tol=1e-6, method='eigh')\n",
    "#     fd_d[l] = torch.tensor(virtual_samples)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label :  0\n",
      "label :  1\n",
      "label :  2\n",
      "label :  3\n"
     ]
    }
   ],
   "source": [
    "fd_d = server_aggregate_stat(upload_d_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for k, v in fd_d.items():\n",
    "#     print(\"label\", k)\n",
    "#     print(v.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filename_pikle = \"CCVR_results/extracted_features_iid[{}]_unbalanced[{}]_.pickle\".format(iid, unbalanced)\n",
    "\n",
    "with open(filename_pikle, 'wb') as handle:\n",
    "    pickle.dump(fd_d, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(filename_pikle, 'rb') as handle:\n",
    "    fd_d = pickle.load(handle)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class DictDataset(Dataset):\n",
    "    def __init__(self, label_data_d):\n",
    "        \"Initialization\"\n",
    "        self.data, self.labels = [], []\n",
    "        for label, data in label_data_d.items():\n",
    "            self.data.append(data)\n",
    "            self.labels.append(torch.tensor([label] * len(data)))\n",
    "\n",
    "        self.data = torch.cat(self.data).type(torch.float32)\n",
    "        self.labels = torch.cat(self.labels).type(torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"Denotes the total number of samples\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"Generates one sample of data\"\n",
    "        return self.data[index], self.labels[index]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_dataloader(trainset, testset, batch_size, num_workers=0, pin_memory=False):\n",
    "    trainloader = DataLoader(\n",
    "        trainset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "    )\n",
    "    testloader = DataLoader(\n",
    "        testset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "    )\n",
    "\n",
    "    return trainloader, testloader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import torch.nn.functional as F\n",
    "#\n",
    "# class classifier(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(classifier, self).__init__()\n",
    "#\n",
    "#         # network ends a 10-way fully-connected layer\n",
    "#         expansion = 4\n",
    "#         num_classes = 10\n",
    "#\n",
    "#         self.linear = nn.Linear(512 * expansion, num_classes)\n",
    "#\n",
    "#     def forward(self, x):\n",
    "#         # out = F.avg_pool2d(x, 4)  # average pooling before fully connected layer\n",
    "#         out = x.view(x.size(0), -1)\n",
    "#         out = self.linear(out)\n",
    "#         return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "g = classifier()\n",
    "g.to(device)\n",
    "summary(g, (2048, 1, 1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# fd_d[0][0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# fd_d[0][0].reshape((2048, 1, 1)).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# x = fd_d[0].reshape((1000, 2048, 1, 1)).type(torch.float).to(device)\n",
    "# x.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# g(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "optimizer = torch.optim.SGD(g.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# prepare datasets, models, optimizers, and more\n",
    "trainset = DictDataset(fd_d)\n",
    "train_loader, _ = get_dataloader(trainset, trainset, batch_size=64)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for epoch in range(1, n_epochs+1):\n",
    "for epoch in range(1, 100):\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    correct_train = 0.0\n",
    "    correct_valid = 0.0\n",
    "\n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    g.train()\n",
    "\n",
    "    for k, v in fd_d.items():\n",
    "\n",
    "        data, target = v.type(torch.float).cuda(), torch.full((1000,), k).cuda()\n",
    "\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = g(data.reshape((1000, 2048, 1, 1)))\n",
    "\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += (loss.data.item() * data.shape[0])\n",
    "        # print('outputs on which to apply torch.max ', prediction)\n",
    "        # find the maximum along the rows, use dim=1 to torch.max()\n",
    "        _, predicted_outputs = torch.max(output.data, 1)\n",
    "        # Update the running corrects\n",
    "        correct_train += (predicted_outputs == target).float().sum().item()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # calculate average losses\n",
    "    train_loss = train_loss / len(train_loader.sampler)\n",
    "    # calculate accuracies\n",
    "    train_acc =  correct_train / len(train_loader.sampler)\n",
    "\n",
    "    print('Epoch: {} \\tTraining Loss: {:.3f} \\tTraining Accuracy: {:.3f}'.format(\n",
    "        epoch, train_loss, train_acc))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test_inference(f, g, test_dataset, gpu=1, local_batch_size=10, loss_function=\"CrossEntropyLoss\"):\n",
    "    \"\"\"\n",
    "    Returns the test accuracy and loss.\n",
    "    \"\"\"\n",
    "\n",
    "    f.eval()\n",
    "    g.eval()\n",
    "\n",
    "    test_loss = 0.0\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "\n",
    "    device = 'cuda' if gpu else 'cpu'\n",
    "    if loss_function == \"NLLLoss\":\n",
    "        criterion = nn.NLLLoss()\n",
    "    if loss_function == \"CrossEntropyLoss\":\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    testloader = DataLoader(test_dataset, batch_size=10,\n",
    "                            shuffle=False, generator=generator)\n",
    "\n",
    "    for images, labels in testloader:\n",
    "    # for k, v in fd_d.items():\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # images, labels = v.type(torch.float).cuda().reshape(1000, 2048, 1, 1), torch.full((1000,), k).cuda()\n",
    "\n",
    "        # Inference\n",
    "        # output_f = f(images)[\"avg_pool2d\"]\n",
    "        output_f = f(images.cuda())\n",
    "        output_g = g(output_f)\n",
    "\n",
    "        loss = criterion(output_g, labels)\n",
    "        test_loss += (loss.data.item() * images.shape[0])\n",
    "\n",
    "        # Prediction\n",
    "        # convert output probabilities to predicted class\n",
    "        _, pred = torch.max(output_g, 1)\n",
    "        # compare predictions to true label\n",
    "        correct_tensor = pred.eq(labels.data.view_as(pred))\n",
    "        correct = np.squeeze(correct_tensor.numpy()) if not gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "\n",
    "        for i in range(len(images)):\n",
    "            label = labels.data[i]\n",
    "            class_correct[label] += correct[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "    # average test loss\n",
    "    test_loss = test_loss / len(testloader.dataset)\n",
    "\n",
    "    accuracy = np.sum(class_correct) / np.sum(class_total)\n",
    "\n",
    "    return accuracy, test_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# test the trained model\n",
    "\n",
    "test_acc, test_loss = test_inference(f, g, test_dataset=test_dataset, gpu=gpu,\n",
    "                                     loss_function=loss_function)\n",
    "\n",
    "print(f'\\nResults after {n_epochs} global rounds of training:')\n",
    "print(\"|---- Test Accuracy: {:.2f}%\".format(100*test_acc))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}