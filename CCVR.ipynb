{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import copy\n",
    "import pickle\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from models import ResNet50\n",
    "from models_CCVR import feature_extractor, classifier\n",
    "from update import LocalUpdate, test_inference"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# parameters\n",
    "iid = 0 # if the data is i.i.d or not\n",
    "unbalanced = 1 # in non i.i.d. setting split the data between clients equally or not\n",
    "num_users = 100 # number of client\n",
    "frac = 0.1 # fraction of the clients to be used for federated updates\n",
    "n_epochs = 100\n",
    "gpu = 0\n",
    "optimizer = \"sgd\" #sgd or adam\n",
    "local_batch_size = 10 # batch size of local updates in each user\n",
    "lr = 0.01 # learning rate\n",
    "local_epochs = 10\n",
    "loss_function = \"CrossEntropyLoss\"\n",
    "\n",
    "# percentage = 90  # percentage of strugglers\n",
    "\n",
    "num_groups = 0  # 0 for BatchNorm, > 0 for GroupNorm\n",
    "if num_groups == 0:\n",
    "    normalization_type = \"BatchNorm\"\n",
    "else:\n",
    "    normalization_type = \"GroupNorm\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "if iid:\n",
    "    from utils_v2 import get_dataset, average_weights, weighted_average_weights, exp_details\n",
    "else:\n",
    "    from utils import get_dataset, average_weights, weighted_average_weights, exp_details"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# for REPRODUCIBILITY https://pytorch.org/docs/stable/notes/randomness.html\n",
    "torch.manual_seed(0)\n",
    "\n",
    "generator = torch.Generator()\n",
    "generator.manual_seed(0)\n",
    "\n",
    "np.random.seed(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class DatasetSplit(Dataset):\n",
    "    \"\"\"\n",
    "    An abstract Dataset class wrapped around Pytorch Dataset class.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, idxs):\n",
    "        self.dataset = dataset\n",
    "        self.idxs = [int(i) for i in idxs]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idxs)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        image, label = self.dataset[self.idxs[item]]\n",
    "        return torch.tensor(image), torch.tensor(label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def get_dataloader(dataset, idxs):\n",
    "    trainloader = DataLoader(DatasetSplit(dataset, idxs),\n",
    "                             batch_size=None, shuffle=True, generator=generator,\n",
    "                             worker_init_fn=seed_worker)\n",
    "\n",
    "    return trainloader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset, user_groups = get_dataset(iid=iid, unbalanced=unbalanced,\n",
    "                                                       num_users=num_users)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n"
     ]
    },
    {
     "data": {
      "text/plain": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n  )\n  (layer3): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n  )\n  (layer4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n  )\n  (linear): Linear(in_features=2048, out_features=10, bias=True)\n)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet50(n_type=normalization_type)\n",
    "# model = CNNCifar()\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "    device = torch.device(\"cpu\")\n",
    "    gpu = 0\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')\n",
    "    device = torch.device(\"cuda\")\n",
    "    gpu = 1\n",
    "\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_pt = \"fedAVG_results/weighted_average/ResNet50_100_sgd_lr_[0.001]_C[0.1]_iid[0]_unbalanced[1]_E[1]_B[10]_BatchNorm_numGroups[0].pt\"\n",
    "\n",
    "\n",
    "# load saved model (i.e. the one with the smallest validation loss)\n",
    "model.load_state_dict(torch.load(filename_pt))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = feature_extractor()\n",
    "f.to(device)\n",
    "\n",
    "f.load_state_dict(torch.load(filename_pt))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# def test_inference(model, test_dataset, gpu=1, local_batch_size=10, loss_function=\"NLLLoss\"):\n",
    "#     \"\"\"\n",
    "#     Returns the test accuracy and loss.\n",
    "#     \"\"\"\n",
    "#\n",
    "#     model.eval()\n",
    "#     test_loss = 0.0\n",
    "#     class_correct = list(0. for i in range(10))\n",
    "#     class_total = list(0. for i in range(10))\n",
    "#\n",
    "#     device = 'cuda' if gpu else 'cpu'\n",
    "#     if loss_function == \"NLLLoss\":\n",
    "#         criterion = nn.NLLLoss()\n",
    "#     if loss_function == \"CrossEntropyLoss\":\n",
    "#         criterion = nn.CrossEntropyLoss()\n",
    "#\n",
    "#     testloader = DataLoader(test_dataset, batch_size=local_batch_size,\n",
    "#                             shuffle=False, generator=generator)\n",
    "#\n",
    "#     for images, labels in testloader:\n",
    "#         images, labels = images.to(device), labels.to(device)\n",
    "#\n",
    "#         # Inference\n",
    "#         output = model(images)\n",
    "#         loss = criterion(output, labels)\n",
    "#         test_loss += (loss.data.item() * images.shape[0])\n",
    "#\n",
    "#         # Prediction\n",
    "#         # convert output probabilities to predicted class\n",
    "#         _, pred = torch.max(output, 1)\n",
    "#         # compare predictions to true label\n",
    "#         correct_tensor = pred.eq(labels.data.view_as(pred))\n",
    "#         correct = np.squeeze(correct_tensor.numpy()) if not gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "#\n",
    "#         for i in range(len(images)):\n",
    "#             label = labels.data[i]\n",
    "#             class_correct[label] += correct[i].item()\n",
    "#             class_total[label] += 1\n",
    "#\n",
    "#     # average test loss\n",
    "#     test_loss = test_loss / len(testloader.dataset)\n",
    "#\n",
    "#     accuracy = np.sum(class_correct) / np.sum(class_total)\n",
    "#\n",
    "#     return accuracy, test_loss\n",
    "#\n",
    "#\n",
    "# # test the trained model\n",
    "#\n",
    "# test_acc, test_loss = test_inference(model=model, test_dataset=test_dataset, gpu=gpu,\n",
    "#                                      loss_function=loss_function)\n",
    "#\n",
    "# print(f'\\nResults after {n_epochs} global rounds of training:')\n",
    "# print(\"|---- Test Accuracy: {:.2f}%\".format(100*test_acc))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# import torch.nn.functional as F\n",
    "#\n",
    "# f = nn.Sequential(\n",
    "#     # stop at conv4\n",
    "#     *list(model.children())[:-1]\n",
    "# )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "            Conv2d-3           [-1, 64, 32, 32]           4,096\n",
      "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
      "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
      "            Conv2d-7          [-1, 256, 32, 32]          16,384\n",
      "       BatchNorm2d-8          [-1, 256, 32, 32]             512\n",
      "            Conv2d-9          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-10          [-1, 256, 32, 32]             512\n",
      "       Bottleneck-11          [-1, 256, 32, 32]               0\n",
      "           Conv2d-12           [-1, 64, 32, 32]          16,384\n",
      "      BatchNorm2d-13           [-1, 64, 32, 32]             128\n",
      "           Conv2d-14           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-15           [-1, 64, 32, 32]             128\n",
      "           Conv2d-16          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-17          [-1, 256, 32, 32]             512\n",
      "       Bottleneck-18          [-1, 256, 32, 32]               0\n",
      "           Conv2d-19           [-1, 64, 32, 32]          16,384\n",
      "      BatchNorm2d-20           [-1, 64, 32, 32]             128\n",
      "           Conv2d-21           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-22           [-1, 64, 32, 32]             128\n",
      "           Conv2d-23          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 32, 32]             512\n",
      "       Bottleneck-25          [-1, 256, 32, 32]               0\n",
      "           Conv2d-26          [-1, 128, 32, 32]          32,768\n",
      "      BatchNorm2d-27          [-1, 128, 32, 32]             256\n",
      "           Conv2d-28          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 16, 16]             256\n",
      "           Conv2d-30          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-31          [-1, 512, 16, 16]           1,024\n",
      "           Conv2d-32          [-1, 512, 16, 16]         131,072\n",
      "      BatchNorm2d-33          [-1, 512, 16, 16]           1,024\n",
      "       Bottleneck-34          [-1, 512, 16, 16]               0\n",
      "           Conv2d-35          [-1, 128, 16, 16]          65,536\n",
      "      BatchNorm2d-36          [-1, 128, 16, 16]             256\n",
      "           Conv2d-37          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-38          [-1, 128, 16, 16]             256\n",
      "           Conv2d-39          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-40          [-1, 512, 16, 16]           1,024\n",
      "       Bottleneck-41          [-1, 512, 16, 16]               0\n",
      "           Conv2d-42          [-1, 128, 16, 16]          65,536\n",
      "      BatchNorm2d-43          [-1, 128, 16, 16]             256\n",
      "           Conv2d-44          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-45          [-1, 128, 16, 16]             256\n",
      "           Conv2d-46          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-47          [-1, 512, 16, 16]           1,024\n",
      "       Bottleneck-48          [-1, 512, 16, 16]               0\n",
      "           Conv2d-49          [-1, 128, 16, 16]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 16, 16]             256\n",
      "           Conv2d-51          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-52          [-1, 128, 16, 16]             256\n",
      "           Conv2d-53          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-54          [-1, 512, 16, 16]           1,024\n",
      "       Bottleneck-55          [-1, 512, 16, 16]               0\n",
      "           Conv2d-56          [-1, 256, 16, 16]         131,072\n",
      "      BatchNorm2d-57          [-1, 256, 16, 16]             512\n",
      "           Conv2d-58            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-59            [-1, 256, 8, 8]             512\n",
      "           Conv2d-60           [-1, 1024, 8, 8]         262,144\n",
      "      BatchNorm2d-61           [-1, 1024, 8, 8]           2,048\n",
      "           Conv2d-62           [-1, 1024, 8, 8]         524,288\n",
      "      BatchNorm2d-63           [-1, 1024, 8, 8]           2,048\n",
      "       Bottleneck-64           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-65            [-1, 256, 8, 8]         262,144\n",
      "      BatchNorm2d-66            [-1, 256, 8, 8]             512\n",
      "           Conv2d-67            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-68            [-1, 256, 8, 8]             512\n",
      "           Conv2d-69           [-1, 1024, 8, 8]         262,144\n",
      "      BatchNorm2d-70           [-1, 1024, 8, 8]           2,048\n",
      "       Bottleneck-71           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-72            [-1, 256, 8, 8]         262,144\n",
      "      BatchNorm2d-73            [-1, 256, 8, 8]             512\n",
      "           Conv2d-74            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-75            [-1, 256, 8, 8]             512\n",
      "           Conv2d-76           [-1, 1024, 8, 8]         262,144\n",
      "      BatchNorm2d-77           [-1, 1024, 8, 8]           2,048\n",
      "       Bottleneck-78           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-79            [-1, 256, 8, 8]         262,144\n",
      "      BatchNorm2d-80            [-1, 256, 8, 8]             512\n",
      "           Conv2d-81            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-82            [-1, 256, 8, 8]             512\n",
      "           Conv2d-83           [-1, 1024, 8, 8]         262,144\n",
      "      BatchNorm2d-84           [-1, 1024, 8, 8]           2,048\n",
      "       Bottleneck-85           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-86            [-1, 256, 8, 8]         262,144\n",
      "      BatchNorm2d-87            [-1, 256, 8, 8]             512\n",
      "           Conv2d-88            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-89            [-1, 256, 8, 8]             512\n",
      "           Conv2d-90           [-1, 1024, 8, 8]         262,144\n",
      "      BatchNorm2d-91           [-1, 1024, 8, 8]           2,048\n",
      "       Bottleneck-92           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-93            [-1, 256, 8, 8]         262,144\n",
      "      BatchNorm2d-94            [-1, 256, 8, 8]             512\n",
      "           Conv2d-95            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-96            [-1, 256, 8, 8]             512\n",
      "           Conv2d-97           [-1, 1024, 8, 8]         262,144\n",
      "      BatchNorm2d-98           [-1, 1024, 8, 8]           2,048\n",
      "       Bottleneck-99           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-100            [-1, 512, 8, 8]         524,288\n",
      "     BatchNorm2d-101            [-1, 512, 8, 8]           1,024\n",
      "          Conv2d-102            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-103            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-104           [-1, 2048, 4, 4]       1,048,576\n",
      "     BatchNorm2d-105           [-1, 2048, 4, 4]           4,096\n",
      "          Conv2d-106           [-1, 2048, 4, 4]       2,097,152\n",
      "     BatchNorm2d-107           [-1, 2048, 4, 4]           4,096\n",
      "      Bottleneck-108           [-1, 2048, 4, 4]               0\n",
      "          Conv2d-109            [-1, 512, 4, 4]       1,048,576\n",
      "     BatchNorm2d-110            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-111            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-112            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-113           [-1, 2048, 4, 4]       1,048,576\n",
      "     BatchNorm2d-114           [-1, 2048, 4, 4]           4,096\n",
      "      Bottleneck-115           [-1, 2048, 4, 4]               0\n",
      "          Conv2d-116            [-1, 512, 4, 4]       1,048,576\n",
      "     BatchNorm2d-117            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-118            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-119            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-120           [-1, 2048, 4, 4]       1,048,576\n",
      "     BatchNorm2d-121           [-1, 2048, 4, 4]           4,096\n",
      "      Bottleneck-122           [-1, 2048, 4, 4]               0\n",
      "================================================================\n",
      "Total params: 23,500,352\n",
      "Trainable params: 23,500,352\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 66.12\n",
      "Params size (MB): 89.65\n",
      "Estimated Total Size (MB): 155.78\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(f, (3, 32, 32))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "            Conv2d-3           [-1, 64, 32, 32]           4,096\n",
      "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
      "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
      "            Conv2d-7          [-1, 256, 32, 32]          16,384\n",
      "       BatchNorm2d-8          [-1, 256, 32, 32]             512\n",
      "            Conv2d-9          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-10          [-1, 256, 32, 32]             512\n",
      "       Bottleneck-11          [-1, 256, 32, 32]               0\n",
      "           Conv2d-12           [-1, 64, 32, 32]          16,384\n",
      "      BatchNorm2d-13           [-1, 64, 32, 32]             128\n",
      "           Conv2d-14           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-15           [-1, 64, 32, 32]             128\n",
      "           Conv2d-16          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-17          [-1, 256, 32, 32]             512\n",
      "       Bottleneck-18          [-1, 256, 32, 32]               0\n",
      "           Conv2d-19           [-1, 64, 32, 32]          16,384\n",
      "      BatchNorm2d-20           [-1, 64, 32, 32]             128\n",
      "           Conv2d-21           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-22           [-1, 64, 32, 32]             128\n",
      "           Conv2d-23          [-1, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 32, 32]             512\n",
      "       Bottleneck-25          [-1, 256, 32, 32]               0\n",
      "           Conv2d-26          [-1, 128, 32, 32]          32,768\n",
      "      BatchNorm2d-27          [-1, 128, 32, 32]             256\n",
      "           Conv2d-28          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 16, 16]             256\n",
      "           Conv2d-30          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-31          [-1, 512, 16, 16]           1,024\n",
      "           Conv2d-32          [-1, 512, 16, 16]         131,072\n",
      "      BatchNorm2d-33          [-1, 512, 16, 16]           1,024\n",
      "       Bottleneck-34          [-1, 512, 16, 16]               0\n",
      "           Conv2d-35          [-1, 128, 16, 16]          65,536\n",
      "      BatchNorm2d-36          [-1, 128, 16, 16]             256\n",
      "           Conv2d-37          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-38          [-1, 128, 16, 16]             256\n",
      "           Conv2d-39          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-40          [-1, 512, 16, 16]           1,024\n",
      "       Bottleneck-41          [-1, 512, 16, 16]               0\n",
      "           Conv2d-42          [-1, 128, 16, 16]          65,536\n",
      "      BatchNorm2d-43          [-1, 128, 16, 16]             256\n",
      "           Conv2d-44          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-45          [-1, 128, 16, 16]             256\n",
      "           Conv2d-46          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-47          [-1, 512, 16, 16]           1,024\n",
      "       Bottleneck-48          [-1, 512, 16, 16]               0\n",
      "           Conv2d-49          [-1, 128, 16, 16]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 16, 16]             256\n",
      "           Conv2d-51          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-52          [-1, 128, 16, 16]             256\n",
      "           Conv2d-53          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-54          [-1, 512, 16, 16]           1,024\n",
      "       Bottleneck-55          [-1, 512, 16, 16]               0\n",
      "           Conv2d-56          [-1, 256, 16, 16]         131,072\n",
      "      BatchNorm2d-57          [-1, 256, 16, 16]             512\n",
      "           Conv2d-58            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-59            [-1, 256, 8, 8]             512\n",
      "           Conv2d-60           [-1, 1024, 8, 8]         262,144\n",
      "      BatchNorm2d-61           [-1, 1024, 8, 8]           2,048\n",
      "           Conv2d-62           [-1, 1024, 8, 8]         524,288\n",
      "      BatchNorm2d-63           [-1, 1024, 8, 8]           2,048\n",
      "       Bottleneck-64           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-65            [-1, 256, 8, 8]         262,144\n",
      "      BatchNorm2d-66            [-1, 256, 8, 8]             512\n",
      "           Conv2d-67            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-68            [-1, 256, 8, 8]             512\n",
      "           Conv2d-69           [-1, 1024, 8, 8]         262,144\n",
      "      BatchNorm2d-70           [-1, 1024, 8, 8]           2,048\n",
      "       Bottleneck-71           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-72            [-1, 256, 8, 8]         262,144\n",
      "      BatchNorm2d-73            [-1, 256, 8, 8]             512\n",
      "           Conv2d-74            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-75            [-1, 256, 8, 8]             512\n",
      "           Conv2d-76           [-1, 1024, 8, 8]         262,144\n",
      "      BatchNorm2d-77           [-1, 1024, 8, 8]           2,048\n",
      "       Bottleneck-78           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-79            [-1, 256, 8, 8]         262,144\n",
      "      BatchNorm2d-80            [-1, 256, 8, 8]             512\n",
      "           Conv2d-81            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-82            [-1, 256, 8, 8]             512\n",
      "           Conv2d-83           [-1, 1024, 8, 8]         262,144\n",
      "      BatchNorm2d-84           [-1, 1024, 8, 8]           2,048\n",
      "       Bottleneck-85           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-86            [-1, 256, 8, 8]         262,144\n",
      "      BatchNorm2d-87            [-1, 256, 8, 8]             512\n",
      "           Conv2d-88            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-89            [-1, 256, 8, 8]             512\n",
      "           Conv2d-90           [-1, 1024, 8, 8]         262,144\n",
      "      BatchNorm2d-91           [-1, 1024, 8, 8]           2,048\n",
      "       Bottleneck-92           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-93            [-1, 256, 8, 8]         262,144\n",
      "      BatchNorm2d-94            [-1, 256, 8, 8]             512\n",
      "           Conv2d-95            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-96            [-1, 256, 8, 8]             512\n",
      "           Conv2d-97           [-1, 1024, 8, 8]         262,144\n",
      "      BatchNorm2d-98           [-1, 1024, 8, 8]           2,048\n",
      "       Bottleneck-99           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-100            [-1, 512, 8, 8]         524,288\n",
      "     BatchNorm2d-101            [-1, 512, 8, 8]           1,024\n",
      "          Conv2d-102            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-103            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-104           [-1, 2048, 4, 4]       1,048,576\n",
      "     BatchNorm2d-105           [-1, 2048, 4, 4]           4,096\n",
      "          Conv2d-106           [-1, 2048, 4, 4]       2,097,152\n",
      "     BatchNorm2d-107           [-1, 2048, 4, 4]           4,096\n",
      "      Bottleneck-108           [-1, 2048, 4, 4]               0\n",
      "          Conv2d-109            [-1, 512, 4, 4]       1,048,576\n",
      "     BatchNorm2d-110            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-111            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-112            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-113           [-1, 2048, 4, 4]       1,048,576\n",
      "     BatchNorm2d-114           [-1, 2048, 4, 4]           4,096\n",
      "      Bottleneck-115           [-1, 2048, 4, 4]               0\n",
      "          Conv2d-116            [-1, 512, 4, 4]       1,048,576\n",
      "     BatchNorm2d-117            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-118            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-119            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-120           [-1, 2048, 4, 4]       1,048,576\n",
      "     BatchNorm2d-121           [-1, 2048, 4, 4]           4,096\n",
      "      Bottleneck-122           [-1, 2048, 4, 4]               0\n",
      "          Linear-123                   [-1, 10]          20,490\n",
      "================================================================\n",
      "Total params: 23,520,842\n",
      "Trainable params: 23,520,842\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 66.13\n",
      "Params size (MB): 89.72\n",
      "Estimated Total Size (MB): 155.86\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (3, 32, 32))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# from torchvision.models.feature_extraction import get_graph_node_names\n",
    "#\n",
    "# train_nodes, eval_nodes = get_graph_node_names(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# return_nodes_featureExtractor = {\n",
    "#     # node_name: user-specified key for output dict\n",
    "#     'layer1.2.relu_2': 'layer1',\n",
    "#     'layer2.3.relu_2': 'layer2',\n",
    "#     'layer3.5.relu_2': 'layer3',\n",
    "#     'layer4.2.relu_2': 'layer4'\n",
    "# }\n",
    "#\n",
    "# return_nodes_Classifier = {\n",
    "#     'avg_pool2d' : 'avg_pool',\n",
    "#     'size' : 'size',\n",
    "#     'view' : 'view',\n",
    "#     'linear' : 'linear'\n",
    "# }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# from torchvision.models.feature_extraction import create_feature_extractor\n",
    "#\n",
    "# f = create_feature_extractor(model, train_return_nodes=train_nodes[:-3], eval_return_nodes=eval_nodes[:-3])\n",
    "# # f = create_feature_extractor(model, return_nodes_featureExtractor)\n",
    "# g = create_feature_extractor(model, return_nodes_Classifier)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# f(torch.rand((1, 3, 32, 32)).to(device))[\"avg_pool2d\"].reshape(-1).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# g(torch.rand((1, 3, 32, 32)).to(device))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def clientUpdate(f, dataset, idxs, device):\n",
    "\n",
    "    trainloader = get_dataloader(dataset, idxs)\n",
    "\n",
    "    d = {}\n",
    "    sum_ = 0\n",
    "\n",
    "    # extract features by category\n",
    "    for batch_idx, (image, label) in enumerate(trainloader):\n",
    "        sum_ += 1\n",
    "\n",
    "        image = image.to(device)\n",
    "        label = int(label.cpu())\n",
    "\n",
    "        # feature = (f(image.reshape(1, 3, 32, 32))[\"avg_pool2d\"].reshape(-1)).cpu().detach()\n",
    "        # feature = (f(image.reshape(1, 3, 32, 32))[\"layer4.2.relu_2\"].reshape(-1)).cpu().detach()\n",
    "        feature = (f(image.reshape(1, 3, 32, 32)).reshape(-1)).cpu().detach()\n",
    "\n",
    "        if label in d.keys():\n",
    "            d[label].append(feature)\n",
    "        else:\n",
    "            d[label] = [feature]\n",
    "\n",
    "    # mu, sigma\n",
    "    upload_d = {}\n",
    "\n",
    "    # for k, v in tqdm.tqdm(d.items()):\n",
    "    #     v_item = torch.stack(v).detach().cpu()\n",
    "    #\n",
    "    #     # consider the case where the sample size is too small to upload\n",
    "    #     if len(v_item) < 10:\n",
    "    #         continue\n",
    "    #\n",
    "    #     mu, sigma = v_item.mean(dim=0), v_item.var(dim=0)\n",
    "    #     upload_d[k] = {\"mu\": mu, \"sigma\": sigma, \"N\": len(v)}\n",
    "\n",
    "    for k, v in tqdm.tqdm(d.items()):\n",
    "        v_item = torch.stack(v).detach().cpu()\n",
    "        # consider the case where the sample size is too small to upload\n",
    "        if len(v_item) < 10:\n",
    "            continue\n",
    "\n",
    "        N = len(v)\n",
    "\n",
    "        mu = v_item.mean(dim=0)\n",
    "\n",
    "        sigma = torch.zeros((2048, 2048))\n",
    "        for t in v_item:\n",
    "            x = (t - mu).reshape(1, 2048)\n",
    "            sigma = torch.add(torch.mul(x, torch.transpose(x, 1, 0)), sigma)\n",
    "        sigma *= 1/(N-1)\n",
    "\n",
    "        upload_d[k] = {\"mu\": mu, \"sigma\": sigma, \"N\": N}\n",
    "\n",
    "    return upload_d"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_34616\\3803027819.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(image), torch.tensor(label)\n",
      "100%|██████████| 6/6 [00:03<00:00,  1.84it/s]\n"
     ]
    }
   ],
   "source": [
    "upload_d = clientUpdate(f, train_dataset, user_groups[0], device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys([0, 6, 3, 9, 5, 2])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload_d.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2048])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload_d[0][\"mu\"].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2048, 2048])"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload_d[0][\"sigma\"].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_34616\\3803027819.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(image), torch.tensor(label)\n",
      "100%|██████████| 6/6 [00:03<00:00,  1.92it/s]\n",
      "100%|██████████| 7/7 [00:03<00:00,  1.87it/s]\n",
      "100%|██████████| 9/9 [00:05<00:00,  1.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.73it/s]\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.95it/s]\n",
      "100%|██████████| 10/10 [00:06<00:00,  1.46it/s]\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.93it/s]\n",
      "100%|██████████| 3/3 [00:03<00:00,  1.15s/it]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.96it/s]\n",
      "100%|██████████| 7/7 [00:04<00:00,  1.49it/s]\n",
      "100%|██████████| 10/10 [00:05<00:00,  1.81it/s]\n",
      "100%|██████████| 7/7 [00:04<00:00,  1.72it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.98it/s]\n",
      "100%|██████████| 7/7 [00:05<00:00,  1.26it/s]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.84it/s]\n",
      "100%|██████████| 10/10 [00:06<00:00,  1.52it/s]\n",
      "100%|██████████| 9/9 [00:06<00:00,  1.42it/s]\n",
      "100%|██████████| 7/7 [00:02<00:00,  2.44it/s]\n",
      "100%|██████████| 9/9 [00:06<00:00,  1.36it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.91it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.36it/s]\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.55it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.26it/s]\n",
      "100%|██████████| 6/6 [00:03<00:00,  1.53it/s]\n",
      "100%|██████████| 9/9 [00:05<00:00,  1.50it/s]\n",
      "100%|██████████| 7/7 [00:04<00:00,  1.52it/s]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.71it/s]\n",
      "100%|██████████| 9/9 [00:05<00:00,  1.52it/s]\n",
      "100%|██████████| 7/7 [00:03<00:00,  2.15it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.51it/s]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.54it/s]\n",
      "100%|██████████| 9/9 [00:05<00:00,  1.75it/s]\n",
      "100%|██████████| 5/5 [00:04<00:00,  1.05it/s]\n",
      "100%|██████████| 7/7 [00:04<00:00,  1.69it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.61it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.50it/s]\n",
      "100%|██████████| 6/6 [00:03<00:00,  1.59it/s]\n",
      "100%|██████████| 7/7 [00:03<00:00,  1.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.12it/s]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.80it/s]\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.99it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.18it/s]\n",
      "100%|██████████| 9/9 [00:04<00:00,  1.89it/s]\n"
     ]
    }
   ],
   "source": [
    "m = max(int(frac * num_users), 1) # number of users to be used for federated updates, at least 1\n",
    "# idxs_users = np.random.choice(range(num_users), m, replace=False) # choose randomly m users\n",
    "\n",
    "idxs_users = range(num_users)\n",
    "\n",
    "upload_d_list = [ clientUpdate(f, train_dataset, user_groups[idx], device) for idx in idxs_users ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(len(upload_d_list))\n",
    "upload_d_list[5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def server_aggregate_stat(upload_d_list):\n",
    "    # statistical feature distribution for each label\n",
    "    fd_d = {}\n",
    "\n",
    "    for l in range(10):  # for each label\n",
    "\n",
    "        print(\"label : \", l)\n",
    "\n",
    "        # clients do not necessarily have all tags, heterogeneous\n",
    "        labeled_fd_lst = [ x for x in upload_d_list if l in x.keys() ]\n",
    "        sum_n = sum(x[l][\"N\"] for x in labeled_fd_lst)\n",
    "\n",
    "        mu_lst = [fd[l][\"mu\"] * fd[l][\"N\"] / sum_n for fd in labeled_fd_lst]\n",
    "        mu = torch.stack(mu_lst).sum(dim=0)\n",
    "        # print(mu.shape)\n",
    "        #\n",
    "        # sigma1 = torch.stack(\n",
    "        #     [fd[l][\"mu\"] * (fd[l][\"N\"] - 1) / (sum_n - 1) for fd in labeled_fd_lst]\n",
    "        # ).sum(dim=0)\n",
    "        #\n",
    "        # sigma2 = torch.stack(\n",
    "        #     [\n",
    "        #         fd[l][\"mu\"] * fd[l][\"mu\"].T * fd[l][\"N\"] / (sum_n - 1)\n",
    "        #         for fd in labeled_fd_lst\n",
    "        #     ]\n",
    "        # ).sum(dim=0)\n",
    "        #\n",
    "        # sigma = sigma1 + sigma2 - sum_n / (sum_n - 1) * mu * mu.T\n",
    "\n",
    "        sigma1 = torch.stack(\n",
    "            [ (fd[l][\"N\"] - 1) / (sum_n - 1) * fd[l][\"sigma\"] for fd in labeled_fd_lst ]\n",
    "        ).sum(dim=0)\n",
    "        # print(sigma1.shape)\n",
    "\n",
    "        sigma2 = torch.stack(\n",
    "            [\n",
    "                fd[l][\"mu\"].reshape(1, 2048) * torch.transpose(fd[l][\"mu\"].reshape(1, 2048), 1, 0) * fd[l][\"N\"] / (sum_n - 1)\n",
    "                for fd in labeled_fd_lst\n",
    "            ]\n",
    "        ).sum(dim=0)\n",
    "        # print(sigma2.shape)\n",
    "\n",
    "        sigma3 = sum_n / (sum_n - 1) * mu.reshape(1, 2048) * torch.transpose(mu.reshape(1, 2048), 1, 0)\n",
    "        # print(sigma3.shape)\n",
    "\n",
    "        sigma = sigma1 + sigma2 - sigma3\n",
    "        # print(sigma.shape)\n",
    "\n",
    "\n",
    "        virtual_samples = np.random.default_rng().multivariate_normal(mu, sigma, check_valid='ignore', size=1000, tol=1e-6, method='eigh')\n",
    "        fd_d[l] = torch.tensor(virtual_samples)\n",
    "\n",
    "\n",
    "        # generate data samples with batchsize of 1k, there are 10 categories in total, so it is 10k samples\n",
    "        # dist_c = np.random.normal(mu, sigma, size=(1000, mu.size()[0]))\n",
    "        # fd_d[l] = torch.tensor(dist_c)\n",
    "\n",
    "    return fd_d"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# fd_d = {}\n",
    "# for l in range(10):  # for each label\n",
    "#     print(\"label : \", l)\n",
    "#\n",
    "#     # clients do not necessarily have all tags, heterogeneous\n",
    "#     labeled_fd_lst = [ x for x in upload_d_list if l in x.keys() ]\n",
    "#     sum_n = sum(x[l][\"N\"] for x in labeled_fd_lst)\n",
    "#\n",
    "#     mu_lst = [fd[l][\"mu\"] * fd[l][\"N\"] / sum_n for fd in labeled_fd_lst]\n",
    "#     mu = torch.stack(mu_lst).sum(dim=0)\n",
    "#     # print(mu.shape)\n",
    "#\n",
    "#     sigma1 = torch.stack(\n",
    "#         [ (fd[l][\"N\"] - 1) / (sum_n - 1) * fd[l][\"sigma\"] for fd in labeled_fd_lst ]\n",
    "#     ).sum(dim=0)\n",
    "#     # print(sigma1.shape)\n",
    "#\n",
    "#     sigma2 = torch.stack(\n",
    "#         [\n",
    "#             fd[l][\"mu\"].reshape(1, 2048) * torch.transpose(fd[l][\"mu\"].reshape(1, 2048), 1, 0) * fd[l][\"N\"] / (sum_n - 1)\n",
    "#             for fd in labeled_fd_lst\n",
    "#         ]\n",
    "#     ).sum(dim=0)\n",
    "#     # print(sigma2.shape)\n",
    "#\n",
    "#     sigma3 = sum_n / (sum_n - 1) * mu.reshape(1, 2048) * torch.transpose(mu.reshape(1, 2048), 1, 0)\n",
    "#     # print(sigma3.shape)\n",
    "#\n",
    "#     sigma = sigma1 + sigma2 - sum_n / (sum_n - 1) * mu * mu.T\n",
    "#     # print(sigma.shape)\n",
    "#\n",
    "#\n",
    "#     virtual_samples = np.random.default_rng().multivariate_normal(mu, sigma, check_valid='ignore', size=100, tol=1e-6, method='eigh')\n",
    "#     fd_d[l] = torch.tensor(virtual_samples)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fd_d = server_aggregate_stat(upload_d_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for k, v in fd_d.items():\n",
    "#     print(\"label\", k)\n",
    "#     print(v.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('CCVR_results/extracted_features.pickle', 'wb') as handle:\n",
    "    pickle.dump(fd_d, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('fCCVR_results/extracted_features.pickle', 'rb') as handle:\n",
    "    fd_d = pickle.load(handle)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class DictDataset(Dataset):\n",
    "    def __init__(self, label_data_d):\n",
    "        \"Initialization\"\n",
    "        self.data, self.labels = [], []\n",
    "        for label, data in label_data_d.items():\n",
    "            self.data.append(data)\n",
    "            self.labels.append(torch.tensor([label] * len(data)))\n",
    "\n",
    "        self.data = torch.cat(self.data).type(torch.float32)\n",
    "        self.labels = torch.cat(self.labels).type(torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"Denotes the total number of samples\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"Generates one sample of data\"\n",
    "        return self.data[index], self.labels[index]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_dataloader(trainset, testset, batch_size, num_workers=0, pin_memory=False):\n",
    "    trainloader = DataLoader(\n",
    "        trainset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "    )\n",
    "    testloader = DataLoader(\n",
    "        testset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "    )\n",
    "\n",
    "    return trainloader, testloader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import torch.nn.functional as F\n",
    "#\n",
    "# class classifier(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(classifier, self).__init__()\n",
    "#\n",
    "#         # network ends a 10-way fully-connected layer\n",
    "#         expansion = 4\n",
    "#         num_classes = 10\n",
    "#\n",
    "#         self.linear = nn.Linear(512 * expansion, num_classes)\n",
    "#\n",
    "#     def forward(self, x):\n",
    "#         # out = F.avg_pool2d(x, 4)  # average pooling before fully connected layer\n",
    "#         out = x.view(x.size(0), -1)\n",
    "#         out = self.linear(out)\n",
    "#         return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "g = classifier()\n",
    "g.to(device)\n",
    "summary(g, (2048, 1, 1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# fd_d[0][0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# fd_d[0][0].reshape((2048, 1, 1)).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# x = fd_d[0].reshape((1000, 2048, 1, 1)).type(torch.float).to(device)\n",
    "# x.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# g(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  1\n",
      "epoch :  2\n",
      "epoch :  3\n",
      "epoch :  4\n"
     ]
    }
   ],
   "source": [
    "# prepare datasets, models, optimizers, and more\n",
    "trainset = DictDataset(fd_d)\n",
    "train_loader, _ = get_dataloader(trainset, trainset, batch_size=64)\n",
    "\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "optimizer = torch.optim.SGD(g.parameters(), lr=lr, momentum=0.9, weight_decay=0.05)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# for epoch in range(1, n_epochs+1):\n",
    "for epoch in range(1, 100):\n",
    "\n",
    "    print(\"epoch : \", epoch)\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    correct_train = 0.0\n",
    "    correct_valid = 0.0\n",
    "\n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    g.train()\n",
    "\n",
    "    for k, v in fd_d.items():\n",
    "\n",
    "        data, target = v.type(torch.float).cuda(), torch.full((1000,), k).cuda()\n",
    "\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = g(data.reshape((1000, 2048, 1, 1)))\n",
    "\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += (loss.data.item() * data.shape[0])\n",
    "        # print('outputs on which to apply torch.max ', prediction)\n",
    "        # find the maximum along the rows, use dim=1 to torch.max()\n",
    "        _, predicted_outputs = torch.max(output.data, 1)\n",
    "        # Update the running corrects\n",
    "        correct_train += (predicted_outputs == target).float().sum().item()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "def test_inference(f, g, test_dataset, gpu=1, local_batch_size=10, loss_function=\"CrossEntropyLoss\"):\n",
    "    \"\"\"\n",
    "    Returns the test accuracy and loss.\n",
    "    \"\"\"\n",
    "\n",
    "    f.eval()\n",
    "    g.eval()\n",
    "\n",
    "    test_loss = 0.0\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "\n",
    "    device = 'cuda' if gpu else 'cpu'\n",
    "    if loss_function == \"NLLLoss\":\n",
    "        criterion = nn.NLLLoss()\n",
    "    if loss_function == \"CrossEntropyLoss\":\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    testloader = DataLoader(test_dataset, batch_size=10,\n",
    "                            shuffle=False, generator=generator)\n",
    "\n",
    "    for images, labels in testloader:\n",
    "    # for k, v in fd_d.items():\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # images, labels = v.type(torch.float).cuda().reshape(1000, 2048, 1, 1), torch.full((1000,), k).cuda()\n",
    "\n",
    "        # Inference\n",
    "        # output_f = f(images)[\"avg_pool2d\"]\n",
    "        output_f = f(images)\n",
    "        output_g = g(output_f)\n",
    "\n",
    "        loss = criterion(output_g, labels)\n",
    "        test_loss += (loss.data.item() * images.shape[0])\n",
    "\n",
    "        # Prediction\n",
    "        # convert output probabilities to predicted class\n",
    "        _, pred = torch.max(output_g, 1)\n",
    "        # compare predictions to true label\n",
    "        correct_tensor = pred.eq(labels.data.view_as(pred))\n",
    "        correct = np.squeeze(correct_tensor.numpy()) if not gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "\n",
    "        for i in range(len(images)):\n",
    "            label = labels.data[i]\n",
    "            class_correct[label] += correct[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "    # average test loss\n",
    "    test_loss = test_loss / len(testloader.dataset)\n",
    "\n",
    "    accuracy = np.sum(class_correct) / np.sum(class_total)\n",
    "\n",
    "    return accuracy, test_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results after 100 global rounds of training:\n",
      "|---- Test Accuracy: 9.99%\n"
     ]
    }
   ],
   "source": [
    "# test the trained model\n",
    "\n",
    "test_acc, test_loss = test_inference(f, g, test_dataset=test_dataset, gpu=gpu,\n",
    "                                     loss_function=loss_function)\n",
    "\n",
    "print(f'\\nResults after {n_epochs} global rounds of training:')\n",
    "print(\"|---- Test Accuracy: {:.2f}%\".format(100*test_acc))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}