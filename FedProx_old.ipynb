{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from models import ResNet50\n",
    "# from utils import get_dataset, average_weights, exp_details\n",
    "# from utils_v2 import get_dataset, average_weights, exp_details\n",
    "from update import LocalUpdate, test_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# parameters\n",
    "iid = 0 # if the data is i.i.d or not\n",
    "unbalanced = 1 # in non i.i.d. setting split the data between clients equally or not\n",
    "num_users = 100 # number of client\n",
    "frac = 0.1 # fraction of the clients to be used for federated updates\n",
    "n_epochs = 100\n",
    "gpu = 0\n",
    "optimizer = \"sgd\" #sgd or adam\n",
    "local_batch_size = 10 # batch size of local updates in each user\n",
    "lr = 0.001 # learning rate\n",
    "local_epochs = 1\n",
    "loss_function = \"CrossEntropyLoss\"\n",
    "\n",
    "num_groups = 4  # 0 for BatchNorm, > 0 for GroupNorm\n",
    "if num_groups == 0:\n",
    "    normalization_type = \"BatchNorm\"\n",
    "else:\n",
    "    normalization_type = \"GroupNorm\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "if iid:\n",
    "    from utils_v2 import get_dataset, average_weights, weighted_average_weights, exp_details\n",
    "else:\n",
    "    from utils import get_dataset, average_weights, weighted_average_weights, exp_details"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experimental details:\n",
      "    Model     : ResNet50\n",
      "    Optimizer : sgd\n",
      "    Learning  : 0.001\n",
      "    Normalization  : GroupNorm\n",
      "    Global Rounds   : 100\n",
      "\n",
      "    Federated parameters:\n",
      "    Non-IID - unbalanced\n",
      "    NUmber of users  : 100\n",
      "    Fraction of users  : 0.1\n",
      "    Local Batch size   : 10\n",
      "    Local Epochs       : 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exp_details(\"ResNet50\", optimizer, lr, normalization_type, n_epochs, iid, frac,\n",
    "            local_batch_size, local_epochs, unbalanced, num_users)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# for REPRODUCIBILITY https://pytorch.org/docs/stable/notes/randomness.html\n",
    "torch.manual_seed(0)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)\n",
    "\n",
    "np.random.seed(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset, user_groups = get_dataset(iid=iid, unbalanced=unbalanced,\n",
    "                                                       num_users=num_users)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n"
     ]
    },
    {
     "data": {
      "text/plain": "ResNet(\n  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=64, out_features=10, bias=True)\n)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet50(n_type=normalization_type)\n",
    "# model = CNNCifar()\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "    device = torch.device(\"cpu\")\n",
    "    gpu = 0\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')\n",
    "    device = torch.device(\"cuda\")\n",
    "    gpu = 1\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# set the model to train\n",
    "model.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "clients = []\n",
    "\n",
    "idxs_users = range(num_users)\n",
    "\n",
    "# init all clients\n",
    "for idx in idxs_users:\n",
    "    clients.append(copy.deepcopy(model))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (1735952895.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Input \u001B[1;32mIn [9]\u001B[1;36m\u001B[0m\n\u001B[1;33m    for old_params, new_params in zip(clients[idx].parameters(), model.parameters())\u001B[0m\n\u001B[1;37m                                                                                    ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs+1):\n",
    "\n",
    "    print(f'Epoch: {epoch} \\n')\n",
    "\n",
    "    m = max(int(frac * num_users), 1) # number of users to be used for federated updates, at least 1\n",
    "    idxs_chosen_users = np.random.choice(range(num_users), m, replace=False) # choose randomly m users\n",
    "\n",
    "    # dispatch\n",
    "    for idx in idxs_chosen_users:\n",
    "        for old_params, new_params in zip(clients[idx].parameters(), model.parameters())\n",
    "            old_params.data = new_params.data.clone()\n",
    "\n",
    "    # clients update\n",
    "    for idx in idxs_chosen_users:\n",
    "        clients[idx] = train(clients[idx], model, epoch)\n",
    "\n",
    "    # aggregation\n",
    "    s = 0\n",
    "    for idx in idxs_chosen_users:\n",
    "        s += clients[idx].len\n",
    "\n",
    "    params = {}\n",
    "    for k, v in clients[0].named_parameters():\n",
    "        params[k] = torch.zeros_like(v.data)\n",
    "\n",
    "    for idx in idxs_chosen_users:\n",
    "        for k, v in clients[idx].named_parameters():\n",
    "            params[k] += v.data * (clients[idx].len / s)\n",
    "\n",
    "    for k, v in model.named_parameters():\n",
    "        v.data = params[k].data.clone()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}