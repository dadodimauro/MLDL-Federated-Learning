{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import trange\n",
    "\n",
    "from models import ResNet50\n",
    "from SCAFFOLD_update import SCAFFOLDTrainer\n",
    "\n",
    "from fedlab.utils.serialization import SerializationTool"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "iid = 1 # if the data is i.i.d or not\n",
    "unbalanced = 0 # in non i.i.d. setting split the data between clients equally or not\n",
    "num_users = 20 # number of client\n",
    "frac = 0.5 # fraction of the clients to be used for federated updates\n",
    "n_epochs = 20\n",
    "gpu = 0\n",
    "optimizer = \"sgd\" #sgd or adam\n",
    "local_batch_size = 10 # batch size of local updates in each user\n",
    "lr = 0.001 # learning rate\n",
    "local_epochs = 1\n",
    "loss_function = \"CrossEntropyLoss\"\n",
    "\n",
    "num_groups = 0  # 0 for BatchNorm, > 0 for GroupNorm\n",
    "if num_groups == 0:\n",
    "    normalization_type = \"BatchNorm\"\n",
    "else:\n",
    "    normalization_type = \"GroupNorm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "if iid:\n",
    "    from utils_v2 import get_dataset, average_weights, weighted_average_weights, exp_details\n",
    "else:\n",
    "    from utils import get_dataset, average_weights, weighted_average_weights, exp_details"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experimental details:\n",
      "    Model     : ResNet50\n",
      "    Optimizer : sgd\n",
      "    Learning  : 0.001\n",
      "    Normalization  : BatchNorm\n",
      "    Global Rounds   : 20\n",
      "\n",
      "    Federated parameters:\n",
      "    IID\n",
      "    NUmber of users  : 20\n",
      "    Fraction of users  : 0.5\n",
      "    Local Batch size   : 10\n",
      "    Local Epochs       : 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exp_details(\"ResNet50\", optimizer, lr, normalization_type, n_epochs, iid, frac,\n",
    "            local_batch_size, local_epochs, unbalanced, num_users)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# for REPRODUCIBILITY https://pytorch.org/docs/stable/notes/randomness.html\n",
    "torch.manual_seed(0)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)\n",
    "\n",
    "np.random.seed(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n"
     ]
    },
    {
     "data": {
      "text/plain": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n  )\n  (layer3): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n  )\n  (layer4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n  )\n  (linear): Linear(in_features=2048, out_features=10, bias=True)\n)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet50(n_type=normalization_type)\n",
    "# model = CNNCifar()\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "    device = torch.device(\"cpu\")\n",
    "    gpu = 0\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')\n",
    "    device = torch.device(\"cuda\")\n",
    "    gpu = 1\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# set the model to train\n",
    "model.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset, user_groups = get_dataset(iid=iid, unbalanced=unbalanced,\n",
    "                                                       num_users=num_users)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "# ???\n",
    "c_global = [\n",
    "    torch.zeros_like(param, device=device)\n",
    "    for param in model.parameters()\n",
    "    if param.requires_grad\n",
    "]\n",
    "\n",
    "client_list = [\n",
    "    SCAFFOLDTrainer(\n",
    "        id=idx,\n",
    "        global_model=deepcopy(model),\n",
    "        train_dataset=train_dataset,\n",
    "        test_dataset=test_dataset,\n",
    "        batch_size=local_batch_size,\n",
    "        idxs=user_groups[idx],\n",
    "        lr=lr,\n",
    "        epochs=local_epochs,\n",
    "        gpu=gpu\n",
    "    )\n",
    "    for idx in range(num_users)\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[1;33mtraining epoch\u001B[0m:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;34mselected clients in round [0]: [ 3 19 16  0 13  6 15 17  4 12]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "client [3]:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[AC:\\Users\\david\\OneDrive - Politecnico di Torino\\PoliTO\\MASTER\\MACHINE LEARNING AND DEEP LEARNING\\MLDL Federated Learning\\SCAFFOLD_update.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(image), torch.tensor(label)\n",
      "\n",
      "client [3]: 100%|██████████| 1/1 [00:01<00:00,  1.78s/it]\u001B[A\n",
      "\n",
      "client [19]: 100%|██████████| 1/1 [00:00<00:00, 13.92it/s]\n",
      "\n",
      "client [16]:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "client [16]: 100%|██████████| 1/1 [00:00<00:00,  8.64it/s]\u001B[A\n",
      "\n",
      "client [0]: 100%|██████████| 1/1 [00:00<00:00, 10.78it/s]\n",
      "\n",
      "client [13]: 100%|██████████| 1/1 [00:00<00:00, 16.71it/s]\n",
      "\n",
      "client [6]: 100%|██████████| 1/1 [00:00<00:00, 20.89it/s]\n",
      "\n",
      "client [15]:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "client [15]: 100%|██████████| 1/1 [00:00<00:00,  7.83it/s]\u001B[A\n",
      "\n",
      "client [17]: 100%|██████████| 1/1 [00:00<00:00, 10.23it/s]\n",
      "\n",
      "client [4]: 100%|██████████| 1/1 [00:00<00:00, 18.23it/s]\n",
      "\n",
      "client [12]: 100%|██████████| 1/1 [00:00<00:00, 21.80it/s]\n",
      "\u001B[1;33mtraining epoch\u001B[0m:   5%|▌         | 1/20 [00:03<01:09,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;34mselected clients in round [1]: [ 4  8  7  9  1  5 16 15  6 18]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "client [4]: 100%|██████████| 1/1 [00:00<00:00, 18.92it/s]\n",
      "\n",
      "client [8]: 100%|██████████| 1/1 [00:00<00:00, 22.28it/s]\n",
      "\n",
      "client [7]: 100%|██████████| 1/1 [00:00<00:00, 22.79it/s]\n",
      "\n",
      "client [9]: 100%|██████████| 1/1 [00:00<00:00, 20.47it/s]\n",
      "\n",
      "client [1]: 100%|██████████| 1/1 [00:00<00:00, 22.79it/s]\n",
      "\n",
      "client [5]: 100%|██████████| 1/1 [00:00<00:00, 20.88it/s]\n",
      "\n",
      "client [16]: 100%|██████████| 1/1 [00:00<00:00, 22.79it/s]\n",
      "\n",
      "client [15]: 100%|██████████| 1/1 [00:00<00:00, 21.80it/s]\n",
      "\n",
      "client [6]: 100%|██████████| 1/1 [00:00<00:00, 22.79it/s]\n",
      "\n",
      "client [18]: 100%|██████████| 1/1 [00:00<00:00, 23.33it/s]\n",
      "\u001B[1;33mtraining epoch\u001B[0m:  10%|█         | 2/20 [00:05<00:42,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;34mselected clients in round [2]: [ 6 15 14 11  7  3  5 13  4  2]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "client [6]: 100%|██████████| 1/1 [00:00<00:00, 18.92it/s]\n",
      "\n",
      "client [15]: 100%|██████████| 1/1 [00:00<00:00, 21.80it/s]\n",
      "\n",
      "client [14]: 100%|██████████| 1/1 [00:00<00:00, 21.33it/s]\n",
      "\n",
      "client [11]: 100%|██████████| 1/1 [00:00<00:00, 20.46it/s]\n",
      "\n",
      "client [7]: 100%|██████████| 1/1 [00:00<00:00, 19.66it/s]\n",
      "\n",
      "client [3]: 100%|██████████| 1/1 [00:00<00:00, 21.80it/s]\n",
      "\n",
      "client [5]: 100%|██████████| 1/1 [00:00<00:00, 20.05it/s]\n",
      "\n",
      "client [13]: 100%|██████████| 1/1 [00:00<00:00, 22.79it/s]\n",
      "\n",
      "client [4]: 100%|██████████| 1/1 [00:00<00:00, 20.05it/s]\n",
      "\n",
      "client [2]: 100%|██████████| 1/1 [00:00<00:00, 19.66it/s]\n",
      "\u001B[1;33mtraining epoch\u001B[0m:  15%|█▌        | 3/20 [00:06<00:33,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;34mselected clients in round [3]: [ 6 19  1  2  3  9  0 12  7 14]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "client [6]: 100%|██████████| 1/1 [00:00<00:00, 21.80it/s]\n",
      "\n",
      "client [19]: 100%|██████████| 1/1 [00:00<00:00, 20.46it/s]\n",
      "\n",
      "client [1]: 100%|██████████| 1/1 [00:00<00:00, 21.80it/s]\n",
      "\n",
      "client [2]: 100%|██████████| 1/1 [00:00<00:00, 22.28it/s]\n",
      "\n",
      "client [3]: 100%|██████████| 1/1 [00:00<00:00, 22.28it/s]\n",
      "\n",
      "client [9]: 100%|██████████| 1/1 [00:00<00:00, 19.66it/s]\n",
      "\n",
      "client [0]: 100%|██████████| 1/1 [00:00<00:00, 21.80it/s]\n",
      "\n",
      "client [12]: 100%|██████████| 1/1 [00:00<00:00, 20.89it/s]\n",
      "\n",
      "client [7]: 100%|██████████| 1/1 [00:00<00:00, 22.81it/s]\n",
      "\n",
      "client [14]: 100%|██████████| 1/1 [00:00<00:00, 21.80it/s]\n",
      "\u001B[1;33mtraining epoch\u001B[0m:  20%|██        | 4/20 [00:08<00:27,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;34mselected clients in round [4]: [ 1  4 16 14 13  0 15 10 18  9]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "client [1]: 100%|██████████| 1/1 [00:00<00:00, 23.33it/s]\n",
      "\n",
      "client [4]: 100%|██████████| 1/1 [00:00<00:00, 22.79it/s]\n",
      "\n",
      "client [16]: 100%|██████████| 1/1 [00:00<00:00, 20.05it/s]\n",
      "\n",
      "client [14]: 100%|██████████| 1/1 [00:00<00:00, 20.89it/s]\n",
      "\n",
      "client [13]: 100%|██████████| 1/1 [00:00<00:00, 21.80it/s]\n",
      "\n",
      "client [0]: 100%|██████████| 1/1 [00:00<00:00, 22.79it/s]\n",
      "\n",
      "client [15]: 100%|██████████| 1/1 [00:00<00:00, 22.28it/s]\n",
      "\n",
      "client [10]: 100%|██████████| 1/1 [00:00<00:00, 19.66it/s]\n",
      "\n",
      "client [18]: 100%|██████████| 1/1 [00:00<00:00, 22.79it/s]\n",
      "\n",
      "client [9]: 100%|██████████| 1/1 [00:00<00:00, 22.29it/s]\n",
      "\u001B[1;33mtraining epoch\u001B[0m:  25%|██▌       | 5/20 [00:09<00:24,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;34mselected clients in round [5]: [ 8 19  5 13  2 14  3  1 11 16]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "client [8]: 100%|██████████| 1/1 [00:00<00:00, 21.33it/s]\n",
      "\n",
      "client [19]: 100%|██████████| 1/1 [00:00<00:00, 23.30it/s]\n",
      "\n",
      "client [5]: 100%|██████████| 1/1 [00:00<00:00, 23.33it/s]\n",
      "\n",
      "client [13]: 100%|██████████| 1/1 [00:00<00:00, 23.32it/s]\n",
      "\n",
      "client [2]: 100%|██████████| 1/1 [00:00<00:00, 21.34it/s]\n",
      "\n",
      "client [14]: 100%|██████████| 1/1 [00:00<00:00, 22.77it/s]\n",
      "\n",
      "client [3]: 100%|██████████| 1/1 [00:00<00:00, 23.33it/s]\n",
      "\n",
      "client [1]: 100%|██████████| 1/1 [00:00<00:00, 20.47it/s]\n",
      "\n",
      "client [11]: 100%|██████████| 1/1 [00:00<00:00, 22.79it/s]\n",
      "\n",
      "client [16]: 100%|██████████| 1/1 [00:00<00:00, 22.27it/s]\n",
      "\u001B[1;33mtraining epoch\u001B[0m:  30%|███       | 6/20 [00:10<00:21,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;34mselected clients in round [6]: [ 9 18  7  1  6  5  3 11  0  4]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "client [9]: 100%|██████████| 1/1 [00:00<00:00, 23.32it/s]\n",
      "\n",
      "client [18]: 100%|██████████| 1/1 [00:00<00:00, 22.79it/s]\n",
      "\n",
      "client [7]: 100%|██████████| 1/1 [00:00<00:00, 21.80it/s]\n",
      "\n",
      "client [1]: 100%|██████████| 1/1 [00:00<00:00, 22.79it/s]\n",
      "\n",
      "client [6]: 100%|██████████| 1/1 [00:00<00:00, 22.78it/s]\n",
      "\n",
      "client [5]: 100%|██████████| 1/1 [00:00<00:00, 22.28it/s]\n",
      "\n",
      "client [3]: 100%|██████████| 1/1 [00:00<00:00, 22.78it/s]\n",
      "\n",
      "client [11]: 100%|██████████| 1/1 [00:00<00:00, 23.30it/s]\n",
      "\n",
      "client [0]: 100%|██████████| 1/1 [00:00<00:00, 19.66it/s]\n",
      "\n",
      "client [4]: 100%|██████████| 1/1 [00:00<00:00, 18.57it/s]\n",
      "\u001B[1;33mtraining epoch\u001B[0m:  35%|███▌      | 7/20 [00:12<00:19,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;34mselected clients in round [7]: [19 16  6 17  4  1  2 13 18  7]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "client [19]: 100%|██████████| 1/1 [00:00<00:00, 21.80it/s]\n",
      "\n",
      "client [16]: 100%|██████████| 1/1 [00:00<00:00, 19.66it/s]\n",
      "\n",
      "client [6]: 100%|██████████| 1/1 [00:00<00:00, 21.33it/s]\n",
      "\n",
      "client [17]: 100%|██████████| 1/1 [00:00<00:00, 21.80it/s]\n",
      "\n",
      "client [4]: 100%|██████████| 1/1 [00:00<00:00, 21.80it/s]\n",
      "\n",
      "client [1]: 100%|██████████| 1/1 [00:00<00:00, 20.05it/s]\n",
      "\n",
      "client [2]: 100%|██████████| 1/1 [00:00<00:00, 21.33it/s]\n",
      "\n",
      "client [13]: 100%|██████████| 1/1 [00:00<00:00, 20.46it/s]\n",
      "\n",
      "client [18]: 100%|██████████| 1/1 [00:00<00:00, 20.05it/s]\n",
      "\n",
      "client [7]: 100%|██████████| 1/1 [00:00<00:00, 21.80it/s]\n",
      "\u001B[1;33mtraining epoch\u001B[0m:  40%|████      | 8/20 [00:13<00:17,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;34mselected clients in round [8]: [13 16 14 19 15  7  0 12  3  2]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "client [13]: 100%|██████████| 1/1 [00:00<00:00, 20.89it/s]\n",
      "\n",
      "client [16]: 100%|██████████| 1/1 [00:00<00:00, 23.32it/s]\n",
      "\n",
      "client [14]: 100%|██████████| 1/1 [00:00<00:00, 22.30it/s]\n",
      "\n",
      "client [19]: 100%|██████████| 1/1 [00:00<00:00, 23.87it/s]\n",
      "\n",
      "client [15]: 100%|██████████| 1/1 [00:00<00:00, 23.32it/s]\n",
      "\n",
      "client [7]: 100%|██████████| 1/1 [00:00<00:00, 21.32it/s]\n",
      "\n",
      "client [0]: 100%|██████████| 1/1 [00:00<00:00, 23.32it/s]\n",
      "\n",
      "client [12]: 100%|██████████| 1/1 [00:00<00:00, 23.87it/s]\n",
      "\n",
      "client [3]: 100%|██████████| 1/1 [00:00<00:00, 23.32it/s]\n",
      "\n",
      "client [2]: 100%|██████████| 1/1 [00:00<00:00, 22.80it/s]\n",
      "\u001B[1;33mtraining epoch\u001B[0m:  45%|████▌     | 9/20 [00:15<00:16,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;34mselected clients in round [9]: [11 15  2  5  3 18 16  9  6  4]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "client [11]: 100%|██████████| 1/1 [00:00<00:00, 18.92it/s]\n",
      "\n",
      "client [15]: 100%|██████████| 1/1 [00:00<00:00, 22.30it/s]\n",
      "\n",
      "client [2]: 100%|██████████| 1/1 [00:00<00:00, 21.80it/s]\n",
      "\n",
      "client [5]: 100%|██████████| 1/1 [00:00<00:00, 21.34it/s]\n",
      "\n",
      "client [3]: 100%|██████████| 1/1 [00:00<00:00, 22.79it/s]\n",
      "\n",
      "client [18]: 100%|██████████| 1/1 [00:00<00:00, 22.79it/s]\n",
      "\n",
      "client [16]: 100%|██████████| 1/1 [00:00<00:00, 21.33it/s]\n",
      "\n",
      "client [9]: 100%|██████████| 1/1 [00:00<00:00, 22.79it/s]\n",
      "\n",
      "client [6]: 100%|██████████| 1/1 [00:00<00:00, 22.79it/s]\n",
      "\n",
      "client [4]: 100%|██████████| 1/1 [00:00<00:00, 21.33it/s]\n",
      "\u001B[1;33mtraining epoch\u001B[0m:  50%|█████     | 10/20 [00:16<00:14,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;34mselected clients in round [10]: [11  1 14  3 15 18 13  8 19  0]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "client [11]: 100%|██████████| 1/1 [00:00<00:00, 21.33it/s]\n",
      "\n",
      "client [1]: 100%|██████████| 1/1 [00:00<00:00, 22.27it/s]\n",
      "\n",
      "client [14]: 100%|██████████| 1/1 [00:00<00:00, 23.87it/s]\n",
      "\n",
      "client [3]: 100%|██████████| 1/1 [00:00<00:00, 23.33it/s]\n",
      "\n",
      "client [15]: 100%|██████████| 1/1 [00:00<00:00, 22.28it/s]\n",
      "\n",
      "client [18]: 100%|██████████| 1/1 [00:00<00:00, 22.80it/s]\n",
      "\n",
      "client [13]: 100%|██████████| 1/1 [00:00<00:00, 23.32it/s]\n",
      "\n",
      "client [8]: 100%|██████████| 1/1 [00:00<00:00, 19.66it/s]\n",
      "\n",
      "client [19]: 100%|██████████| 1/1 [00:00<00:00, 21.78it/s]\n",
      "\n",
      "client [0]: 100%|██████████| 1/1 [00:00<00:00, 22.27it/s]\n",
      "\u001B[1;33mtraining epoch\u001B[0m:  55%|█████▌    | 11/20 [00:17<00:12,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;34mselected clients in round [11]: [ 0 12  6 13 16  8  2 18  1 14]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "client [0]: 100%|██████████| 1/1 [00:00<00:00, 22.29it/s]\n",
      "\n",
      "client [12]: 100%|██████████| 1/1 [00:00<00:00, 23.32it/s]\n",
      "\n",
      "client [6]: 100%|██████████| 1/1 [00:00<00:00, 22.27it/s]\n",
      "\n",
      "client [13]: 100%|██████████| 1/1 [00:00<00:00, 21.80it/s]\n",
      "\n",
      "client [16]: 100%|██████████| 1/1 [00:00<00:00, 22.28it/s]\n",
      "\n",
      "client [8]: 100%|██████████| 1/1 [00:00<00:00, 22.79it/s]\n",
      "\n",
      "client [2]: 100%|██████████| 1/1 [00:00<00:00, 22.30it/s]\n",
      "\n",
      "client [18]: 100%|██████████| 1/1 [00:00<00:00, 18.92it/s]\n",
      "\n",
      "client [1]: 100%|██████████| 1/1 [00:00<00:00, 21.33it/s]\n",
      "\n",
      "client [14]: 100%|██████████| 1/1 [00:00<00:00, 18.92it/s]\n",
      "\u001B[1;33mtraining epoch\u001B[0m:  60%|██████    | 12/20 [00:19<00:11,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;34mselected clients in round [12]: [10  5  4  7 13 18 15  6  2 16]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "client [10]: 100%|██████████| 1/1 [00:00<00:00, 20.05it/s]\n",
      "\n",
      "client [5]: 100%|██████████| 1/1 [00:00<00:00, 19.66it/s]\n",
      "\n",
      "client [4]: 100%|██████████| 1/1 [00:00<00:00, 22.28it/s]\n",
      "\n",
      "client [7]: 100%|██████████| 1/1 [00:00<00:00, 22.79it/s]\n",
      "\n",
      "client [13]: 100%|██████████| 1/1 [00:00<00:00, 22.28it/s]\n",
      "\n",
      "client [18]: 100%|██████████| 1/1 [00:00<00:00, 21.80it/s]\n",
      "\n",
      "client [15]: 100%|██████████| 1/1 [00:00<00:00, 20.89it/s]\n",
      "\n",
      "client [6]: 100%|██████████| 1/1 [00:00<00:00, 21.80it/s]\n",
      "\n",
      "client [2]: 100%|██████████| 1/1 [00:00<00:00, 21.33it/s]\n",
      "\n",
      "client [16]: 100%|██████████| 1/1 [00:00<00:00, 21.33it/s]\n",
      "\u001B[1;33mtraining epoch\u001B[0m:  65%|██████▌   | 13/20 [00:20<00:10,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;34mselected clients in round [13]: [15  4  7 16  9 10 14  8  0  2]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "client [15]: 100%|██████████| 1/1 [00:00<00:00, 20.46it/s]\n",
      "\n",
      "client [4]: 100%|██████████| 1/1 [00:00<00:00, 22.79it/s]\n",
      "\n",
      "client [7]: 100%|██████████| 1/1 [00:00<00:00, 22.77it/s]\n",
      "\n",
      "client [16]: 100%|██████████| 1/1 [00:00<00:00, 23.87it/s]\n",
      "\n",
      "client [9]: 100%|██████████| 1/1 [00:00<00:00, 21.81it/s]\n",
      "\n",
      "client [10]: 100%|██████████| 1/1 [00:00<00:00, 21.80it/s]\n",
      "\n",
      "client [14]: 100%|██████████| 1/1 [00:00<00:00, 21.33it/s]\n",
      "\n",
      "client [8]: 100%|██████████| 1/1 [00:00<00:00, 22.27it/s]\n",
      "\n",
      "client [0]: 100%|██████████| 1/1 [00:00<00:00, 22.28it/s]\n",
      "\n",
      "client [2]: 100%|██████████| 1/1 [00:00<00:00, 21.80it/s]\n",
      "\u001B[1;33mtraining epoch\u001B[0m:  70%|███████   | 14/20 [00:22<00:08,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;34mselected clients in round [14]: [ 2  3 11  9  5  1 10 18  4  0]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "client [2]: 100%|██████████| 1/1 [00:00<00:00, 21.35it/s]\n",
      "\n",
      "client [3]: 100%|██████████| 1/1 [00:00<00:00, 21.80it/s]\n",
      "\n",
      "client [11]: 100%|██████████| 1/1 [00:00<00:00, 22.77it/s]\n",
      "\n",
      "client [9]: 100%|██████████| 1/1 [00:00<00:00, 20.06it/s]\n",
      "\n",
      "client [5]: 100%|██████████| 1/1 [00:00<00:00, 22.79it/s]\n",
      "\n",
      "client [1]: 100%|██████████| 1/1 [00:00<00:00, 22.28it/s]\n",
      "\n",
      "client [10]: 100%|██████████| 1/1 [00:00<00:00, 21.81it/s]\n",
      "\n",
      "client [18]: 100%|██████████| 1/1 [00:00<00:00, 23.32it/s]\n",
      "\n",
      "client [4]: 100%|██████████| 1/1 [00:00<00:00, 21.32it/s]\n",
      "\n",
      "client [0]: 100%|██████████| 1/1 [00:00<00:00, 20.46it/s]\n",
      "\u001B[1;33mtraining epoch\u001B[0m:  75%|███████▌  | 15/20 [00:23<00:07,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;34mselected clients in round [15]: [13  3 19  4 10 15  7  2  0 12]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "client [13]: 100%|██████████| 1/1 [00:00<00:00, 22.28it/s]\n",
      "\n",
      "client [3]: 100%|██████████| 1/1 [00:00<00:00, 21.80it/s]\n",
      "\n",
      "client [19]: 100%|██████████| 1/1 [00:00<00:00, 20.89it/s]\n",
      "\n",
      "client [4]: 100%|██████████| 1/1 [00:00<00:00, 21.33it/s]\n",
      "\n",
      "client [10]: 100%|██████████| 1/1 [00:00<00:00, 23.32it/s]\n",
      "\n",
      "client [15]: 100%|██████████| 1/1 [00:00<00:00, 20.89it/s]\n",
      "\n",
      "client [7]: 100%|██████████| 1/1 [00:00<00:00, 19.65it/s]\n",
      "\n",
      "client [2]: 100%|██████████| 1/1 [00:00<00:00, 20.05it/s]\n",
      "\n",
      "client [0]: 100%|██████████| 1/1 [00:00<00:00, 21.35it/s]\n",
      "\n",
      "client [12]: 100%|██████████| 1/1 [00:00<00:00, 22.28it/s]\n",
      "\u001B[1;33mtraining epoch\u001B[0m:  80%|████████  | 16/20 [00:25<00:05,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;34mselected clients in round [16]: [ 0  8  5 10 18  9 11  4 19 12]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "client [0]: 100%|██████████| 1/1 [00:00<00:00, 21.80it/s]\n",
      "\n",
      "client [8]: 100%|██████████| 1/1 [00:00<00:00, 22.77it/s]\n",
      "\n",
      "client [5]: 100%|██████████| 1/1 [00:00<00:00, 21.80it/s]\n",
      "\n",
      "client [10]: 100%|██████████| 1/1 [00:00<00:00, 23.86it/s]\n",
      "\n",
      "client [18]: 100%|██████████| 1/1 [00:00<00:00, 23.32it/s]\n",
      "\n",
      "client [9]: 100%|██████████| 1/1 [00:00<00:00, 20.89it/s]\n",
      "\n",
      "client [11]: 100%|██████████| 1/1 [00:00<00:00, 22.28it/s]\n",
      "\n",
      "client [4]: 100%|██████████| 1/1 [00:00<00:00, 17.90it/s]\n",
      "\n",
      "client [19]: 100%|██████████| 1/1 [00:00<00:00, 20.46it/s]\n",
      "\n",
      "client [12]: 100%|██████████| 1/1 [00:00<00:00, 20.05it/s]\n",
      "\u001B[1;33mtraining epoch\u001B[0m:  85%|████████▌ | 17/20 [00:26<00:04,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;34mselected clients in round [17]: [ 3 16  7  6 10  9 15  2  8  4]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "client [3]: 100%|██████████| 1/1 [00:00<00:00, 20.89it/s]\n",
      "\n",
      "client [16]: 100%|██████████| 1/1 [00:00<00:00, 21.33it/s]\n",
      "\n",
      "client [7]: 100%|██████████| 1/1 [00:00<00:00, 22.79it/s]\n",
      "\n",
      "client [6]: 100%|██████████| 1/1 [00:00<00:00, 17.90it/s]\n",
      "\n",
      "client [10]: 100%|██████████| 1/1 [00:00<00:00, 20.46it/s]\n",
      "\n",
      "client [9]: 100%|██████████| 1/1 [00:00<00:00, 20.89it/s]\n",
      "\n",
      "client [15]: 100%|██████████| 1/1 [00:00<00:00, 20.89it/s]\n",
      "\n",
      "client [2]: 100%|██████████| 1/1 [00:00<00:00, 20.05it/s]\n",
      "\n",
      "client [8]: 100%|██████████| 1/1 [00:00<00:00, 21.80it/s]\n",
      "\n",
      "client [4]: 100%|██████████| 1/1 [00:00<00:00, 22.78it/s]\n",
      "\u001B[1;33mtraining epoch\u001B[0m:  90%|█████████ | 18/20 [00:27<00:02,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;34mselected clients in round [18]: [ 2  0 12 11 10  8 14  9  7 19]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "client [2]: 100%|██████████| 1/1 [00:00<00:00, 23.87it/s]\n",
      "\n",
      "client [0]: 100%|██████████| 1/1 [00:00<00:00, 22.28it/s]\n",
      "\n",
      "client [12]: 100%|██████████| 1/1 [00:00<00:00, 21.78it/s]\n",
      "\n",
      "client [11]: 100%|██████████| 1/1 [00:00<00:00, 22.80it/s]\n",
      "\n",
      "client [10]: 100%|██████████| 1/1 [00:00<00:00, 21.33it/s]\n",
      "\n",
      "client [8]: 100%|██████████| 1/1 [00:00<00:00, 22.28it/s]\n",
      "\n",
      "client [14]: 100%|██████████| 1/1 [00:00<00:00, 21.33it/s]\n",
      "\n",
      "client [9]: 100%|██████████| 1/1 [00:00<00:00, 23.33it/s]\n",
      "\n",
      "client [7]: 100%|██████████| 1/1 [00:00<00:00, 22.79it/s]\n",
      "\n",
      "client [19]: 100%|██████████| 1/1 [00:00<00:00, 20.89it/s]\n",
      "\u001B[1;33mtraining epoch\u001B[0m:  95%|█████████▌| 19/20 [00:29<00:01,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;34mselected clients in round [19]: [ 4 10  8  1 17  2 19 14 11  9]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "client [4]: 100%|██████████| 1/1 [00:00<00:00, 23.30it/s]\n",
      "\n",
      "client [10]: 100%|██████████| 1/1 [00:00<00:00, 23.30it/s]\n",
      "\n",
      "client [8]: 100%|██████████| 1/1 [00:00<00:00, 23.33it/s]\n",
      "\n",
      "client [1]: 100%|██████████| 1/1 [00:00<00:00, 22.77it/s]\n",
      "\n",
      "client [17]: 100%|██████████| 1/1 [00:00<00:00, 23.33it/s]\n",
      "\n",
      "client [2]: 100%|██████████| 1/1 [00:00<00:00, 22.30it/s]\n",
      "\n",
      "client [19]: 100%|██████████| 1/1 [00:00<00:00, 23.32it/s]\n",
      "\n",
      "client [14]: 100%|██████████| 1/1 [00:00<00:00, 23.27it/s]\n",
      "\n",
      "client [11]: 100%|██████████| 1/1 [00:00<00:00, 23.30it/s]\n",
      "\n",
      "client [9]: 100%|██████████| 1/1 [00:00<00:00, 23.32it/s]\n",
      "\u001B[1;33mtraining epoch\u001B[0m: 100%|██████████| 20/20 [00:30<00:00,  1.54s/it]\n"
     ]
    }
   ],
   "source": [
    "for r in trange(n_epochs, desc=\"\\033[1;33mtraining epoch\\033[0m\"):\n",
    "\n",
    "    # different clients at each epoch\n",
    "    m = max(int(frac * num_users), 1) # number of users to be used for federated updates, at least 1\n",
    "    idxs_users = np.random.choice(range(num_users), m, replace=False) # choose randomly m users\n",
    "\n",
    "    print(\n",
    "        \"\\033[1;34mselected clients in round [{}]: {}\\033[0m\".format(\n",
    "            r, idxs_users\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # retrieve model parameter\n",
    "    global_model_param = SerializationTool.serialize_model(model)\n",
    "    c_delta_buffer = []\n",
    "    y_delta_buffer = []\n",
    "\n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    for idx in idxs_users:  # for each user\n",
    "\n",
    "        c_delta, y_delta = 0, 0\n",
    "        c_delta, y_delta = client_list[idx].train(\n",
    "            global_model_param, c_global\n",
    "        )\n",
    "\n",
    "        c_delta_buffer.append(c_delta)\n",
    "        y_delta_buffer.append(y_delta)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # update global model\n",
    "        for y_del in y_delta_buffer:\n",
    "            for param, diff in zip (model.parameters(), y_del):\n",
    "                param.data.add_(diff.data / (num_users * frac))\n",
    "\n",
    "        # update global_c\n",
    "        for c_delta in c_delta_buffer:\n",
    "            for c_g, c_d in zip(c_global, c_delta):\n",
    "                c_g.data += c_d.data / num_users\n",
    "\n",
    "\n",
    "    # ######################\n",
    "    # # validate the model #\n",
    "    # ######################\n",
    "    # avg_loss_g = 0  # global model loss\n",
    "    # avg_acc_g = 0  # global model accuracy\n",
    "    # avg_loss_l = 0  # localized model loss\n",
    "    # avg_acc_l = 0  # localized model accuracy\n",
    "    #\n",
    "    # test_round = 2\n",
    "    # for r in trange(test_round, desc=\"\\033[1;36mevaluating epoch\\033[0m\"):\n",
    "    #     m = max(int(frac * num_users), 1) # number of users to be used for federated updates, at least 1\n",
    "    #     idxs_users = np.random.choice(range(num_users), m, replace=False) # choose randomly m users\n",
    "    #\n",
    "    #     print(\n",
    "    #         \"\\033[1;34mselected clients in round [{}]: {}\\033[0m\".format(\n",
    "    #             r, idxs_users\n",
    "    #         )\n",
    "    #     )\n",
    "    #     global_model_param = SerializationTool.serialize_model(model)\n",
    "    #     for idx in idxs_users:\n",
    "    #         stats = client_list[idx].eval(global_model_param, c_global)\n",
    "    #         avg_loss_g += stats[0]\n",
    "    #         avg_acc_g += stats[1]\n",
    "    #         avg_loss_l += stats[2]\n",
    "    #         avg_acc_l += stats[3]\n",
    "    #\n",
    "    #     # display experiment results\n",
    "    #     avg_loss_g /= (num_users * frac) * test_round\n",
    "    #     avg_acc_g /= (num_users * frac) * test_round\n",
    "    #     avg_loss_l /= (num_users * frac) * test_round\n",
    "    #     avg_acc_l /= (num_users * frac) * test_round\n",
    "    #     print(\"\\033[1;32m---------------------- RESULTS ----------------------\\033[0m\")\n",
    "    #     print(\"\\033[1;33m Global SCAFFOLD loss: {:.4f}\\033[0m\".format(avg_loss_g))\n",
    "    #     print(\"\\033[1;33m Global SCAFFOLD accuracy: {:.2f}%\\033[0m\".format(avg_acc_g))\n",
    "    #     print(\"\\033[1;36m Localized SCAFFOLD loss: {:.4f}\\033[0m\".format(avg_loss_l))\n",
    "    #     print(\"\\033[1;36m Localized SCAFFOLD accuracy: {:.2f}%\\033[0m\".format(avg_acc_l))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}