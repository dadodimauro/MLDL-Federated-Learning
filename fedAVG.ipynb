{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/AshwinRJ/Federated-Learning-PyTorch\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from models import ResNet50\n",
    "# from utils import get_dataset, average_weights, exp_details\n",
    "from utils_v2 import get_dataset, average_weights, exp_details\n",
    "from update import LocalUpdate, test_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# parameters\n",
    "iid = 1 # if the data is i.i.d or not\n",
    "unbalanced = 0 # in non i.i.d. setting split the data between clients equally or not\n",
    "num_users = 100 # number of client\n",
    "frac = 0.1 # fraction of the clients to be used for federated updates\n",
    "n_epochs = 100\n",
    "gpu = 0\n",
    "optimizer = \"sgd\" #sgd or adam\n",
    "local_batch_size = 10 # batch size of local updates in each user\n",
    "lr = 0.001 # learning rate\n",
    "local_epochs = 1\n",
    "loss_function = \"CrossEntropyLoss\"\n",
    "\n",
    "num_groups = 4  # 0 for BatchNorm, > 0 for GroupNorm\n",
    "if num_groups == 0:\n",
    "    normalization_type = \"BatchNorm\"\n",
    "else:\n",
    "    normalization_type = \"GroupNorm\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experimental details:\n",
      "    Model     : ResNet50\n",
      "    Optimizer : sgd\n",
      "    Learning  : 0.001\n",
      "    Normalization  : GroupNorm\n",
      "    Global Rounds   : 100\n",
      "\n",
      "    Federated parameters:\n",
      "    IID\n",
      "    NUmber of users  : 100\n",
      "    Fraction of users  : 0.1\n",
      "    Local Batch size   : 10\n",
      "    Local Epochs       : 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exp_details(\"ResNet50\", optimizer, lr, normalization_type, n_epochs, iid, frac,\n",
    "            local_batch_size, local_epochs, unbalanced, num_users)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# for REPRODUCIBILITY https://pytorch.org/docs/stable/notes/randomness.html\n",
    "torch.manual_seed(0)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)\n",
    "\n",
    "np.random.seed(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset, user_groups = get_dataset(iid=iid, unbalanced=unbalanced,\n",
    "                                                       num_users=num_users)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n"
     ]
    },
    {
     "data": {
      "text/plain": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n  (bn1): GroupNorm(4, 64, eps=1e-05, affine=True)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): GroupNorm(4, 64, eps=1e-05, affine=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): GroupNorm(4, 64, eps=1e-05, affine=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): GroupNorm(4, 256, eps=1e-05, affine=True)\n      (shortcut): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): GroupNorm(4, 256, eps=1e-05, affine=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): GroupNorm(4, 64, eps=1e-05, affine=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): GroupNorm(4, 64, eps=1e-05, affine=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): GroupNorm(4, 256, eps=1e-05, affine=True)\n      (shortcut): Sequential()\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): GroupNorm(4, 64, eps=1e-05, affine=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): GroupNorm(4, 64, eps=1e-05, affine=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): GroupNorm(4, 256, eps=1e-05, affine=True)\n      (shortcut): Sequential()\n    )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): GroupNorm(4, 128, eps=1e-05, affine=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): GroupNorm(4, 128, eps=1e-05, affine=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): GroupNorm(4, 512, eps=1e-05, affine=True)\n      (shortcut): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): GroupNorm(4, 512, eps=1e-05, affine=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): GroupNorm(4, 128, eps=1e-05, affine=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): GroupNorm(4, 128, eps=1e-05, affine=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): GroupNorm(4, 512, eps=1e-05, affine=True)\n      (shortcut): Sequential()\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): GroupNorm(4, 128, eps=1e-05, affine=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): GroupNorm(4, 128, eps=1e-05, affine=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): GroupNorm(4, 512, eps=1e-05, affine=True)\n      (shortcut): Sequential()\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): GroupNorm(4, 128, eps=1e-05, affine=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): GroupNorm(4, 128, eps=1e-05, affine=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): GroupNorm(4, 512, eps=1e-05, affine=True)\n      (shortcut): Sequential()\n    )\n  )\n  (layer3): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): GroupNorm(4, 256, eps=1e-05, affine=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): GroupNorm(4, 256, eps=1e-05, affine=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): GroupNorm(4, 1024, eps=1e-05, affine=True)\n      (shortcut): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): GroupNorm(4, 1024, eps=1e-05, affine=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): GroupNorm(4, 256, eps=1e-05, affine=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): GroupNorm(4, 256, eps=1e-05, affine=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): GroupNorm(4, 1024, eps=1e-05, affine=True)\n      (shortcut): Sequential()\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): GroupNorm(4, 256, eps=1e-05, affine=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): GroupNorm(4, 256, eps=1e-05, affine=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): GroupNorm(4, 1024, eps=1e-05, affine=True)\n      (shortcut): Sequential()\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): GroupNorm(4, 256, eps=1e-05, affine=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): GroupNorm(4, 256, eps=1e-05, affine=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): GroupNorm(4, 1024, eps=1e-05, affine=True)\n      (shortcut): Sequential()\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): GroupNorm(4, 256, eps=1e-05, affine=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): GroupNorm(4, 256, eps=1e-05, affine=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): GroupNorm(4, 1024, eps=1e-05, affine=True)\n      (shortcut): Sequential()\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): GroupNorm(4, 256, eps=1e-05, affine=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): GroupNorm(4, 256, eps=1e-05, affine=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): GroupNorm(4, 1024, eps=1e-05, affine=True)\n      (shortcut): Sequential()\n    )\n  )\n  (layer4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): GroupNorm(4, 512, eps=1e-05, affine=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): GroupNorm(4, 512, eps=1e-05, affine=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): GroupNorm(4, 2048, eps=1e-05, affine=True)\n      (shortcut): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): GroupNorm(4, 2048, eps=1e-05, affine=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): GroupNorm(4, 512, eps=1e-05, affine=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): GroupNorm(4, 512, eps=1e-05, affine=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): GroupNorm(4, 2048, eps=1e-05, affine=True)\n      (shortcut): Sequential()\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): GroupNorm(4, 512, eps=1e-05, affine=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): GroupNorm(4, 512, eps=1e-05, affine=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): GroupNorm(4, 2048, eps=1e-05, affine=True)\n      (shortcut): Sequential()\n    )\n  )\n  (linear): Linear(in_features=2048, out_features=10, bias=True)\n)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet50(n_type=normalization_type)\n",
    "# model = CNNCifar()\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "    device = torch.device(\"cpu\")\n",
    "    gpu = 0\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')\n",
    "    device = torch.device(\"cuda\")\n",
    "    gpu = 1\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# set the model to train\n",
    "model.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "         GroupNorm-2           [-1, 64, 32, 32]             128\n",
      "            Conv2d-3           [-1, 64, 32, 32]           4,096\n",
      "         GroupNorm-4           [-1, 64, 32, 32]             128\n",
      "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
      "         GroupNorm-6           [-1, 64, 32, 32]             128\n",
      "            Conv2d-7          [-1, 256, 32, 32]          16,384\n",
      "         GroupNorm-8          [-1, 256, 32, 32]             512\n",
      "            Conv2d-9          [-1, 256, 32, 32]          16,384\n",
      "        GroupNorm-10          [-1, 256, 32, 32]             512\n",
      "       Bottleneck-11          [-1, 256, 32, 32]               0\n",
      "           Conv2d-12           [-1, 64, 32, 32]          16,384\n",
      "        GroupNorm-13           [-1, 64, 32, 32]             128\n",
      "           Conv2d-14           [-1, 64, 32, 32]          36,864\n",
      "        GroupNorm-15           [-1, 64, 32, 32]             128\n",
      "           Conv2d-16          [-1, 256, 32, 32]          16,384\n",
      "        GroupNorm-17          [-1, 256, 32, 32]             512\n",
      "       Bottleneck-18          [-1, 256, 32, 32]               0\n",
      "           Conv2d-19           [-1, 64, 32, 32]          16,384\n",
      "        GroupNorm-20           [-1, 64, 32, 32]             128\n",
      "           Conv2d-21           [-1, 64, 32, 32]          36,864\n",
      "        GroupNorm-22           [-1, 64, 32, 32]             128\n",
      "           Conv2d-23          [-1, 256, 32, 32]          16,384\n",
      "        GroupNorm-24          [-1, 256, 32, 32]             512\n",
      "       Bottleneck-25          [-1, 256, 32, 32]               0\n",
      "           Conv2d-26          [-1, 128, 32, 32]          32,768\n",
      "        GroupNorm-27          [-1, 128, 32, 32]             256\n",
      "           Conv2d-28          [-1, 128, 16, 16]         147,456\n",
      "        GroupNorm-29          [-1, 128, 16, 16]             256\n",
      "           Conv2d-30          [-1, 512, 16, 16]          65,536\n",
      "        GroupNorm-31          [-1, 512, 16, 16]           1,024\n",
      "           Conv2d-32          [-1, 512, 16, 16]         131,072\n",
      "        GroupNorm-33          [-1, 512, 16, 16]           1,024\n",
      "       Bottleneck-34          [-1, 512, 16, 16]               0\n",
      "           Conv2d-35          [-1, 128, 16, 16]          65,536\n",
      "        GroupNorm-36          [-1, 128, 16, 16]             256\n",
      "           Conv2d-37          [-1, 128, 16, 16]         147,456\n",
      "        GroupNorm-38          [-1, 128, 16, 16]             256\n",
      "           Conv2d-39          [-1, 512, 16, 16]          65,536\n",
      "        GroupNorm-40          [-1, 512, 16, 16]           1,024\n",
      "       Bottleneck-41          [-1, 512, 16, 16]               0\n",
      "           Conv2d-42          [-1, 128, 16, 16]          65,536\n",
      "        GroupNorm-43          [-1, 128, 16, 16]             256\n",
      "           Conv2d-44          [-1, 128, 16, 16]         147,456\n",
      "        GroupNorm-45          [-1, 128, 16, 16]             256\n",
      "           Conv2d-46          [-1, 512, 16, 16]          65,536\n",
      "        GroupNorm-47          [-1, 512, 16, 16]           1,024\n",
      "       Bottleneck-48          [-1, 512, 16, 16]               0\n",
      "           Conv2d-49          [-1, 128, 16, 16]          65,536\n",
      "        GroupNorm-50          [-1, 128, 16, 16]             256\n",
      "           Conv2d-51          [-1, 128, 16, 16]         147,456\n",
      "        GroupNorm-52          [-1, 128, 16, 16]             256\n",
      "           Conv2d-53          [-1, 512, 16, 16]          65,536\n",
      "        GroupNorm-54          [-1, 512, 16, 16]           1,024\n",
      "       Bottleneck-55          [-1, 512, 16, 16]               0\n",
      "           Conv2d-56          [-1, 256, 16, 16]         131,072\n",
      "        GroupNorm-57          [-1, 256, 16, 16]             512\n",
      "           Conv2d-58            [-1, 256, 8, 8]         589,824\n",
      "        GroupNorm-59            [-1, 256, 8, 8]             512\n",
      "           Conv2d-60           [-1, 1024, 8, 8]         262,144\n",
      "        GroupNorm-61           [-1, 1024, 8, 8]           2,048\n",
      "           Conv2d-62           [-1, 1024, 8, 8]         524,288\n",
      "        GroupNorm-63           [-1, 1024, 8, 8]           2,048\n",
      "       Bottleneck-64           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-65            [-1, 256, 8, 8]         262,144\n",
      "        GroupNorm-66            [-1, 256, 8, 8]             512\n",
      "           Conv2d-67            [-1, 256, 8, 8]         589,824\n",
      "        GroupNorm-68            [-1, 256, 8, 8]             512\n",
      "           Conv2d-69           [-1, 1024, 8, 8]         262,144\n",
      "        GroupNorm-70           [-1, 1024, 8, 8]           2,048\n",
      "       Bottleneck-71           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-72            [-1, 256, 8, 8]         262,144\n",
      "        GroupNorm-73            [-1, 256, 8, 8]             512\n",
      "           Conv2d-74            [-1, 256, 8, 8]         589,824\n",
      "        GroupNorm-75            [-1, 256, 8, 8]             512\n",
      "           Conv2d-76           [-1, 1024, 8, 8]         262,144\n",
      "        GroupNorm-77           [-1, 1024, 8, 8]           2,048\n",
      "       Bottleneck-78           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-79            [-1, 256, 8, 8]         262,144\n",
      "        GroupNorm-80            [-1, 256, 8, 8]             512\n",
      "           Conv2d-81            [-1, 256, 8, 8]         589,824\n",
      "        GroupNorm-82            [-1, 256, 8, 8]             512\n",
      "           Conv2d-83           [-1, 1024, 8, 8]         262,144\n",
      "        GroupNorm-84           [-1, 1024, 8, 8]           2,048\n",
      "       Bottleneck-85           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-86            [-1, 256, 8, 8]         262,144\n",
      "        GroupNorm-87            [-1, 256, 8, 8]             512\n",
      "           Conv2d-88            [-1, 256, 8, 8]         589,824\n",
      "        GroupNorm-89            [-1, 256, 8, 8]             512\n",
      "           Conv2d-90           [-1, 1024, 8, 8]         262,144\n",
      "        GroupNorm-91           [-1, 1024, 8, 8]           2,048\n",
      "       Bottleneck-92           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-93            [-1, 256, 8, 8]         262,144\n",
      "        GroupNorm-94            [-1, 256, 8, 8]             512\n",
      "           Conv2d-95            [-1, 256, 8, 8]         589,824\n",
      "        GroupNorm-96            [-1, 256, 8, 8]             512\n",
      "           Conv2d-97           [-1, 1024, 8, 8]         262,144\n",
      "        GroupNorm-98           [-1, 1024, 8, 8]           2,048\n",
      "       Bottleneck-99           [-1, 1024, 8, 8]               0\n",
      "          Conv2d-100            [-1, 512, 8, 8]         524,288\n",
      "       GroupNorm-101            [-1, 512, 8, 8]           1,024\n",
      "          Conv2d-102            [-1, 512, 4, 4]       2,359,296\n",
      "       GroupNorm-103            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-104           [-1, 2048, 4, 4]       1,048,576\n",
      "       GroupNorm-105           [-1, 2048, 4, 4]           4,096\n",
      "          Conv2d-106           [-1, 2048, 4, 4]       2,097,152\n",
      "       GroupNorm-107           [-1, 2048, 4, 4]           4,096\n",
      "      Bottleneck-108           [-1, 2048, 4, 4]               0\n",
      "          Conv2d-109            [-1, 512, 4, 4]       1,048,576\n",
      "       GroupNorm-110            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-111            [-1, 512, 4, 4]       2,359,296\n",
      "       GroupNorm-112            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-113           [-1, 2048, 4, 4]       1,048,576\n",
      "       GroupNorm-114           [-1, 2048, 4, 4]           4,096\n",
      "      Bottleneck-115           [-1, 2048, 4, 4]               0\n",
      "          Conv2d-116            [-1, 512, 4, 4]       1,048,576\n",
      "       GroupNorm-117            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-118            [-1, 512, 4, 4]       2,359,296\n",
      "       GroupNorm-119            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-120           [-1, 2048, 4, 4]       1,048,576\n",
      "       GroupNorm-121           [-1, 2048, 4, 4]           4,096\n",
      "      Bottleneck-122           [-1, 2048, 4, 4]               0\n",
      "          Linear-123                   [-1, 10]          20,490\n",
      "================================================================\n",
      "Total params: 23,520,842\n",
      "Trainable params: 23,520,842\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 66.13\n",
      "Params size (MB): 89.72\n",
      "Estimated Total Size (MB): 155.86\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# total number of params 591,322\n",
    "summary(model, (3, 32, 32))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# copy weights\n",
    "global_weights = model.state_dict()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\OneDrive - Politecnico di Torino\\PoliTO\\MASTER\\MACHINE LEARNING AND DEEP LEARNING\\MLDL Federated Learning\\update.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(image), torch.tensor(label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Global Round : 1 | Local Epoch : 1 | Train Loss: 3.4358 | Train Accuracy: 0.10\n",
      "| Global Round : 1 | Average Train Loss: 3.4358 \n",
      "| Client : 43 | Average Loss: 3.4358 \n",
      "| Global Round : 1 | Local Epoch : 1 | Train Loss: 3.3412 | Train Accuracy: 0.08\n",
      "| Global Round : 1 | Average Train Loss: 3.3412 \n",
      "| Client : 36 | Average Loss: 3.3412 \n",
      "| Global Round : 1 | Local Epoch : 1 | Train Loss: 3.2304 | Train Accuracy: 0.12\n",
      "| Global Round : 1 | Average Train Loss: 3.2304 \n",
      "| Client : 92 | Average Loss: 3.2304 \n",
      "| Global Round : 1 | Local Epoch : 1 | Train Loss: 3.3639 | Train Accuracy: 0.10\n",
      "| Global Round : 1 | Average Train Loss: 3.3639 \n",
      "| Client : 80 | Average Loss: 3.3639 \n",
      "| Global Round : 1 | Local Epoch : 1 | Train Loss: 3.5930 | Train Accuracy: 0.10\n",
      "| Global Round : 1 | Average Train Loss: 3.5930 \n",
      "| Client : 15 | Average Loss: 3.5930 \n",
      "| Global Round : 1 | Local Epoch : 1 | Train Loss: 3.4897 | Train Accuracy: 0.13\n",
      "| Global Round : 1 | Average Train Loss: 3.4897 \n",
      "| Client : 26 | Average Loss: 3.4897 \n",
      "| Global Round : 1 | Local Epoch : 1 | Train Loss: 3.0534 | Train Accuracy: 0.12\n",
      "| Global Round : 1 | Average Train Loss: 3.0534 \n",
      "| Client : 63 | Average Loss: 3.0534 \n",
      "| Global Round : 1 | Local Epoch : 1 | Train Loss: 3.4658 | Train Accuracy: 0.10\n",
      "| Global Round : 1 | Average Train Loss: 3.4658 \n",
      "| Client : 52 | Average Loss: 3.4658 \n",
      "| Global Round : 1 | Local Epoch : 1 | Train Loss: 3.1159 | Train Accuracy: 0.11\n",
      "| Global Round : 1 | Average Train Loss: 3.1159 \n",
      "| Client : 48 | Average Loss: 3.1159 \n",
      "| Global Round : 1 | Local Epoch : 1 | Train Loss: 3.5006 | Train Accuracy: 0.10\n",
      "| Global Round : 1 | Average Train Loss: 3.5006 \n",
      "| Client : 93 | Average Loss: 3.5006 \n",
      "\n",
      "Average training statistics (global epoch : 1\n",
      "|---- Trainig Loss : 3.3589808310402764\n",
      "|---- Training Accuracy: 13.52% \n",
      "\n",
      "Epoch: 2 \n",
      "\n",
      "| Global Round : 2 | Local Epoch : 1 | Train Loss: 2.6152 | Train Accuracy: 0.10\n",
      "| Global Round : 2 | Average Train Loss: 2.6152 \n",
      "| Client : 24 | Average Loss: 2.6152 \n",
      "| Global Round : 2 | Local Epoch : 1 | Train Loss: 2.5908 | Train Accuracy: 0.13\n",
      "| Global Round : 2 | Average Train Loss: 2.5908 \n",
      "| Client : 19 | Average Loss: 2.5908 \n",
      "| Global Round : 2 | Local Epoch : 1 | Train Loss: 2.7097 | Train Accuracy: 0.10\n",
      "| Global Round : 2 | Average Train Loss: 2.7097 \n",
      "| Client : 18 | Average Loss: 2.7097 \n",
      "| Global Round : 2 | Local Epoch : 1 | Train Loss: 2.6325 | Train Accuracy: 0.08\n",
      "| Global Round : 2 | Average Train Loss: 2.6325 \n",
      "| Client : 4 | Average Loss: 2.6325 \n",
      "| Global Round : 2 | Local Epoch : 1 | Train Loss: 2.9360 | Train Accuracy: 0.12\n",
      "| Global Round : 2 | Average Train Loss: 2.9360 \n",
      "| Client : 6 | Average Loss: 2.9360 \n",
      "| Global Round : 2 | Local Epoch : 1 | Train Loss: 2.6902 | Train Accuracy: 0.10\n",
      "| Global Round : 2 | Average Train Loss: 2.6902 \n",
      "| Client : 40 | Average Loss: 2.6902 \n",
      "| Global Round : 2 | Local Epoch : 1 | Train Loss: 2.6933 | Train Accuracy: 0.10\n",
      "| Global Round : 2 | Average Train Loss: 2.6933 \n",
      "| Client : 53 | Average Loss: 2.6933 \n",
      "| Global Round : 2 | Local Epoch : 1 | Train Loss: 2.6427 | Train Accuracy: 0.10\n",
      "| Global Round : 2 | Average Train Loss: 2.6427 \n",
      "| Client : 32 | Average Loss: 2.6427 \n",
      "| Global Round : 2 | Local Epoch : 1 | Train Loss: 2.7315 | Train Accuracy: 0.10\n",
      "| Global Round : 2 | Average Train Loss: 2.7315 \n",
      "| Client : 79 | Average Loss: 2.7315 \n",
      "| Global Round : 2 | Local Epoch : 1 | Train Loss: 2.6185 | Train Accuracy: 0.11\n",
      "| Global Round : 2 | Average Train Loss: 2.6185 \n",
      "| Client : 26 | Average Loss: 2.6185 \n",
      "\n",
      "Average training statistics (global epoch : 2\n",
      "|---- Trainig Loss : 3.0225128889083863\n",
      "|---- Training Accuracy: 9.54% \n",
      "\n",
      "Epoch: 3 \n",
      "\n",
      "| Global Round : 3 | Local Epoch : 1 | Train Loss: 2.6325 | Train Accuracy: 0.14\n",
      "| Global Round : 3 | Average Train Loss: 2.6325 \n",
      "| Client : 81 | Average Loss: 2.6325 \n",
      "| Global Round : 3 | Local Epoch : 1 | Train Loss: 2.5536 | Train Accuracy: 0.09\n",
      "| Global Round : 3 | Average Train Loss: 2.5536 \n",
      "| Client : 68 | Average Loss: 2.5536 \n",
      "| Global Round : 3 | Local Epoch : 1 | Train Loss: 2.5935 | Train Accuracy: 0.10\n",
      "| Global Round : 3 | Average Train Loss: 2.5935 \n",
      "| Client : 29 | Average Loss: 2.5935 \n",
      "| Global Round : 3 | Local Epoch : 1 | Train Loss: 2.5266 | Train Accuracy: 0.11\n",
      "| Global Round : 3 | Average Train Loss: 2.5266 \n",
      "| Client : 86 | Average Loss: 2.5266 \n",
      "| Global Round : 3 | Local Epoch : 1 | Train Loss: 2.4970 | Train Accuracy: 0.10\n",
      "| Global Round : 3 | Average Train Loss: 2.4970 \n",
      "| Client : 58 | Average Loss: 2.4970 \n",
      "| Global Round : 3 | Local Epoch : 1 | Train Loss: 2.5693 | Train Accuracy: 0.14\n",
      "| Global Round : 3 | Average Train Loss: 2.5693 \n",
      "| Client : 79 | Average Loss: 2.5693 \n",
      "| Global Round : 3 | Local Epoch : 1 | Train Loss: 2.5230 | Train Accuracy: 0.12\n",
      "| Global Round : 3 | Average Train Loss: 2.5230 \n",
      "| Client : 15 | Average Loss: 2.5230 \n",
      "| Global Round : 3 | Local Epoch : 1 | Train Loss: 2.5194 | Train Accuracy: 0.14\n",
      "| Global Round : 3 | Average Train Loss: 2.5194 \n",
      "| Client : 76 | Average Loss: 2.5194 \n",
      "| Global Round : 3 | Local Epoch : 1 | Train Loss: 2.5020 | Train Accuracy: 0.12\n",
      "| Global Round : 3 | Average Train Loss: 2.5020 \n",
      "| Client : 24 | Average Loss: 2.5020 \n",
      "| Global Round : 3 | Local Epoch : 1 | Train Loss: 2.6145 | Train Accuracy: 0.13\n",
      "| Global Round : 3 | Average Train Loss: 2.6145 \n",
      "| Client : 45 | Average Loss: 2.6145 \n",
      "\n",
      "Average training statistics (global epoch : 3\n",
      "|---- Trainig Loss : 2.8660529388321776\n",
      "|---- Training Accuracy: 14.80% \n",
      "\n",
      "Epoch: 4 \n",
      "\n",
      "| Global Round : 4 | Local Epoch : 1 | Train Loss: 2.4287 | Train Accuracy: 0.12\n",
      "| Global Round : 4 | Average Train Loss: 2.4287 \n",
      "| Client : 96 | Average Loss: 2.4287 \n",
      "| Global Round : 4 | Local Epoch : 1 | Train Loss: 2.4784 | Train Accuracy: 0.11\n",
      "| Global Round : 4 | Average Train Loss: 2.4784 \n",
      "| Client : 84 | Average Loss: 2.4784 \n",
      "| Global Round : 4 | Local Epoch : 1 | Train Loss: 2.4170 | Train Accuracy: 0.15\n",
      "| Global Round : 4 | Average Train Loss: 2.4170 \n",
      "| Client : 38 | Average Loss: 2.4170 \n",
      "| Global Round : 4 | Local Epoch : 1 | Train Loss: 2.5279 | Train Accuracy: 0.12\n",
      "| Global Round : 4 | Average Train Loss: 2.5279 \n",
      "| Client : 56 | Average Loss: 2.5279 \n",
      "| Global Round : 4 | Local Epoch : 1 | Train Loss: 2.4190 | Train Accuracy: 0.13\n",
      "| Global Round : 4 | Average Train Loss: 2.4190 \n",
      "| Client : 23 | Average Loss: 2.4190 \n",
      "| Global Round : 4 | Local Epoch : 1 | Train Loss: 2.4725 | Train Accuracy: 0.14\n",
      "| Global Round : 4 | Average Train Loss: 2.4725 \n",
      "| Client : 55 | Average Loss: 2.4725 \n",
      "| Global Round : 4 | Local Epoch : 1 | Train Loss: 2.5635 | Train Accuracy: 0.12\n",
      "| Global Round : 4 | Average Train Loss: 2.5635 \n",
      "| Client : 10 | Average Loss: 2.5635 \n",
      "| Global Round : 4 | Local Epoch : 1 | Train Loss: 2.4655 | Train Accuracy: 0.13\n",
      "| Global Round : 4 | Average Train Loss: 2.4655 \n",
      "| Client : 71 | Average Loss: 2.4655 \n",
      "| Global Round : 4 | Local Epoch : 1 | Train Loss: 2.4615 | Train Accuracy: 0.14\n",
      "| Global Round : 4 | Average Train Loss: 2.4615 \n",
      "| Client : 3 | Average Loss: 2.4615 \n",
      "| Global Round : 4 | Local Epoch : 1 | Train Loss: 2.5583 | Train Accuracy: 0.12\n",
      "| Global Round : 4 | Average Train Loss: 2.5583 \n",
      "| Client : 2 | Average Loss: 2.5583 \n",
      "\n",
      "Average training statistics (global epoch : 4\n",
      "|---- Trainig Loss : 2.76934871700075\n",
      "|---- Training Accuracy: 18.94% \n",
      "\n",
      "Epoch: 5 \n",
      "\n",
      "| Global Round : 5 | Local Epoch : 1 | Train Loss: 2.3680 | Train Accuracy: 0.14\n",
      "| Global Round : 5 | Average Train Loss: 2.3680 \n",
      "| Client : 34 | Average Loss: 2.3680 \n",
      "| Global Round : 5 | Local Epoch : 1 | Train Loss: 2.4502 | Train Accuracy: 0.12\n",
      "| Global Round : 5 | Average Train Loss: 2.4502 \n",
      "| Client : 25 | Average Loss: 2.4502 \n",
      "| Global Round : 5 | Local Epoch : 1 | Train Loss: 2.4215 | Train Accuracy: 0.13\n",
      "| Global Round : 5 | Average Train Loss: 2.4215 \n",
      "| Client : 77 | Average Loss: 2.4215 \n",
      "| Global Round : 5 | Local Epoch : 1 | Train Loss: 2.4702 | Train Accuracy: 0.12\n",
      "| Global Round : 5 | Average Train Loss: 2.4702 \n",
      "| Client : 54 | Average Loss: 2.4702 \n",
      "| Global Round : 5 | Local Epoch : 1 | Train Loss: 2.4543 | Train Accuracy: 0.17\n",
      "| Global Round : 5 | Average Train Loss: 2.4543 \n",
      "| Client : 53 | Average Loss: 2.4543 \n",
      "| Global Round : 5 | Local Epoch : 1 | Train Loss: 2.4709 | Train Accuracy: 0.11\n",
      "| Global Round : 5 | Average Train Loss: 2.4709 \n",
      "| Client : 84 | Average Loss: 2.4709 \n",
      "| Global Round : 5 | Local Epoch : 1 | Train Loss: 2.4423 | Train Accuracy: 0.10\n",
      "| Global Round : 5 | Average Train Loss: 2.4423 \n",
      "| Client : 69 | Average Loss: 2.4423 \n",
      "| Global Round : 5 | Local Epoch : 1 | Train Loss: 2.5015 | Train Accuracy: 0.13\n",
      "| Global Round : 5 | Average Train Loss: 2.5015 \n",
      "| Client : 33 | Average Loss: 2.5015 \n",
      "| Global Round : 5 | Local Epoch : 1 | Train Loss: 2.3585 | Train Accuracy: 0.17\n",
      "| Global Round : 5 | Average Train Loss: 2.3585 \n",
      "| Client : 1 | Average Loss: 2.3585 \n",
      "| Global Round : 5 | Local Epoch : 1 | Train Loss: 2.3359 | Train Accuracy: 0.13\n",
      "| Global Round : 5 | Average Train Loss: 2.3359 \n",
      "| Client : 24 | Average Loss: 2.3359 \n",
      "\n",
      "Average training statistics (global epoch : 5\n",
      "|---- Trainig Loss : 2.7009432109196987\n",
      "|---- Training Accuracy: 17.76% \n",
      "\n",
      "Epoch: 6 \n",
      "\n",
      "| Global Round : 6 | Local Epoch : 1 | Train Loss: 2.3200 | Train Accuracy: 0.15\n",
      "| Global Round : 6 | Average Train Loss: 2.3200 \n",
      "| Client : 78 | Average Loss: 2.3200 \n",
      "| Global Round : 6 | Local Epoch : 1 | Train Loss: 2.3899 | Train Accuracy: 0.17\n",
      "| Global Round : 6 | Average Train Loss: 2.3899 \n",
      "| Client : 92 | Average Loss: 2.3899 \n",
      "| Global Round : 6 | Local Epoch : 1 | Train Loss: 2.3935 | Train Accuracy: 0.13\n",
      "| Global Round : 6 | Average Train Loss: 2.3935 \n",
      "| Client : 0 | Average Loss: 2.3935 \n",
      "| Global Round : 6 | Local Epoch : 1 | Train Loss: 2.3268 | Train Accuracy: 0.14\n",
      "| Global Round : 6 | Average Train Loss: 2.3268 \n",
      "| Client : 75 | Average Loss: 2.3268 \n",
      "| Global Round : 6 | Local Epoch : 1 | Train Loss: 2.4495 | Train Accuracy: 0.16\n",
      "| Global Round : 6 | Average Train Loss: 2.4495 \n",
      "| Client : 20 | Average Loss: 2.4495 \n",
      "| Global Round : 6 | Local Epoch : 1 | Train Loss: 2.2688 | Train Accuracy: 0.15\n",
      "| Global Round : 6 | Average Train Loss: 2.2688 \n",
      "| Client : 13 | Average Loss: 2.2688 \n",
      "| Global Round : 6 | Local Epoch : 1 | Train Loss: 2.3127 | Train Accuracy: 0.17\n",
      "| Global Round : 6 | Average Train Loss: 2.3127 \n",
      "| Client : 43 | Average Loss: 2.3127 \n",
      "| Global Round : 6 | Local Epoch : 1 | Train Loss: 2.3463 | Train Accuracy: 0.16\n",
      "| Global Round : 6 | Average Train Loss: 2.3463 \n",
      "| Client : 51 | Average Loss: 2.3463 \n",
      "| Global Round : 6 | Local Epoch : 1 | Train Loss: 2.4236 | Train Accuracy: 0.17\n",
      "| Global Round : 6 | Average Train Loss: 2.4236 \n",
      "| Client : 65 | Average Loss: 2.4236 \n",
      "| Global Round : 6 | Local Epoch : 1 | Train Loss: 2.4173 | Train Accuracy: 0.14\n",
      "| Global Round : 6 | Average Train Loss: 2.4173 \n",
      "| Client : 9 | Average Loss: 2.4173 \n",
      "\n",
      "Average training statistics (global epoch : 6\n",
      "|---- Trainig Loss : 2.6449271794601725\n",
      "|---- Training Accuracy: 21.38% \n",
      "\n",
      "Epoch: 7 \n",
      "\n",
      "| Global Round : 7 | Local Epoch : 1 | Train Loss: 2.3704 | Train Accuracy: 0.15\n",
      "| Global Round : 7 | Average Train Loss: 2.3704 \n",
      "| Client : 81 | Average Loss: 2.3704 \n",
      "| Global Round : 7 | Local Epoch : 1 | Train Loss: 2.2542 | Train Accuracy: 0.17\n",
      "| Global Round : 7 | Average Train Loss: 2.2542 \n",
      "| Client : 35 | Average Loss: 2.2542 \n",
      "| Global Round : 7 | Local Epoch : 1 | Train Loss: 2.2954 | Train Accuracy: 0.17\n",
      "| Global Round : 7 | Average Train Loss: 2.2954 \n",
      "| Client : 57 | Average Loss: 2.2954 \n",
      "| Global Round : 7 | Local Epoch : 1 | Train Loss: 2.3247 | Train Accuracy: 0.19\n",
      "| Global Round : 7 | Average Train Loss: 2.3247 \n",
      "| Client : 6 | Average Loss: 2.3247 \n",
      "| Global Round : 7 | Local Epoch : 1 | Train Loss: 2.3132 | Train Accuracy: 0.17\n",
      "| Global Round : 7 | Average Train Loss: 2.3132 \n",
      "| Client : 88 | Average Loss: 2.3132 \n",
      "| Global Round : 7 | Local Epoch : 1 | Train Loss: 2.3838 | Train Accuracy: 0.16\n",
      "| Global Round : 7 | Average Train Loss: 2.3838 \n",
      "| Client : 66 | Average Loss: 2.3838 \n",
      "| Global Round : 7 | Local Epoch : 1 | Train Loss: 2.3624 | Train Accuracy: 0.15\n",
      "| Global Round : 7 | Average Train Loss: 2.3624 \n",
      "| Client : 78 | Average Loss: 2.3624 \n",
      "| Global Round : 7 | Local Epoch : 1 | Train Loss: 2.3211 | Train Accuracy: 0.19\n",
      "| Global Round : 7 | Average Train Loss: 2.3211 \n",
      "| Client : 2 | Average Loss: 2.3211 \n",
      "| Global Round : 7 | Local Epoch : 1 | Train Loss: 2.2776 | Train Accuracy: 0.17\n",
      "| Global Round : 7 | Average Train Loss: 2.2776 \n",
      "| Client : 91 | Average Loss: 2.2776 \n",
      "| Global Round : 7 | Local Epoch : 1 | Train Loss: 2.2395 | Train Accuracy: 0.20\n",
      "| Global Round : 7 | Average Train Loss: 2.2395 \n",
      "| Client : 12 | Average Loss: 2.2395 \n",
      "\n",
      "Average training statistics (global epoch : 7\n",
      "|---- Trainig Loss : 2.5976853841448593\n",
      "|---- Training Accuracy: 20.82% \n",
      "\n",
      "Epoch: 8 \n",
      "\n",
      "| Global Round : 8 | Local Epoch : 1 | Train Loss: 2.2447 | Train Accuracy: 0.18\n",
      "| Global Round : 8 | Average Train Loss: 2.2447 \n",
      "| Client : 98 | Average Loss: 2.2447 \n",
      "| Global Round : 8 | Local Epoch : 1 | Train Loss: 2.3123 | Train Accuracy: 0.16\n",
      "| Global Round : 8 | Average Train Loss: 2.3123 \n",
      "| Client : 18 | Average Loss: 2.3123 \n",
      "| Global Round : 8 | Local Epoch : 1 | Train Loss: 2.2081 | Train Accuracy: 0.22\n",
      "| Global Round : 8 | Average Train Loss: 2.2081 \n",
      "| Client : 22 | Average Loss: 2.2081 \n",
      "| Global Round : 8 | Local Epoch : 1 | Train Loss: 2.2825 | Train Accuracy: 0.18\n",
      "| Global Round : 8 | Average Train Loss: 2.2825 \n",
      "| Client : 47 | Average Loss: 2.2825 \n",
      "| Global Round : 8 | Local Epoch : 1 | Train Loss: 2.2667 | Train Accuracy: 0.18\n",
      "| Global Round : 8 | Average Train Loss: 2.2667 \n",
      "| Client : 23 | Average Loss: 2.2667 \n",
      "| Global Round : 8 | Local Epoch : 1 | Train Loss: 2.2276 | Train Accuracy: 0.16\n",
      "| Global Round : 8 | Average Train Loss: 2.2276 \n",
      "| Client : 17 | Average Loss: 2.2276 \n",
      "| Global Round : 8 | Local Epoch : 1 | Train Loss: 2.1826 | Train Accuracy: 0.19\n",
      "| Global Round : 8 | Average Train Loss: 2.1826 \n",
      "| Client : 44 | Average Loss: 2.1826 \n",
      "| Global Round : 8 | Local Epoch : 1 | Train Loss: 2.2212 | Train Accuracy: 0.18\n",
      "| Global Round : 8 | Average Train Loss: 2.2212 \n",
      "| Client : 88 | Average Loss: 2.2212 \n",
      "| Global Round : 8 | Local Epoch : 1 | Train Loss: 2.2260 | Train Accuracy: 0.16\n",
      "| Global Round : 8 | Average Train Loss: 2.2260 \n",
      "| Client : 94 | Average Loss: 2.2260 \n",
      "| Global Round : 8 | Local Epoch : 1 | Train Loss: 2.2233 | Train Accuracy: 0.19\n",
      "| Global Round : 8 | Average Train Loss: 2.2233 \n",
      "| Client : 3 | Average Loss: 2.2233 \n",
      "\n",
      "Average training statistics (global epoch : 8\n",
      "|---- Trainig Loss : 2.552914014094406\n",
      "|---- Training Accuracy: 23.22% \n",
      "\n",
      "Epoch: 9 \n",
      "\n",
      "| Global Round : 9 | Local Epoch : 1 | Train Loss: 2.2175 | Train Accuracy: 0.19\n",
      "| Global Round : 9 | Average Train Loss: 2.2175 \n",
      "| Client : 85 | Average Loss: 2.2175 \n",
      "| Global Round : 9 | Local Epoch : 1 | Train Loss: 2.2158 | Train Accuracy: 0.18\n",
      "| Global Round : 9 | Average Train Loss: 2.2158 \n",
      "| Client : 95 | Average Loss: 2.2158 \n",
      "| Global Round : 9 | Local Epoch : 1 | Train Loss: 2.2045 | Train Accuracy: 0.20\n",
      "| Global Round : 9 | Average Train Loss: 2.2045 \n",
      "| Client : 54 | Average Loss: 2.2045 \n",
      "| Global Round : 9 | Local Epoch : 1 | Train Loss: 2.1957 | Train Accuracy: 0.24\n",
      "| Global Round : 9 | Average Train Loss: 2.1957 \n",
      "| Client : 1 | Average Loss: 2.1957 \n",
      "| Global Round : 9 | Local Epoch : 1 | Train Loss: 2.2958 | Train Accuracy: 0.17\n",
      "| Global Round : 9 | Average Train Loss: 2.2958 \n",
      "| Client : 72 | Average Loss: 2.2958 \n",
      "| Global Round : 9 | Local Epoch : 1 | Train Loss: 2.2455 | Train Accuracy: 0.18\n",
      "| Global Round : 9 | Average Train Loss: 2.2455 \n",
      "| Client : 6 | Average Loss: 2.2455 \n",
      "| Global Round : 9 | Local Epoch : 1 | Train Loss: 2.2721 | Train Accuracy: 0.16\n",
      "| Global Round : 9 | Average Train Loss: 2.2721 \n",
      "| Client : 0 | Average Loss: 2.2721 \n",
      "| Global Round : 9 | Local Epoch : 1 | Train Loss: 2.2909 | Train Accuracy: 0.19\n",
      "| Global Round : 9 | Average Train Loss: 2.2909 \n",
      "| Client : 42 | Average Loss: 2.2909 \n",
      "| Global Round : 9 | Local Epoch : 1 | Train Loss: 2.2452 | Train Accuracy: 0.17\n",
      "| Global Round : 9 | Average Train Loss: 2.2452 \n",
      "| Client : 15 | Average Loss: 2.2452 \n",
      "| Global Round : 9 | Local Epoch : 1 | Train Loss: 2.2723 | Train Accuracy: 0.16\n",
      "| Global Round : 9 | Average Train Loss: 2.2723 \n",
      "| Client : 51 | Average Loss: 2.2723 \n",
      "\n",
      "Average training statistics (global epoch : 9\n",
      "|---- Trainig Loss : 2.518758373819752\n",
      "|---- Training Accuracy: 23.06% \n",
      "\n",
      "Epoch: 10 \n",
      "\n",
      "| Global Round : 10 | Local Epoch : 1 | Train Loss: 2.1661 | Train Accuracy: 0.21\n",
      "| Global Round : 10 | Average Train Loss: 2.1661 \n",
      "| Client : 9 | Average Loss: 2.1661 \n",
      "| Global Round : 10 | Local Epoch : 1 | Train Loss: 2.1924 | Train Accuracy: 0.21\n",
      "| Global Round : 10 | Average Train Loss: 2.1924 \n",
      "| Client : 55 | Average Loss: 2.1924 \n",
      "| Global Round : 10 | Local Epoch : 1 | Train Loss: 2.2252 | Train Accuracy: 0.19\n",
      "| Global Round : 10 | Average Train Loss: 2.2252 \n",
      "| Client : 74 | Average Loss: 2.2252 \n",
      "| Global Round : 10 | Local Epoch : 1 | Train Loss: 2.2846 | Train Accuracy: 0.17\n",
      "| Global Round : 10 | Average Train Loss: 2.2846 \n",
      "| Client : 46 | Average Loss: 2.2846 \n",
      "| Global Round : 10 | Local Epoch : 1 | Train Loss: 2.1465 | Train Accuracy: 0.21\n",
      "| Global Round : 10 | Average Train Loss: 2.1465 \n",
      "| Client : 58 | Average Loss: 2.1465 \n",
      "| Global Round : 10 | Local Epoch : 1 | Train Loss: 2.2314 | Train Accuracy: 0.17\n",
      "| Global Round : 10 | Average Train Loss: 2.2314 \n",
      "| Client : 18 | Average Loss: 2.2314 \n",
      "| Global Round : 10 | Local Epoch : 1 | Train Loss: 2.2454 | Train Accuracy: 0.20\n",
      "| Global Round : 10 | Average Train Loss: 2.2454 \n",
      "| Client : 38 | Average Loss: 2.2454 \n",
      "| Global Round : 10 | Local Epoch : 1 | Train Loss: 2.2689 | Train Accuracy: 0.20\n",
      "| Global Round : 10 | Average Train Loss: 2.2689 \n",
      "| Client : 19 | Average Loss: 2.2689 \n",
      "| Global Round : 10 | Local Epoch : 1 | Train Loss: 2.2789 | Train Accuracy: 0.15\n",
      "| Global Round : 10 | Average Train Loss: 2.2789 \n",
      "| Client : 5 | Average Loss: 2.2789 \n",
      "| Global Round : 10 | Local Epoch : 1 | Train Loss: 2.2545 | Train Accuracy: 0.19\n",
      "| Global Round : 10 | Average Train Loss: 2.2545 \n",
      "| Client : 37 | Average Loss: 2.2545 \n",
      "\n",
      "Average training statistics (global epoch : 10\n",
      "|---- Trainig Loss : 2.489821437623766\n",
      "|---- Training Accuracy: 22.52% \n",
      "\n",
      "Epoch: 11 \n",
      "\n",
      "| Global Round : 11 | Local Epoch : 1 | Train Loss: 2.1448 | Train Accuracy: 0.22\n",
      "| Global Round : 11 | Average Train Loss: 2.1448 \n",
      "| Client : 68 | Average Loss: 2.1448 \n",
      "| Global Round : 11 | Local Epoch : 1 | Train Loss: 2.1511 | Train Accuracy: 0.22\n",
      "| Global Round : 11 | Average Train Loss: 2.1511 \n",
      "| Client : 16 | Average Loss: 2.1511 \n",
      "| Global Round : 11 | Local Epoch : 1 | Train Loss: 2.2039 | Train Accuracy: 0.20\n",
      "| Global Round : 11 | Average Train Loss: 2.2039 \n",
      "| Client : 18 | Average Loss: 2.2039 \n",
      "| Global Round : 11 | Local Epoch : 1 | Train Loss: 2.2604 | Train Accuracy: 0.20\n",
      "| Global Round : 11 | Average Train Loss: 2.2604 \n",
      "| Client : 48 | Average Loss: 2.2604 \n",
      "| Global Round : 11 | Local Epoch : 1 | Train Loss: 2.1665 | Train Accuracy: 0.18\n",
      "| Global Round : 11 | Average Train Loss: 2.1665 \n",
      "| Client : 98 | Average Loss: 2.1665 \n",
      "| Global Round : 11 | Local Epoch : 1 | Train Loss: 2.1188 | Train Accuracy: 0.24\n",
      "| Global Round : 11 | Average Train Loss: 2.1188 \n",
      "| Client : 47 | Average Loss: 2.1188 \n",
      "| Global Round : 11 | Local Epoch : 1 | Train Loss: 2.1425 | Train Accuracy: 0.22\n",
      "| Global Round : 11 | Average Train Loss: 2.1425 \n",
      "| Client : 39 | Average Loss: 2.1425 \n",
      "| Global Round : 11 | Local Epoch : 1 | Train Loss: 2.2034 | Train Accuracy: 0.20\n",
      "| Global Round : 11 | Average Train Loss: 2.2034 \n",
      "| Client : 67 | Average Loss: 2.2034 \n",
      "| Global Round : 11 | Local Epoch : 1 | Train Loss: 2.1781 | Train Accuracy: 0.21\n",
      "| Global Round : 11 | Average Train Loss: 2.1781 \n",
      "| Client : 37 | Average Loss: 2.1781 \n",
      "| Global Round : 11 | Local Epoch : 1 | Train Loss: 2.2111 | Train Accuracy: 0.19\n",
      "| Global Round : 11 | Average Train Loss: 2.2111 \n",
      "| Client : 69 | Average Loss: 2.2111 \n",
      "\n",
      "Average training statistics (global epoch : 11\n",
      "|---- Trainig Loss : 2.4614796936391583\n",
      "|---- Training Accuracy: 24.30% \n",
      "\n",
      "Epoch: 12 \n",
      "\n",
      "| Global Round : 12 | Local Epoch : 1 | Train Loss: 2.1507 | Train Accuracy: 0.22\n",
      "| Global Round : 12 | Average Train Loss: 2.1507 \n",
      "| Client : 11 | Average Loss: 2.1507 \n",
      "| Global Round : 12 | Local Epoch : 1 | Train Loss: 2.1358 | Train Accuracy: 0.23\n",
      "| Global Round : 12 | Average Train Loss: 2.1358 \n",
      "| Client : 26 | Average Loss: 2.1358 \n",
      "| Global Round : 12 | Local Epoch : 1 | Train Loss: 2.1201 | Train Accuracy: 0.20\n",
      "| Global Round : 12 | Average Train Loss: 2.1201 \n",
      "| Client : 29 | Average Loss: 2.1201 \n",
      "| Global Round : 12 | Local Epoch : 1 | Train Loss: 2.1186 | Train Accuracy: 0.28\n",
      "| Global Round : 12 | Average Train Loss: 2.1186 \n",
      "| Client : 34 | Average Loss: 2.1186 \n",
      "| Global Round : 12 | Local Epoch : 1 | Train Loss: 2.1640 | Train Accuracy: 0.20\n",
      "| Global Round : 12 | Average Train Loss: 2.1640 \n",
      "| Client : 10 | Average Loss: 2.1640 \n",
      "| Global Round : 12 | Local Epoch : 1 | Train Loss: 2.1531 | Train Accuracy: 0.22\n",
      "| Global Round : 12 | Average Train Loss: 2.1531 \n",
      "| Client : 79 | Average Loss: 2.1531 \n",
      "| Global Round : 12 | Local Epoch : 1 | Train Loss: 2.1898 | Train Accuracy: 0.19\n",
      "| Global Round : 12 | Average Train Loss: 2.1898 \n",
      "| Client : 0 | Average Loss: 2.1898 \n",
      "| Global Round : 12 | Local Epoch : 1 | Train Loss: 2.1431 | Train Accuracy: 0.22\n",
      "| Global Round : 12 | Average Train Loss: 2.1431 \n",
      "| Client : 8 | Average Loss: 2.1431 \n",
      "| Global Round : 12 | Local Epoch : 1 | Train Loss: 2.1865 | Train Accuracy: 0.21\n",
      "| Global Round : 12 | Average Train Loss: 2.1865 \n",
      "| Client : 76 | Average Loss: 2.1865 \n",
      "| Global Round : 12 | Local Epoch : 1 | Train Loss: 2.1521 | Train Accuracy: 0.20\n",
      "| Global Round : 12 | Average Train Loss: 2.1521 \n",
      "| Client : 33 | Average Loss: 2.1521 \n",
      "\n",
      "Average training statistics (global epoch : 12\n",
      "|---- Trainig Loss : 2.43563887057481\n",
      "|---- Training Accuracy: 24.12% \n",
      "\n",
      "Epoch: 13 \n",
      "\n",
      "| Global Round : 13 | Local Epoch : 1 | Train Loss: 2.1196 | Train Accuracy: 0.19\n",
      "| Global Round : 13 | Average Train Loss: 2.1196 \n",
      "| Client : 74 | Average Loss: 2.1196 \n",
      "| Global Round : 13 | Local Epoch : 1 | Train Loss: 2.0867 | Train Accuracy: 0.25\n",
      "| Global Round : 13 | Average Train Loss: 2.0867 \n",
      "| Client : 1 | Average Loss: 2.0867 \n",
      "| Global Round : 13 | Local Epoch : 1 | Train Loss: 2.1741 | Train Accuracy: 0.22\n",
      "| Global Round : 13 | Average Train Loss: 2.1741 \n",
      "| Client : 69 | Average Loss: 2.1741 \n",
      "| Global Round : 13 | Local Epoch : 1 | Train Loss: 2.0760 | Train Accuracy: 0.22\n",
      "| Global Round : 13 | Average Train Loss: 2.0760 \n",
      "| Client : 35 | Average Loss: 2.0760 \n",
      "| Global Round : 13 | Local Epoch : 1 | Train Loss: 2.0994 | Train Accuracy: 0.20\n",
      "| Global Round : 13 | Average Train Loss: 2.0994 \n",
      "| Client : 85 | Average Loss: 2.0994 \n",
      "| Global Round : 13 | Local Epoch : 1 | Train Loss: 2.1648 | Train Accuracy: 0.19\n",
      "| Global Round : 13 | Average Train Loss: 2.1648 \n",
      "| Client : 33 | Average Loss: 2.1648 \n",
      "| Global Round : 13 | Local Epoch : 1 | Train Loss: 2.0658 | Train Accuracy: 0.26\n",
      "| Global Round : 13 | Average Train Loss: 2.0658 \n",
      "| Client : 22 | Average Loss: 2.0658 \n",
      "| Global Round : 13 | Local Epoch : 1 | Train Loss: 2.1903 | Train Accuracy: 0.20\n",
      "| Global Round : 13 | Average Train Loss: 2.1903 \n",
      "| Client : 55 | Average Loss: 2.1903 \n",
      "| Global Round : 13 | Local Epoch : 1 | Train Loss: 2.1256 | Train Accuracy: 0.21\n",
      "| Global Round : 13 | Average Train Loss: 2.1256 \n",
      "| Client : 84 | Average Loss: 2.1256 \n",
      "| Global Round : 13 | Local Epoch : 1 | Train Loss: 2.1877 | Train Accuracy: 0.19\n",
      "| Global Round : 13 | Average Train Loss: 2.1877 \n",
      "| Client : 18 | Average Loss: 2.1877 \n",
      "\n",
      "Average training statistics (global epoch : 13\n",
      "|---- Trainig Loss : 2.4120514192336646\n",
      "|---- Training Accuracy: 24.10% \n",
      "\n",
      "Epoch: 14 \n",
      "\n",
      "| Global Round : 14 | Local Epoch : 1 | Train Loss: 2.2085 | Train Accuracy: 0.18\n",
      "| Global Round : 14 | Average Train Loss: 2.2085 \n",
      "| Client : 38 | Average Loss: 2.2085 \n",
      "| Global Round : 14 | Local Epoch : 1 | Train Loss: 2.1091 | Train Accuracy: 0.19\n",
      "| Global Round : 14 | Average Train Loss: 2.1091 \n",
      "| Client : 56 | Average Loss: 2.1091 \n",
      "| Global Round : 14 | Local Epoch : 1 | Train Loss: 2.1712 | Train Accuracy: 0.20\n",
      "| Global Round : 14 | Average Train Loss: 2.1712 \n",
      "| Client : 28 | Average Loss: 2.1712 \n",
      "| Global Round : 14 | Local Epoch : 1 | Train Loss: 2.1708 | Train Accuracy: 0.19\n",
      "| Global Round : 14 | Average Train Loss: 2.1708 \n",
      "| Client : 2 | Average Loss: 2.1708 \n",
      "| Global Round : 14 | Local Epoch : 1 | Train Loss: 2.1156 | Train Accuracy: 0.21\n",
      "| Global Round : 14 | Average Train Loss: 2.1156 \n",
      "| Client : 92 | Average Loss: 2.1156 \n",
      "| Global Round : 14 | Local Epoch : 1 | Train Loss: 2.1683 | Train Accuracy: 0.23\n",
      "| Global Round : 14 | Average Train Loss: 2.1683 \n",
      "| Client : 73 | Average Loss: 2.1683 \n",
      "| Global Round : 14 | Local Epoch : 1 | Train Loss: 2.1144 | Train Accuracy: 0.24\n",
      "| Global Round : 14 | Average Train Loss: 2.1144 \n",
      "| Client : 0 | Average Loss: 2.1144 \n",
      "| Global Round : 14 | Local Epoch : 1 | Train Loss: 2.2178 | Train Accuracy: 0.20\n",
      "| Global Round : 14 | Average Train Loss: 2.2178 \n",
      "| Client : 69 | Average Loss: 2.2178 \n",
      "| Global Round : 14 | Local Epoch : 1 | Train Loss: 2.1383 | Train Accuracy: 0.22\n",
      "| Global Round : 14 | Average Train Loss: 2.1383 \n",
      "| Client : 13 | Average Loss: 2.1383 \n",
      "| Global Round : 14 | Local Epoch : 1 | Train Loss: 2.1142 | Train Accuracy: 0.22\n",
      "| Global Round : 14 | Average Train Loss: 2.1142 \n",
      "| Client : 91 | Average Loss: 2.1142 \n",
      "\n",
      "Average training statistics (global epoch : 14\n",
      "|---- Trainig Loss : 2.393534253249093\n",
      "|---- Training Accuracy: 22.60% \n",
      "\n",
      "Epoch: 15 \n",
      "\n",
      "| Global Round : 15 | Local Epoch : 1 | Train Loss: 2.1532 | Train Accuracy: 0.18\n",
      "| Global Round : 15 | Average Train Loss: 2.1532 \n",
      "| Client : 11 | Average Loss: 2.1532 \n",
      "| Global Round : 15 | Local Epoch : 1 | Train Loss: 2.1314 | Train Accuracy: 0.21\n",
      "| Global Round : 15 | Average Train Loss: 2.1314 \n",
      "| Client : 54 | Average Loss: 2.1314 \n",
      "| Global Round : 15 | Local Epoch : 1 | Train Loss: 2.1156 | Train Accuracy: 0.20\n",
      "| Global Round : 15 | Average Train Loss: 2.1156 \n",
      "| Client : 31 | Average Loss: 2.1156 \n",
      "| Global Round : 15 | Local Epoch : 1 | Train Loss: 2.1136 | Train Accuracy: 0.22\n",
      "| Global Round : 15 | Average Train Loss: 2.1136 \n",
      "| Client : 13 | Average Loss: 2.1136 \n",
      "| Global Round : 15 | Local Epoch : 1 | Train Loss: 2.1817 | Train Accuracy: 0.21\n",
      "| Global Round : 15 | Average Train Loss: 2.1817 \n",
      "| Client : 20 | Average Loss: 2.1817 \n",
      "| Global Round : 15 | Local Epoch : 1 | Train Loss: 2.1217 | Train Accuracy: 0.21\n",
      "| Global Round : 15 | Average Train Loss: 2.1217 \n",
      "| Client : 97 | Average Loss: 2.1217 \n",
      "| Global Round : 15 | Local Epoch : 1 | Train Loss: 2.1039 | Train Accuracy: 0.19\n",
      "| Global Round : 15 | Average Train Loss: 2.1039 \n",
      "| Client : 3 | Average Loss: 2.1039 \n",
      "| Global Round : 15 | Local Epoch : 1 | Train Loss: 2.1341 | Train Accuracy: 0.21\n",
      "| Global Round : 15 | Average Train Loss: 2.1341 \n",
      "| Client : 87 | Average Loss: 2.1341 \n",
      "| Global Round : 15 | Local Epoch : 1 | Train Loss: 2.0921 | Train Accuracy: 0.21\n",
      "| Global Round : 15 | Average Train Loss: 2.0921 \n",
      "| Client : 80 | Average Loss: 2.0921 \n",
      "| Global Round : 15 | Local Epoch : 1 | Train Loss: 2.0989 | Train Accuracy: 0.22\n",
      "| Global Round : 15 | Average Train Loss: 2.0989 \n",
      "| Client : 79 | Average Loss: 2.0989 \n",
      "\n",
      "Average training statistics (global epoch : 15\n",
      "|---- Trainig Loss : 2.375606633309965\n",
      "|---- Training Accuracy: 22.46% \n",
      "\n",
      "Epoch: 16 \n",
      "\n",
      "| Global Round : 16 | Local Epoch : 1 | Train Loss: 2.1333 | Train Accuracy: 0.22\n",
      "| Global Round : 16 | Average Train Loss: 2.1333 \n",
      "| Client : 83 | Average Loss: 2.1333 \n",
      "| Global Round : 16 | Local Epoch : 1 | Train Loss: 2.0734 | Train Accuracy: 0.22\n",
      "| Global Round : 16 | Average Train Loss: 2.0734 \n",
      "| Client : 25 | Average Loss: 2.0734 \n",
      "| Global Round : 16 | Local Epoch : 1 | Train Loss: 2.1197 | Train Accuracy: 0.21\n",
      "| Global Round : 16 | Average Train Loss: 2.1197 \n",
      "| Client : 10 | Average Loss: 2.1197 \n",
      "| Global Round : 16 | Local Epoch : 1 | Train Loss: 2.1073 | Train Accuracy: 0.23\n",
      "| Global Round : 16 | Average Train Loss: 2.1073 \n",
      "| Client : 1 | Average Loss: 2.1073 \n",
      "| Global Round : 16 | Local Epoch : 1 | Train Loss: 2.0872 | Train Accuracy: 0.24\n",
      "| Global Round : 16 | Average Train Loss: 2.0872 \n",
      "| Client : 22 | Average Loss: 2.0872 \n",
      "| Global Round : 16 | Local Epoch : 1 | Train Loss: 2.1203 | Train Accuracy: 0.22\n",
      "| Global Round : 16 | Average Train Loss: 2.1203 \n",
      "| Client : 84 | Average Loss: 2.1203 \n",
      "| Global Round : 16 | Local Epoch : 1 | Train Loss: 2.1942 | Train Accuracy: 0.20\n",
      "| Global Round : 16 | Average Train Loss: 2.1942 \n",
      "| Client : 37 | Average Loss: 2.1942 \n",
      "| Global Round : 16 | Local Epoch : 1 | Train Loss: 2.1731 | Train Accuracy: 0.23\n",
      "| Global Round : 16 | Average Train Loss: 2.1731 \n",
      "| Client : 16 | Average Loss: 2.1731 \n",
      "| Global Round : 16 | Local Epoch : 1 | Train Loss: 2.1226 | Train Accuracy: 0.22\n",
      "| Global Round : 16 | Average Train Loss: 2.1226 \n",
      "| Client : 60 | Average Loss: 2.1226 \n",
      "| Global Round : 16 | Local Epoch : 1 | Train Loss: 2.1382 | Train Accuracy: 0.21\n",
      "| Global Round : 16 | Average Train Loss: 2.1382 \n",
      "| Client : 46 | Average Loss: 2.1382 \n",
      "\n",
      "Average training statistics (global epoch : 16\n",
      "|---- Trainig Loss : 2.3600646685229405\n",
      "|---- Training Accuracy: 24.76% \n",
      "\n",
      "Epoch: 17 \n",
      "\n",
      "| Global Round : 17 | Local Epoch : 1 | Train Loss: 2.1950 | Train Accuracy: 0.20\n",
      "| Global Round : 17 | Average Train Loss: 2.1950 \n",
      "| Client : 66 | Average Loss: 2.1950 \n",
      "| Global Round : 17 | Local Epoch : 1 | Train Loss: 2.0968 | Train Accuracy: 0.25\n",
      "| Global Round : 17 | Average Train Loss: 2.0968 \n",
      "| Client : 71 | Average Loss: 2.0968 \n",
      "| Global Round : 17 | Local Epoch : 1 | Train Loss: 2.1182 | Train Accuracy: 0.23\n",
      "| Global Round : 17 | Average Train Loss: 2.1182 \n",
      "| Client : 37 | Average Loss: 2.1182 \n",
      "| Global Round : 17 | Local Epoch : 1 | Train Loss: 2.0860 | Train Accuracy: 0.24\n",
      "| Global Round : 17 | Average Train Loss: 2.0860 \n",
      "| Client : 77 | Average Loss: 2.0860 \n",
      "| Global Round : 17 | Local Epoch : 1 | Train Loss: 2.1312 | Train Accuracy: 0.20\n",
      "| Global Round : 17 | Average Train Loss: 2.1312 \n",
      "| Client : 63 | Average Loss: 2.1312 \n",
      "| Global Round : 17 | Local Epoch : 1 | Train Loss: 2.1465 | Train Accuracy: 0.20\n",
      "| Global Round : 17 | Average Train Loss: 2.1465 \n",
      "| Client : 79 | Average Loss: 2.1465 \n",
      "| Global Round : 17 | Local Epoch : 1 | Train Loss: 2.1783 | Train Accuracy: 0.19\n",
      "| Global Round : 17 | Average Train Loss: 2.1783 \n",
      "| Client : 87 | Average Loss: 2.1783 \n",
      "| Global Round : 17 | Local Epoch : 1 | Train Loss: 2.1386 | Train Accuracy: 0.22\n",
      "| Global Round : 17 | Average Train Loss: 2.1386 \n",
      "| Client : 7 | Average Loss: 2.1386 \n",
      "| Global Round : 17 | Local Epoch : 1 | Train Loss: 2.2040 | Train Accuracy: 0.19\n",
      "| Global Round : 17 | Average Train Loss: 2.2040 \n",
      "| Client : 91 | Average Loss: 2.2040 \n",
      "| Global Round : 17 | Local Epoch : 1 | Train Loss: 2.1316 | Train Accuracy: 0.20\n",
      "| Global Round : 17 | Average Train Loss: 2.1316 \n",
      "| Client : 70 | Average Loss: 2.1316 \n",
      "\n",
      "Average training statistics (global epoch : 17\n",
      "|---- Trainig Loss : 2.347274348424151\n",
      "|---- Training Accuracy: 23.78% \n",
      "\n",
      "Epoch: 18 \n",
      "\n",
      "| Global Round : 18 | Local Epoch : 1 | Train Loss: 2.0982 | Train Accuracy: 0.22\n",
      "| Global Round : 18 | Average Train Loss: 2.0982 \n",
      "| Client : 97 | Average Loss: 2.0982 \n",
      "| Global Round : 18 | Local Epoch : 1 | Train Loss: 2.0765 | Train Accuracy: 0.23\n",
      "| Global Round : 18 | Average Train Loss: 2.0765 \n",
      "| Client : 21 | Average Loss: 2.0765 \n",
      "| Global Round : 18 | Local Epoch : 1 | Train Loss: 2.0877 | Train Accuracy: 0.25\n",
      "| Global Round : 18 | Average Train Loss: 2.0877 \n",
      "| Client : 0 | Average Loss: 2.0877 \n",
      "| Global Round : 18 | Local Epoch : 1 | Train Loss: 2.0506 | Train Accuracy: 0.21\n",
      "| Global Round : 18 | Average Train Loss: 2.0506 \n",
      "| Client : 70 | Average Loss: 2.0506 \n",
      "| Global Round : 18 | Local Epoch : 1 | Train Loss: 2.0982 | Train Accuracy: 0.22\n",
      "| Global Round : 18 | Average Train Loss: 2.0982 \n",
      "| Client : 46 | Average Loss: 2.0982 \n",
      "| Global Round : 18 | Local Epoch : 1 | Train Loss: 2.0844 | Train Accuracy: 0.25\n",
      "| Global Round : 18 | Average Train Loss: 2.0844 \n",
      "| Client : 69 | Average Loss: 2.0844 \n",
      "| Global Round : 18 | Local Epoch : 1 | Train Loss: 2.0825 | Train Accuracy: 0.22\n",
      "| Global Round : 18 | Average Train Loss: 2.0825 \n",
      "| Client : 31 | Average Loss: 2.0825 \n",
      "| Global Round : 18 | Local Epoch : 1 | Train Loss: 2.1435 | Train Accuracy: 0.20\n",
      "| Global Round : 18 | Average Train Loss: 2.1435 \n",
      "| Client : 76 | Average Loss: 2.1435 \n",
      "| Global Round : 18 | Local Epoch : 1 | Train Loss: 2.0543 | Train Accuracy: 0.22\n",
      "| Global Round : 18 | Average Train Loss: 2.0543 \n",
      "| Client : 27 | Average Loss: 2.0543 \n",
      "| Global Round : 18 | Local Epoch : 1 | Train Loss: 2.0889 | Train Accuracy: 0.26\n",
      "| Global Round : 18 | Average Train Loss: 2.0889 \n",
      "| Client : 60 | Average Loss: 2.0889 \n",
      "\n",
      "Average training statistics (global epoch : 18\n",
      "|---- Trainig Loss : 2.3327862232555576\n",
      "|---- Training Accuracy: 24.78% \n",
      "\n",
      "Epoch: 19 \n",
      "\n",
      "| Global Round : 19 | Local Epoch : 1 | Train Loss: 2.1025 | Train Accuracy: 0.22\n",
      "| Global Round : 19 | Average Train Loss: 2.1025 \n",
      "| Client : 49 | Average Loss: 2.1025 \n",
      "| Global Round : 19 | Local Epoch : 1 | Train Loss: 2.0179 | Train Accuracy: 0.27\n",
      "| Global Round : 19 | Average Train Loss: 2.0179 \n",
      "| Client : 45 | Average Loss: 2.0179 \n",
      "| Global Round : 19 | Local Epoch : 1 | Train Loss: 2.0940 | Train Accuracy: 0.23\n",
      "| Global Round : 19 | Average Train Loss: 2.0940 \n",
      "| Client : 31 | Average Loss: 2.0940 \n",
      "| Global Round : 19 | Local Epoch : 1 | Train Loss: 2.0990 | Train Accuracy: 0.25\n",
      "| Global Round : 19 | Average Train Loss: 2.0990 \n",
      "| Client : 48 | Average Loss: 2.0990 \n",
      "| Global Round : 19 | Local Epoch : 1 | Train Loss: 2.0704 | Train Accuracy: 0.24\n",
      "| Global Round : 19 | Average Train Loss: 2.0704 \n",
      "| Client : 55 | Average Loss: 2.0704 \n",
      "| Global Round : 19 | Local Epoch : 1 | Train Loss: 2.0967 | Train Accuracy: 0.25\n",
      "| Global Round : 19 | Average Train Loss: 2.0967 \n",
      "| Client : 3 | Average Loss: 2.0967 \n",
      "| Global Round : 19 | Local Epoch : 1 | Train Loss: 2.0900 | Train Accuracy: 0.26\n",
      "| Global Round : 19 | Average Train Loss: 2.0900 \n",
      "| Client : 71 | Average Loss: 2.0900 \n",
      "| Global Round : 19 | Local Epoch : 1 | Train Loss: 2.1588 | Train Accuracy: 0.19\n",
      "| Global Round : 19 | Average Train Loss: 2.1588 \n",
      "| Client : 87 | Average Loss: 2.1588 \n",
      "| Global Round : 19 | Local Epoch : 1 | Train Loss: 2.0583 | Train Accuracy: 0.24\n",
      "| Global Round : 19 | Average Train Loss: 2.0583 \n",
      "| Client : 63 | Average Loss: 2.0583 \n",
      "| Global Round : 19 | Local Epoch : 1 | Train Loss: 2.0603 | Train Accuracy: 0.25\n",
      "| Global Round : 19 | Average Train Loss: 2.0603 \n",
      "| Client : 93 | Average Loss: 2.0603 \n",
      "\n",
      "Average training statistics (global epoch : 19\n",
      "|---- Trainig Loss : 2.3197330109836063\n",
      "|---- Training Accuracy: 24.66% \n",
      "\n",
      "Epoch: 20 \n",
      "\n",
      "| Global Round : 20 | Local Epoch : 1 | Train Loss: 2.1225 | Train Accuracy: 0.23\n",
      "| Global Round : 20 | Average Train Loss: 2.1225 \n",
      "| Client : 15 | Average Loss: 2.1225 \n",
      "| Global Round : 20 | Local Epoch : 1 | Train Loss: 2.0679 | Train Accuracy: 0.23\n",
      "| Global Round : 20 | Average Train Loss: 2.0679 \n",
      "| Client : 14 | Average Loss: 2.0679 \n",
      "| Global Round : 20 | Local Epoch : 1 | Train Loss: 2.0941 | Train Accuracy: 0.24\n",
      "| Global Round : 20 | Average Train Loss: 2.0941 \n",
      "| Client : 27 | Average Loss: 2.0941 \n",
      "| Global Round : 20 | Local Epoch : 1 | Train Loss: 2.0400 | Train Accuracy: 0.24\n",
      "| Global Round : 20 | Average Train Loss: 2.0400 \n",
      "| Client : 40 | Average Loss: 2.0400 \n",
      "| Global Round : 20 | Local Epoch : 1 | Train Loss: 2.0677 | Train Accuracy: 0.23\n",
      "| Global Round : 20 | Average Train Loss: 2.0677 \n",
      "| Client : 82 | Average Loss: 2.0677 \n",
      "| Global Round : 20 | Local Epoch : 1 | Train Loss: 2.0405 | Train Accuracy: 0.27\n",
      "| Global Round : 20 | Average Train Loss: 2.0405 \n",
      "| Client : 96 | Average Loss: 2.0405 \n",
      "| Global Round : 20 | Local Epoch : 1 | Train Loss: 2.0431 | Train Accuracy: 0.21\n",
      "| Global Round : 20 | Average Train Loss: 2.0431 \n",
      "| Client : 23 | Average Loss: 2.0431 \n",
      "| Global Round : 20 | Local Epoch : 1 | Train Loss: 2.1526 | Train Accuracy: 0.18\n",
      "| Global Round : 20 | Average Train Loss: 2.1526 \n",
      "| Client : 76 | Average Loss: 2.1526 \n",
      "| Global Round : 20 | Local Epoch : 1 | Train Loss: 2.0668 | Train Accuracy: 0.23\n",
      "| Global Round : 20 | Average Train Loss: 2.0668 \n",
      "| Client : 86 | Average Loss: 2.0668 \n",
      "| Global Round : 20 | Local Epoch : 1 | Train Loss: 2.0233 | Train Accuracy: 0.26\n",
      "| Global Round : 20 | Average Train Loss: 2.0233 \n",
      "| Client : 58 | Average Loss: 2.0233 \n",
      "\n",
      "Average training statistics (global epoch : 20\n",
      "|---- Trainig Loss : 2.3073392660088006\n",
      "|---- Training Accuracy: 25.54% \n",
      "\n",
      "Epoch: 21 \n",
      "\n",
      "| Global Round : 21 | Local Epoch : 1 | Train Loss: 2.0066 | Train Accuracy: 0.24\n",
      "| Global Round : 21 | Average Train Loss: 2.0066 \n",
      "| Client : 36 | Average Loss: 2.0066 \n",
      "| Global Round : 21 | Local Epoch : 1 | Train Loss: 2.0670 | Train Accuracy: 0.20\n",
      "| Global Round : 21 | Average Train Loss: 2.0670 \n",
      "| Client : 30 | Average Loss: 2.0670 \n",
      "| Global Round : 21 | Local Epoch : 1 | Train Loss: 1.9978 | Train Accuracy: 0.26\n",
      "| Global Round : 21 | Average Train Loss: 1.9978 \n",
      "| Client : 22 | Average Loss: 1.9978 \n",
      "| Global Round : 21 | Local Epoch : 1 | Train Loss: 2.0601 | Train Accuracy: 0.26\n",
      "| Global Round : 21 | Average Train Loss: 2.0601 \n",
      "| Client : 65 | Average Loss: 2.0601 \n",
      "| Global Round : 21 | Local Epoch : 1 | Train Loss: 2.0771 | Train Accuracy: 0.23\n",
      "| Global Round : 21 | Average Train Loss: 2.0771 \n",
      "| Client : 6 | Average Loss: 2.0771 \n",
      "| Global Round : 21 | Local Epoch : 1 | Train Loss: 2.1280 | Train Accuracy: 0.24\n",
      "| Global Round : 21 | Average Train Loss: 2.1280 \n",
      "| Client : 77 | Average Loss: 2.1280 \n",
      "| Global Round : 21 | Local Epoch : 1 | Train Loss: 2.0983 | Train Accuracy: 0.23\n",
      "| Global Round : 21 | Average Train Loss: 2.0983 \n",
      "| Client : 92 | Average Loss: 2.0983 \n",
      "| Global Round : 21 | Local Epoch : 1 | Train Loss: 2.0799 | Train Accuracy: 0.24\n",
      "| Global Round : 21 | Average Train Loss: 2.0799 \n",
      "| Client : 47 | Average Loss: 2.0799 \n",
      "| Global Round : 21 | Local Epoch : 1 | Train Loss: 2.0044 | Train Accuracy: 0.25\n",
      "| Global Round : 21 | Average Train Loss: 2.0044 \n",
      "| Client : 26 | Average Loss: 2.0044 \n",
      "| Global Round : 21 | Local Epoch : 1 | Train Loss: 2.1284 | Train Accuracy: 0.19\n",
      "| Global Round : 21 | Average Train Loss: 2.1284 \n",
      "| Client : 55 | Average Loss: 2.1284 \n",
      "\n",
      "Average training statistics (global epoch : 21\n",
      "|---- Trainig Loss : 2.295786919593811\n",
      "|---- Training Accuracy: 25.32% \n",
      "\n",
      "Epoch: 22 \n",
      "\n",
      "| Global Round : 22 | Local Epoch : 1 | Train Loss: 2.0164 | Train Accuracy: 0.24\n",
      "| Global Round : 22 | Average Train Loss: 2.0164 \n",
      "| Client : 93 | Average Loss: 2.0164 \n",
      "| Global Round : 22 | Local Epoch : 1 | Train Loss: 2.0453 | Train Accuracy: 0.23\n",
      "| Global Round : 22 | Average Train Loss: 2.0453 \n",
      "| Client : 76 | Average Loss: 2.0453 \n",
      "| Global Round : 22 | Local Epoch : 1 | Train Loss: 1.9772 | Train Accuracy: 0.26\n",
      "| Global Round : 22 | Average Train Loss: 1.9772 \n",
      "| Client : 26 | Average Loss: 1.9772 \n",
      "| Global Round : 22 | Local Epoch : 1 | Train Loss: 2.0838 | Train Accuracy: 0.26\n",
      "| Global Round : 22 | Average Train Loss: 2.0838 \n",
      "| Client : 0 | Average Loss: 2.0838 \n",
      "| Global Round : 22 | Local Epoch : 1 | Train Loss: 2.0464 | Train Accuracy: 0.26\n",
      "| Global Round : 22 | Average Train Loss: 2.0464 \n",
      "| Client : 45 | Average Loss: 2.0464 \n",
      "| Global Round : 22 | Local Epoch : 1 | Train Loss: 1.9987 | Train Accuracy: 0.26\n",
      "| Global Round : 22 | Average Train Loss: 1.9987 \n",
      "| Client : 59 | Average Loss: 1.9987 \n",
      "| Global Round : 22 | Local Epoch : 1 | Train Loss: 2.1164 | Train Accuracy: 0.24\n",
      "| Global Round : 22 | Average Train Loss: 2.1164 \n",
      "| Client : 6 | Average Loss: 2.1164 \n",
      "| Global Round : 22 | Local Epoch : 1 | Train Loss: 2.0440 | Train Accuracy: 0.24\n",
      "| Global Round : 22 | Average Train Loss: 2.0440 \n",
      "| Client : 14 | Average Loss: 2.0440 \n",
      "| Global Round : 22 | Local Epoch : 1 | Train Loss: 2.0250 | Train Accuracy: 0.23\n",
      "| Global Round : 22 | Average Train Loss: 2.0250 \n",
      "| Client : 82 | Average Loss: 2.0250 \n",
      "| Global Round : 22 | Local Epoch : 1 | Train Loss: 2.0201 | Train Accuracy: 0.24\n",
      "| Global Round : 22 | Average Train Loss: 2.0201 \n",
      "| Client : 8 | Average Loss: 2.0201 \n",
      "\n",
      "Average training statistics (global epoch : 22\n",
      "|---- Trainig Loss : 2.28403911391894\n",
      "|---- Training Accuracy: 26.84% \n",
      "\n",
      "Epoch: 23 \n",
      "\n",
      "| Global Round : 23 | Local Epoch : 1 | Train Loss: 2.0864 | Train Accuracy: 0.25\n",
      "| Global Round : 23 | Average Train Loss: 2.0864 \n",
      "| Client : 29 | Average Loss: 2.0864 \n",
      "| Global Round : 23 | Local Epoch : 1 | Train Loss: 2.0087 | Train Accuracy: 0.25\n",
      "| Global Round : 23 | Average Train Loss: 2.0087 \n",
      "| Client : 68 | Average Loss: 2.0087 \n",
      "| Global Round : 23 | Local Epoch : 1 | Train Loss: 2.0657 | Train Accuracy: 0.23\n",
      "| Global Round : 23 | Average Train Loss: 2.0657 \n",
      "| Client : 46 | Average Loss: 2.0657 \n",
      "| Global Round : 23 | Local Epoch : 1 | Train Loss: 2.0721 | Train Accuracy: 0.25\n",
      "| Global Round : 23 | Average Train Loss: 2.0721 \n",
      "| Client : 14 | Average Loss: 2.0721 \n",
      "| Global Round : 23 | Local Epoch : 1 | Train Loss: 2.0863 | Train Accuracy: 0.22\n",
      "| Global Round : 23 | Average Train Loss: 2.0863 \n",
      "| Client : 65 | Average Loss: 2.0863 \n",
      "| Global Round : 23 | Local Epoch : 1 | Train Loss: 2.0683 | Train Accuracy: 0.26\n",
      "| Global Round : 23 | Average Train Loss: 2.0683 \n",
      "| Client : 0 | Average Loss: 2.0683 \n",
      "| Global Round : 23 | Local Epoch : 1 | Train Loss: 2.0552 | Train Accuracy: 0.21\n",
      "| Global Round : 23 | Average Train Loss: 2.0552 \n",
      "| Client : 78 | Average Loss: 2.0552 \n",
      "| Global Round : 23 | Local Epoch : 1 | Train Loss: 2.1158 | Train Accuracy: 0.22\n",
      "| Global Round : 23 | Average Train Loss: 2.1158 \n",
      "| Client : 28 | Average Loss: 2.1158 \n",
      "| Global Round : 23 | Local Epoch : 1 | Train Loss: 2.1529 | Train Accuracy: 0.20\n",
      "| Global Round : 23 | Average Train Loss: 2.1529 \n",
      "| Client : 84 | Average Loss: 2.1529 \n",
      "| Global Round : 23 | Local Epoch : 1 | Train Loss: 2.1100 | Train Accuracy: 0.22\n",
      "| Global Round : 23 | Average Train Loss: 2.1100 \n",
      "| Client : 12 | Average Loss: 2.1100 \n",
      "\n",
      "Average training statistics (global epoch : 23\n",
      "|---- Trainig Loss : 2.27526090990518\n",
      "|---- Training Accuracy: 24.30% \n",
      "\n",
      "Epoch: 24 \n",
      "\n",
      "| Global Round : 24 | Local Epoch : 1 | Train Loss: 2.0564 | Train Accuracy: 0.24\n",
      "| Global Round : 24 | Average Train Loss: 2.0564 \n",
      "| Client : 87 | Average Loss: 2.0564 \n",
      "| Global Round : 24 | Local Epoch : 1 | Train Loss: 2.0544 | Train Accuracy: 0.20\n",
      "| Global Round : 24 | Average Train Loss: 2.0544 \n",
      "| Client : 28 | Average Loss: 2.0544 \n",
      "| Global Round : 24 | Local Epoch : 1 | Train Loss: 1.9894 | Train Accuracy: 0.24\n",
      "| Global Round : 24 | Average Train Loss: 1.9894 \n",
      "| Client : 36 | Average Loss: 1.9894 \n",
      "| Global Round : 24 | Local Epoch : 1 | Train Loss: 2.0216 | Train Accuracy: 0.23\n",
      "| Global Round : 24 | Average Train Loss: 2.0216 \n",
      "| Client : 16 | Average Loss: 2.0216 \n",
      "| Global Round : 24 | Local Epoch : 1 | Train Loss: 2.0250 | Train Accuracy: 0.25\n",
      "| Global Round : 24 | Average Train Loss: 2.0250 \n",
      "| Client : 55 | Average Loss: 2.0250 \n",
      "| Global Round : 24 | Local Epoch : 1 | Train Loss: 2.0583 | Train Accuracy: 0.21\n",
      "| Global Round : 24 | Average Train Loss: 2.0583 \n",
      "| Client : 98 | Average Loss: 2.0583 \n",
      "| Global Round : 24 | Local Epoch : 1 | Train Loss: 2.0630 | Train Accuracy: 0.23\n",
      "| Global Round : 24 | Average Train Loss: 2.0630 \n",
      "| Client : 43 | Average Loss: 2.0630 \n",
      "| Global Round : 24 | Local Epoch : 1 | Train Loss: 2.0714 | Train Accuracy: 0.23\n",
      "| Global Round : 24 | Average Train Loss: 2.0714 \n",
      "| Client : 83 | Average Loss: 2.0714 \n",
      "| Global Round : 24 | Local Epoch : 1 | Train Loss: 2.0638 | Train Accuracy: 0.22\n",
      "| Global Round : 24 | Average Train Loss: 2.0638 \n",
      "| Client : 73 | Average Loss: 2.0638 \n",
      "| Global Round : 24 | Local Epoch : 1 | Train Loss: 2.1694 | Train Accuracy: 0.21\n",
      "| Global Round : 24 | Average Train Loss: 2.1694 \n",
      "| Client : 81 | Average Loss: 2.1694 \n",
      "\n",
      "Average training statistics (global epoch : 24\n",
      "|---- Trainig Loss : 2.2661776147727615\n",
      "|---- Training Accuracy: 28.60% \n",
      "\n",
      "Epoch: 25 \n",
      "\n",
      "| Global Round : 25 | Local Epoch : 1 | Train Loss: 2.0478 | Train Accuracy: 0.20\n",
      "| Global Round : 25 | Average Train Loss: 2.0478 \n",
      "| Client : 35 | Average Loss: 2.0478 \n",
      "| Global Round : 25 | Local Epoch : 1 | Train Loss: 2.1873 | Train Accuracy: 0.22\n",
      "| Global Round : 25 | Average Train Loss: 2.1873 \n",
      "| Client : 66 | Average Loss: 2.1873 \n",
      "| Global Round : 25 | Local Epoch : 1 | Train Loss: 1.9582 | Train Accuracy: 0.26\n",
      "| Global Round : 25 | Average Train Loss: 1.9582 \n",
      "| Client : 62 | Average Loss: 1.9582 \n",
      "| Global Round : 25 | Local Epoch : 1 | Train Loss: 2.0647 | Train Accuracy: 0.24\n",
      "| Global Round : 25 | Average Train Loss: 2.0647 \n",
      "| Client : 71 | Average Loss: 2.0647 \n",
      "| Global Round : 25 | Local Epoch : 1 | Train Loss: 2.0784 | Train Accuracy: 0.27\n",
      "| Global Round : 25 | Average Train Loss: 2.0784 \n",
      "| Client : 89 | Average Loss: 2.0784 \n",
      "| Global Round : 25 | Local Epoch : 1 | Train Loss: 2.0523 | Train Accuracy: 0.21\n",
      "| Global Round : 25 | Average Train Loss: 2.0523 \n",
      "| Client : 30 | Average Loss: 2.0523 \n",
      "| Global Round : 25 | Local Epoch : 1 | Train Loss: 2.0346 | Train Accuracy: 0.21\n",
      "| Global Round : 25 | Average Train Loss: 2.0346 \n",
      "| Client : 25 | Average Loss: 2.0346 \n",
      "| Global Round : 25 | Local Epoch : 1 | Train Loss: 2.0161 | Train Accuracy: 0.24\n",
      "| Global Round : 25 | Average Train Loss: 2.0161 \n",
      "| Client : 56 | Average Loss: 2.0161 \n",
      "| Global Round : 25 | Local Epoch : 1 | Train Loss: 2.0765 | Train Accuracy: 0.23\n",
      "| Global Round : 25 | Average Train Loss: 2.0765 \n",
      "| Client : 75 | Average Loss: 2.0765 \n",
      "| Global Round : 25 | Local Epoch : 1 | Train Loss: 2.0413 | Train Accuracy: 0.22\n",
      "| Global Round : 25 | Average Train Loss: 2.0413 \n",
      "| Client : 16 | Average Loss: 2.0413 \n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "train_loss, train_accuracy = [], []\n",
    "val_acc_list, net_list = [], []\n",
    "cv_loss, cv_acc = [], []\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    local_weights = []\n",
    "    local_losses = []\n",
    "\n",
    "    print(f'Epoch: {epoch} \\n')\n",
    "\n",
    "\n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train()\n",
    "\n",
    "    # different clients at each epoch\n",
    "    m = max(int(frac * num_users), 1) # number of users to be used for federated updates, at least 1\n",
    "    idxs_users = np.random.choice(range(num_users), m, replace=False) # choose randomly m users\n",
    "\n",
    "    for idx in idxs_users:  # for each user\n",
    "        # get local model\n",
    "        local_model = LocalUpdate(dataset=train_dataset, idxs=user_groups[idx],\n",
    "                                  gpu=gpu, optimizer=optimizer,\n",
    "                                  local_batch_size=local_batch_size, lr=lr,\n",
    "                                  local_epochs=local_epochs, loss_function=loss_function)\n",
    "\n",
    "        # get updated weight and loss from local model\n",
    "        w, loss = local_model.update_weights(model=copy.deepcopy(model), # pass the global model to the clients\n",
    "                                             global_round=epoch)\n",
    "\n",
    "        print('| Client : {} | Average Loss: {:.4f} '.format(\n",
    "            idx, loss))\n",
    "\n",
    "        local_weights.append(copy.deepcopy(w))\n",
    "        local_losses.append(copy.deepcopy(loss))\n",
    "\n",
    "    # compute global weights (average of local weights)\n",
    "    global_weights = average_weights(local_weights)\n",
    "    # update weights of the global model\n",
    "    model.load_state_dict(global_weights)\n",
    "\n",
    "    # compute average loss\n",
    "    loss_avg = sum(local_losses) / len(local_losses)\n",
    "    train_loss.append(loss_avg)\n",
    "\n",
    "    ######################\n",
    "    # validate the model #\n",
    "    ######################\n",
    "    model.eval()\n",
    "    # calculate avg training accuracy over all users at every epoch\n",
    "    list_acc, list_loss = [], []\n",
    "    for client in range(num_users): # for each client\n",
    "        # get local model\n",
    "        local_model = LocalUpdate(dataset=train_dataset, idxs=user_groups[client],\n",
    "                                  gpu=gpu, optimizer=optimizer,\n",
    "                                  local_batch_size=local_batch_size, lr=lr,\n",
    "                                  local_epochs=local_epochs, loss_function=loss_function)\n",
    "\n",
    "        # get accuracy and loss of local model\n",
    "        acc, loss = local_model.inference(model=model)\n",
    "        list_acc.append(acc)\n",
    "        list_loss.append(loss)\n",
    "\n",
    "    # compute average accuracy\n",
    "    train_accuracy.append(sum(list_acc)/len(list_acc))\n",
    "\n",
    "    # print stats\n",
    "    print(f'\\nAverage training statistics (global epoch : {epoch}')\n",
    "    print(f'|---- Trainig Loss : {np.mean(np.array(train_loss))}')\n",
    "    print('|---- Training Accuracy: {:.2f}% \\n'.format(100*train_accuracy[-1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save train loss and accuracy\n",
    "import pandas as pd\n",
    "\n",
    "filename_csv = 'fedAVG_results/{}_{}_{}_lr_[{}]_C[{}]_iid[{}]_unbalanced[{}]_E[{}]_B[{}]_{}_numGroups[{}].csv'\\\n",
    "    .format(\"ResNet50\", n_epochs, optimizer, lr, frac, iid, unbalanced,\n",
    "           local_epochs, local_batch_size, normalization_type, num_groups)\n",
    "\n",
    "data = list(zip(train_loss, train_accuracy))\n",
    "pd.DataFrame(data, columns=['train_loss','train_accuracy']).to_csv(filename_csv)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "\n",
    "filename_pt = 'fedAVG_results/{}_{}_{}_lr_[{}]_C[{}]_iid[{}]_unbalanced[{}]_E[{}]_B[{}]_{}_numGroups[{}].pt'\\\n",
    "    .format(\"ResNet50\", n_epochs, optimizer, lr, frac, iid, unbalanced,\n",
    "            local_epochs, local_batch_size, normalization_type, num_groups)\n",
    "torch.save(model.state_dict(), filename_pt)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# test the trained model\n",
    "\n",
    "test_acc, test_loss = test_inference(model=model, test_dataset=test_dataset, gpu=gpu,\n",
    "                                     loss_function=loss_function)\n",
    "\n",
    "print(f'\\nResults after {n_epochs} global rounds of training:')\n",
    "print(\"|---- Avgerage Train Accuracy: {:.2f}%\".format(100*train_accuracy[-1]))\n",
    "print(\"|---- Test Accuracy: {:.2f}%\".format(100*test_acc))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}