{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from dataloader import get_dataset\n",
    "from models_server import ResNet50\n",
    "# from models_server_bigResNet import ResNet50\n",
    "from models_client import ResNet8\n",
    "\n",
    "from server import GKTServerTrainer\n",
    "from client import GKTClientTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# parameters\n",
    "normalization_type = \"GroupNorm\" #BatchNorm or GroupNorm\n",
    "iid = 1 # if the data is i.i.d or not\n",
    "unbalanced = 0 # in non i.i.d. setting split the data between clients equally or not\n",
    "num_users = 100 # number of client\n",
    "frac = 0.1 # fraction of the clients to be used for federated updates\n",
    "server_epochs = 3\n",
    "gpu = 0\n",
    "optimizer = \"sgd\" #sgd or adam\n",
    "local_batch_size = 10 # batch size of local updates in each user\n",
    "lr = 0.001 # learning rate\n",
    "client_epochs = 1\n",
    "loss_function = \"CrossEntropyLoss\"\n",
    "\n",
    "partition_alpha = 0.5\n",
    "client_number = num_users  # number of workers in a distributed cluster\n",
    "# the data will be partitioned in client_number groups\n",
    "\n",
    "temperature = 3.0\n",
    "\n",
    "communication_rounds = 2  # number of communication rounds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dataset, test_dataset, user_groups = get_dataset(iid=iid, unbalanced=unbalanced, num_users=num_users)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_client_model():\n",
    "    # client_model = RenNet8(normalization_type)\n",
    "    client_model = ResNet8()\n",
    "    return client_model\n",
    "\n",
    "def create_server_model():\n",
    "    server_model = ResNet50() # actually is a ResNet49 the first layer is done by the ResNet8\n",
    "    return server_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "server_model = create_server_model()\n",
    "client_model = create_client_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "    device = torch.device(\"cpu\")\n",
    "    gpu = 0\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')\n",
    "    device = torch.device(\"cuda\")\n",
    "    gpu = 1\n",
    "\n",
    "server_model.to(device)\n",
    "client_model.to(device)\n",
    "\n",
    "# set the models to train\n",
    "server_model.train()\n",
    "client_model.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 23,503,626 parameters (ResNet49)\n",
    "# 23,520,842 parameters (ResNet50)\n",
    "# summary(server_model, (16, 32, 32))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# summary(client_model, (3, 32, 32))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# init server\n",
    "server_trainer = GKTServerTrainer(server_model, num_users, lr, server_epochs, device,\n",
    "                                  optimizer, temperature)\n",
    "clients_trainer = []  # list of client_trainer\n",
    "\n",
    "# different clients at each epoch\n",
    "\n",
    "idxs_users = range(num_users)\n",
    "\n",
    "# init all clients\n",
    "for idx in idxs_users:\n",
    "    client_trainer = GKTClientTrainer(client_model, train_dataset, test_dataset,\n",
    "                                      user_groups[idx], idx, gpu, optimizer, local_batch_size,\n",
    "                                      lr, client_epochs, temperature, partition_alpha)\n",
    "    clients_trainer.append(client_trainer)\n",
    "    # print(f\"client \\t{idx}/{num_users} initialized\")\n",
    "\n",
    "for communication_round in range(1, communication_rounds+1):\n",
    "    print(f'\\nCommunication Round: {communication_round} \\n')\n",
    "\n",
    "    m = max(int(frac * num_users), 1) # number of users to be used for federated updates, at least 1\n",
    "    idxs_chosen_users = np.random.choice(range(num_users), m, replace=False) # choose randomly m users\n",
    "\n",
    "    print(idxs_chosen_users)\n",
    "    for idx in idxs_chosen_users:\n",
    "        # the server broadcast k-th Z_c to the client\n",
    "        extracted_feature_dict, logits_dict, labels_dict, extracted_feature_dict_test,\n",
    "        labels_dict_test = clients_trainer[idx].train()\n",
    "\n",
    "        # send client result to server\n",
    "        server_trainer.add_local_trained_result(idx, extracted_feature_dict, logits_dict, labels_dict,\n",
    "                                                extracted_feature_dict_test, labels_dict_test)\n",
    "\n",
    "    # # check if all updates are received\n",
    "    # b_all_received = server_trainer.check_whether_all_receive()\n",
    "    # print(\"b_all received\" + str(b_all_received))\n",
    "    #\n",
    "    # if b_all_received:\n",
    "    #     server_trainer.train(communication_round)\n",
    "\n",
    "    server_trainer.train(communication_round, idxs_chosen_users)\n",
    "\n",
    "    for idx in idxs_chosen_users:\n",
    "        # get global logits\n",
    "        global_logits = server_trainer.get_global_logits(idx)\n",
    "\n",
    "        # print(type(global_logits))\n",
    "        # print(len(global_logits))\n",
    "        # print(global_logits)\n",
    "\n",
    "        # send global logits to client\n",
    "        clients_trainer[idx].update_large_model_logits(global_logits)\n",
    "\n",
    "# get lists of train loss and accuracy\n",
    "train_loss, train_accuracy = server_trainer.get_loss_acc_list()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Exectution completed!\")\n",
    "\n",
    "# TODO print summary of parameters used\n",
    "\n",
    "# TODO print last accuracy\n",
    "\n",
    "# TODO some graphs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save train loss and accuracy\n",
    "import pandas as pd\n",
    "\n",
    "file_name = 'fedGKT_results/{}_{}_{}_lr_[{}]_C[{}]_iid[{}]_Es[{}]_Ec[{}]_B[{}]_{}_unbalanced[{}].csv'.\\\n",
    "    format(\"ResNet50\", normalization_type, communication_rounds, lr, frac, iid,\n",
    "           server_epochs, client_epochs, local_batch_size, optimizer, unbalanced)\n",
    "\n",
    "data = list(zip(train_loss, train_accuracy))\n",
    "pd.DataFrame(data, columns=['train_loss','train_accuracy']).to_csv(file_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}